{"/proxy/":{"data":{"":"","architecture-and-workflows#Architecture and Workflows":"See this document on architecture for details on the proxy’s thread components and how various subsystems work.","backend-objects#Backend Objects":"What is a Backend A backend object describes a single memcached server that you want the proxy to talk to. Collections of backend objects are assembled into Pools.\nBackends cannot be directly used in route handlers. They must be wrapped in a pool first.\nWhy are backends separate from pools? We allow the same backend object to be referred in multiple pool objects. This can be useful in scenarios like adjusting the size of a pool over time. This usually requires temporarily creating two pools: if expanding, one with an extra backend, then the other with the original set. Since we can share backend objects between the two, we avoid creating excess TCP connections.\nThis also allows us to customize some options on a per-object basis. Though whether or not this ability is exposed to the user will depend on their route library.\nThe backend object cache Backends are stored indexed by their label. When you attempt to create a backend the proxy will check if it already has an object with that label. If it does, it will check the arguments supplied and replace the object if something has changed (ie; ip address, port, timeout settings, etc).\nThis has both a large speedup on reloading configurations and avoids having a configuration reload double all TCP connections by creating all new objects.\nSince the configuration code doesn’t have to manage this cache, it can simply describe objects any way it wants and the proxy will handle updating them when they change.\nBackend API Allowable from mcp_config_pools\nShort form backend creation\n-- create a backend object from a short description mcp.backend(label, host|ip, port) -- label: uniquely identify this backend object so it may be reused -- host|ip: is the hostname or IP address of the server, though IP addresses are -- strongly recommended as of this writing since DNS lookups can cause -- performance issues. -- port: is the service port the server is listening on. -- The `label` of a backend gives it a unique cache id. If a backend has the -- same label and options during reload, the underlying connections are reused. Long form backend creation. This allows overriding some global settings on a per-backend basis.\nmcp.backend({ -- uniquely identify this backend object so it may be reused label = \"string\", -- the hostname or IP address of the server, though IP addresses are -- strongly recommended as of this writing since DNS lookups can cause host = \"string\", -- the service port the server is listening on. port = number, -- the number of TCP connections to use for this object. The proxy will -- attempt to spread requests across multiple sockets. Useful if you have -- a lot of large items. -- This can create 'count' connections *per worker thread*, so be careful. -- Do not set to a large number! 1 is the default, 2 is probably enough. connections = count, -- If true, any attempt to access this backend will result in immediate -- failure (`SERVER_ERROR backend failure`) down = true|false, -- These next options override global settings, see below for detail. -- seconds may be fractional, ie: 0.5 for 500ms or 2.75 for 2750ms -- mcp.tcp_keepalive tcpkeepalive = true|false, -- mcp.backend_failure_limit failurelimit = count, -- mcp.backend_connect_timeout connecttimeout = seconds, -- mcp.backend_retry_waittime retrywaittime = seconds, -- mcp.backend_read_timeout readtimeout = seconds, -- mcp.backend_flap_time flaptime = seconds, -- mcp.backend_backoff_flap_ramp flapbackofframp = seconds, -- mcp.backend_backoff_flap_max flapbackoffmax = seconds, }) ","configuration-api#Configuration API":"To load the configuration, a dedicated thread first compiles the Lua code. It then calls the function mcp_config_pools, which loads all backends, collects them into pools, and returns a Lua table holding all of the final pool objects. Next, for each worker thread, they each execute mcp_config_routes. This function is expected to set up route handling (code that matches requests to a pool), and sets the command hooks that memcached will call (ie; hooks on get, set, and so on).\nThe proxy flow starts by parsing a request (ie: get foo) and looking for a function hook for this command. If a hook exists, it will call the supplied function. If no hook exists, it will handle the request as though it were a normal memcached.\nIn Lua, this looks like: mcp.attach(mcp.CMD_GET, function) - Functions are objects and can be passed as arguments. The function is called within a coroutine, which allows us to designs routes procedurally even if they have to make a network call in the middle of executing.\nThe function is called with a prototype of:\nfunction(request) end The most basic example of a valid route would be: mcp.attach(mcp.CMD_GET, function(r) return \"SERVER_ERROR no route\\r\\n\" end)\nFor any get command, we will return the above string to the client. This isn’t very useful as-is. We want to test the key and send the command to a specific backend pool; but the function only takes a request object. How are routes actually built?\nThe way we recommend configuring routes are with function closures. In lua functions can be created capturing the environment they were created in. For example:\nfunction new_route() local res = \"SERVER_ERROR no route\\r\\n\" return function(r) return res end end mcp.attach(mcp.CMD_GET, new_route()) In this example, new_route() returns a function. This function has access to the environment (local res = ) of its parent. When proxy calls the CMD_GET hook, it’s calling the function that was returned by new_route(), not new_route() itself. This function uselessly returns a string.\nThis should give you enough context to understand how the libraries in the proxylibs repository are implemented.\nSince we have a real programming language for both configuration and the routes themselves, we can write loops around patterns and keep the configuration short.","examples-and-use-cases#Examples and use cases":"See this document on example architectures for different methods of deploying and using the proxy.","faq#FAQ":"","features#Features":" Supports most of the text and meta protocols Dynamically configured backend pools and route handling Pluggable key distribution hashing algorithms Reduces connections to backend servers Use of Lua coroutines allows procedural programming style Able to selectively override commands, or serve from memcached embedded in the proxy Design routes to precisely fit your needs via simple Lua Flexible topologies: Run as a sidecar client, a large border proxy, or directly on an existing pool of servers Fast: all performance critical code is still C. Minimal Lua is executed for routing requests to backends. Roadmapped features:\nExpanded API for manipulating request data easily TLS support for backend connections (frontend TLS is already supported) ","function-generators-and-request-contexts#Function generators and request contexts":"NOTE: This information is only useful for people intending to develop a route library or extend routelib. End users should read the routelib README.\nTo achieve high performance while still allowing dynamically scriptable route handling, we must A) pre-create data, strings, etc and B) avoid allocations, which avoids Lua garbage collection. We also need to carefully manage the lifecycle of pools and backends used by the proxy, and maintain access to useful context for the duration of a request.\nThis requires wrapping request handling functions with context\nWhen a request is processed by the proxy, it needs to first acquire a request context slot. This provides a function that will execute a request. After a request is complete the slot may be reused for the next request. This also means we need as many slots as there are parallel requests. If a worker is processing three get requests in parallel, it will need to create three contexts in which to execute them.\nWe use a function generator to create this data. This also allows us to pre-create strings, validate arguments, and so on in order to speed up requests.\nA minimal example:\nfunction mcp_config_routes(pool) -- get a new bare object. local fgen = mcp.funcgen_new() -- reference this pool object so it cannot deallocate and be lost. -- note that we can also reference _other function generators_, -- providing us with a graph/tree/recursive style configuration. local handle = fgen:new_handle(pool) -- finalize the function generator object. When we need to create a new -- slot, we will call `route_handler`, which will return a function fgen:ready({ f = route_handler, a = handle }) -- attach this function generator to `get` commands mcp.attach(mcp.CMD_GET, fgen) end -- our job is to pre-configure a reusable function that will process requests function route_handler(rctx, a) -- anything created here is available in the function below as part of its -- local environment local handle = a return function(r) -- the rctx object is unique to _each slot generated_ -- it gives us access to backend API calls, info about the client -- connection, and so on. return rctx:enqueue_and_wait(r, handle) end end ","general-api-documentation#General API documentation":"Allowable from mcp_config_pools function:\nmcp.add_stat(number, label): Creates a fast custom counter, which are viewable via the stats proxy command. Use a unique constant number for the number argument, and a descriptive text for label. Settings:\n-- Time in fractional seconds to wait for a connection before retrying mcp.backend_connect_timeout(seconds) -- Time in whole seconds for waiting before attempting to make a new -- connection after a backend has reached the failure limit and been marked bad. mcp.backend_retry_waittime(seconds) -- Time in fractional seconds to wait for a read response once writing requests -- to a backend. mcp.backend_read_timeout(seconds) -- Number of times a backend can fail to properly connect and validate in a -- row before being marked as bad. mcp.backend_failure_limit(seconds) -- Whether or not all new backends use TCP Keepalive mcp.tcp_keepalive(bool) -- Fast fail if more than this many requests are actively being processed. mcp.active_req_limit(count) -- Fast fail if more than roughly this many kilobytes are actively in use -- by requests for request or response value buffers. mcp.buffer_memory_limit(kilobytes) -- Number of seconds a backend must be held open without errors or else it -- is considered to be flapping. (TODO: docs) mcp.backend_flap_time(seconds) -- A small fractional second value. It is multiplied into `retry_waittime` -- by the number of times it has flapped, providing a backoff for how often -- to retry unhealthy servers. mcp.backend_flap_backoff_ramp(seconds) -- Maximum number of whole seconds to wait before retrying a flapping server. -- Ensures servers with ephemeral issues are occasionally brought back in a -- reasonable timeframe. mcp.backend_flap_backoff_max(seconds) -- Whether or not a backend is hanndled by worker threads or a dedicated IO -- thread, by default. -- disabled by default, which provides better scalability at the cost of more -- TCP connections and less batching of backend syscalls. -- This can be overridden in pool settings. mcp.backend_use_iothread(false) Allowable from mcp_config_routes function:\nmcp.attach(CMD, function): Attaches a function to a command hook. See Configuration API for details.\nmcp.request(request, value): Takes a string request and creates a request object from it. This parses the request to ensure it is valid protocol. Optionally a value string can be added to provide the value portion of a set style request. value may also be a response object, the proxy will internally copy the response value into the new object instead of needing to copy through lua.\nmcp.log(message): ships text message to a log stream viewable via watch proxyuser\nmcp.log_req(request, response, detail): Produces detailed log line into watch proxyreqs stream by comparing the supplied request and response objects. detail is a string that is also passed to the log entry.\nmcp.log_reqsample(milliseconds, rate, allerrors, request, response, detail): This function allows conditionally logging detailed request logs, same as mcp.log_req. request, response, and detail are the same. milliseconds, if non-zero, will log all requests which took longer than this limit to get a result. rate, if non-zero, will log an average of “one in every rate” requests, allowing random sampling. allerrors, if true, will always generate a log line if an error was generated instead of a typical response (ie; backend down, malformed request/response, etc).\nmcp.stat(number, change): Given an index number created from mcp.add_stat, adds the integer change to that counter. change may be positive or negative.\nObject methods:\n(missing lots of documented methods right now)\nrequest objects:\nrequest:key(): returns the key from the parsed request object request:ltrimkey(number): removes number characters from the left side of the key. request:rtrimkey(number): removes number characters from the right side of the key. request:ntokens(): the total number of arguments in the request request:token(n, \"token\"): fetches or replaces a token at this position in the request. If a blank (\"\") is passed as the second argument the token is removed. This can be used, for example, to see or replace the TTL part of a SET request. request:vlen(): length in bytes of the value attached to this request request:has_flag('F'): for use with meta, a fast function for testing if a flag exists in the request string. request:flag_token(\"F\", \"Freplacement\"): for use with meta, a fast function for finding and modifying a request line. Returns (exists, previous_token), a bool on if the flag exists, and if the flag has a token attached it will be returned in previous_token. If a second argument is passed, it will be used to replace the flag and/or token argument in the request. A blank (\"\") value will remove the flag entirely. NOTE: If you run this command repeatedly on the same token, it will not return previously updated values. This behavior may change in the future. response objects:\nresp:hit(): whether a request was a successful hit, if that makes sense from the original request. resp:ok(): whether a request was successfully executed to the backend. For GET requests, both HIT and MISS are OK. resp:line(): for use with meta, returns the full response header line. resp:code(): the response code. Common codes are: mcp.MCMC_CODE_OK mcp.MCMC_CODE_STORED mcp.MCMC_CODE_EXISTS mcp.MCMC_CODE_MISS TODO: document the rest. ","pool-objects#Pool Objects":"What is a pool Pool objects are (typically) very lightweight containers that hold references to backend objects. They also hold configuration for how to choose a backend from a supplied key.\nNormally you would expect a “route handler” to take a list of backends and be able to do the key mapping itself, which is more flexible. For us we need to manage performance carefully and want to minimize the amount of Lua being executed. Thus pools objects are fully implemented in C.\nThe default key distribution method for pools is to use XXHash to hash the keys, and Jumphash algorithm to distribute keys across a list of backends. This is a very fast and very even distribution method. If you use ketama or similar hashing it is highly recommended to try to convert to this newer method.\nIf other methods are desired for compatibility or otherwise, both the hashing algo and key distribution algo can be overridden in C.\nPool API Allowable from mcp_config_pools function:\nmcp.pool({backend1, backend2, etc}, { -- If true, backends listed in this pool use a shared thread for IO -- access, reducing TCP connections. If false, each memcached worker -- thread maintains its own backend TCP socket for this pool. -- [TODO: add anchor for details] iothread = true|false, -- If supplied this prefix will be added to the lables of all specified -- backends. This means this pool object will get unique TCP sockets for -- its backends. Usable for dedicating different sockets for different -- purposes (gets vs sets). beprefix = string, -- A string to \"seed\" the hash algorithm for this pool. If two pools are -- created with the same backends, but different seeds, they will -- distribute keys differently to the backends. seed = string, -- See also `filter_conf`. This allows directing sets of related keys -- onto the same backend nodes, improving batch performance. -- If \"stop\": Will hash only the first part of a key until the configured -- stop text. IE, a three character string like '|#|' -- If \"tags\": Will hash only the parts of a key between two given -- characters. IE, \"{}\" or \"$$\" filter = string, -- Configuration for the requested filter type. See above for examples. filter_conf = string, -- Allow overriding the hash or distribution algorithms. -- TODO: Docs. hash = object, dist = object, }) Pluggable key hashing Pluggable key distribution ","programming-caveats#Programming caveats":"Global values and config reloads When we create route handlers we aim to put all of the context/data that they use in the environment of the function. When configuration reloads happen, all of the code can change. Pre-existing requests might be waiting for a backend response, and we don’t want their code to change out from under them.\nSo long as all data is in the environment of the function then reloads cannot break in-flight requests. However if you rely on globals and those globals may change during a reload, you can get into trouble.\nExample:\nfunction generator(rctx, arg) -- good: retrieve a toggle from a passed in argument local toggle = arg.toggle -- okay: retrieve a toggle from a global during function generation local toggle = GLOBAL_TOGGLE_BOOLEAN local handle = etc return function(r) if toggle then -- some specific prep work else -- different prep work end local res = rctx:enqueue_and_wait(r, handle) if toggle then -- if a reload happened between the first toggle check and this -- one, and instead of 'toggle' we directly referenced -- GLOBAL_TOGGLE_BOOLEAN, we could make a mistake. else -- as above end end end This goes the same for something like a lookup map. In lua, tables and objects are passed around by reference. This means if we are generating a lookup table at load time, and passing it into a function, it is perfectly safe to use.\nExample:\nfunction mcp_config_routes(c) -- skip: various prep work. -- this makes a new top level lookup table. local lookup = { one = 1, two = 2, three = 3 } -- which we then pass into a function generator fgen:ready({ f = generator, a = lookup }) -- the next time a reload happens, it doesn't matter if `lookup` changes, -- because since we make lookup within mcp_config_routes(), it will be -- unique on every load end Another example:\n-- lookup is now a global variable lookup = { one = 1, two = 2, three = 3 } function mcp_config_routes(c) -- skip: various prep work. -- This is still okay, since 'lookup' is being overwritten by a new table -- during reload, and here we are passing a reference to that table. fgen:ready({ f = generator, a = lookup }) end Bad example:\n-- lookup is a global table lookup = { one = 1, two = 2, three = 3 } function mcp_config_routes(c) -- not passing the reference in. fgen:ready({ f = generator }) end function generator(rctx) return function(r) -- could break, since we are now directly referencing the global -- table, which can change. many times this won't matter, but a best -- practice is to always pass referenecs down when needed. local foo = lookup[input] end end ","protocol-commands#Protocol Commands":"The following commands are relevant for controlling memcached proxy\nstats proxy: prints proxy-specific stats counters. Includes dynamically created counters from the lua configuration.\nwatch proxyreqs|proxyevents|proxyuser: watch commands for streaming logs specific to the proxy.\nSending a SIGHUP signal to memcached will cause the proxy to reload its configuration. This does not interrupt active traffic.","quick-start#Quick Start":"Requires memcached version 1.6.23 or newer. If you run into trouble, you can try the next branch in case a fix has already been found.\nYou can use Docker to try the latest code. This image expects a “config.lua” to be in the directory You will need to start backend memcached’s on your own!\ndocker run -v /path/to/config/directory:/config:ro --publish 11211:11211 \\ dormando/memcached:next-proxy A configuration flag is necessary to enable the feature:\n./configure --enable-proxy make make test If building from the next git branch, you will need to run a script to grab some vendored code:\ncd vendor/ ./fetch.sh cd .. ./configure --enable-proxy make make test Unless you want to write your route handlers from scratch, you need a route library. We supply a route library for ease of use. Note that future releases should include this library directly, so you will not always need to download it separately.\nPlease see the routelib README for a quick start guide.\nYou can route commands to the specified pools by adding “foo/” or “bar/” to the key, ie:\nget foo/a\\r\\n or get foo/someotherkey\\r\\n","request-context-api-and-backend-requests#Request context API and backend requests":"Function generator API\n-- creates a new factory object. pass this object as the function argument -- to mcp.attach() or rctx:new_handle. fgen = mcp.funcgen_new() -- references a pool or funcgen into this funcgen and returns a handle. This -- handle is later used during request processing to enqueue requests. handle = fgen:new_handle(pool||funcgen) -- this marks the funcgen generator as ready to run, and passes in a few more -- more arguments. fgen:ready({ -- this is the function factory that we will use. see below for detail f = route_handler, -- an arbitrary argument (bool/string/num/table) to pass to route_handler a = argument, -- a name for this function generator, for 'stats proxyfuncs' output n = string, }) -- 'route_handler' is called _once_ per request slot that is generated. If -- there are many parallel in-flight requests this can be called many times. -- The output function is cached and reused until the configuration is -- reloaded. -- 'route_handler' has a prototype of: function route_handler(rctx, arg) -- 'rctx' is a new request context object that was just created. -- 'arg' is the argument passed in 'a' above via fgen:ready() -- this must return a new function with the following prototype. It is -- then called to serve individual requests repeatedly. return function(r) -- code end end Request factory API. These API calls are available from the function that is generating the function to ultimately serve requests.\n-- execute this function callback when this handle has been executed. -- this allows adding extra handling (stats counters, logging) or overriding -- wait conditions rctx:handle_set_cb(handle, function) -- callbacks look like: local cb = function(res, req) -- the result and request executed are available for examination -- we can _optionally_ return a condition, in case we want to make our own -- judgement of what GOOD/OK/ANY means. return mcp.WAIT_ANY -- we can also return a second argument if we want to end a wait condition -- early return mcp.WAIT_ANY, mcp.WAIT_RESUME end rctx:handle_set_cb(handle, cb) Request handling API\n-- to be called from the request function, queues up a request against the -- designated slot handle, or an array style table of N handles rctx:enqueue(r, handle || table) -- Directly returns a single result object after waiting on -- a specified unqueued handle. res = rctx:enqueue_and_wait(r, h) -- Directly returns a single result object after waiting on -- a specified prequeued handle. res = rctx:wait_handle(h) -- Asynchronously waits for up to \"count\" results out of all currently -- queued handles. Takes a mode to filter for valid responses to count: -- mcp.WAIT_OK, WAIT_GOOD, WAIT_ANY -- WAIT_FASTGOOD will wait for the first \"Good\" (ie; hit) request or N total -- responses -- if \"0\" is supplied for count, it will execute queued requests and -- immediately resume. num_good = rctx:wait_cond(count, mode) -- returns result object if the queue response was considered \"Good\", else -- nil. rctx:res_good(handle) -- same but \"WAIT_ANY\" rctx:res_any(handle) -- same but \"WAIT_OK\" rctx:res_ok(handle) -- returns result object, mcp.RES_GOOD|OK|ANY res, mode = rctx:result(handle) When requests dispatch to backends Requests are enqueued with the various enqueue* functions. The requests are not immediately transmitted to the backends. Whenever an rctx is asked to wait, ie: both for enqueue_and_wait and wait_cond, all enqueued requests are immediately executed.\nThis means if you enqueue two requests, then queue and wait on a third, all three requests are batched and executed simultaneously.\nWhere is the results table? This core API is designed to execute without causing any Lua allocations, which includes tables being returned to the user. As such, our wait functions cannot simply return a table of results.\nHowever, when working with this API you will almost always have handles for all of the backends you are making requests against. Thus a common pattern will be:\n-- in generation phase local handles = {} for k, v in pairs(pools) do table.insert(handles, rctx:new_handle(v)) end -- ... later, at request time rctx:enqueue(r, handles) -- batch enqueue request to all handles rctx:wait_cond(#handles) -- wait for all requests to finish -- use the same table again to iterate the results for x=1, #handles do local result = rctx:res_good(handles[x]) end -- In this example we referenced our list of pools multiple times without -- making any allocations. ","router-objects#Router objects":"Lets say we want to route requests to different pools of memcached instances based on part of the key in the request: for this we use router objects.\nRouters can achieve this matching efficiently without having to examine the key inside Lua, which would result in many copies and regular expressions.\n-- Minimal example of a router. Here: -- \"get foo/etc\" would be handled by the \"funcgen_foo\" handler -- \"get bar/etc\" would be handled by the \"funcgen_bar\" handler -- By default the router checks up to a \"/\" character for the map key. local m = { foo = funcgen_foo, bar = funcgen_bar, } local router = mcp.router_new({ map = m, mode = \"prefix\", stop == \"/\" }) mcp.attach(mcp.CMD_GET, router) Explanation of router options:\nlocal r = mcp.router_new({ -- a table of route handlers to requests to -- see \"command maps\" below for more info. map = m, -- mode can be (default \"prefix\"): -- \"prefix\": we check the prefix of the key against the map. -- stop matching when the \"stop\" character is seen. -- \"anchor\": we check for and skip characters in \"start\", then match until -- \"stop\" is seen. mode = \"etc\", -- start looks for these characters at the start of a key and skips them -- before finding a sub string to match against. It is \"\" by default -- if start is a single character, and optimized algorithm is used. -- it must be 5 characters or less. start = \"_\", -- stop will stop matching at this character, and what came before this -- string to check against the map. It is \"/\" by default. -- It follows the same rules as \"start\": single characters are faster, max -- is 5. stop = \"/\" -- If the request does not match against the map, use this route handler -- by default. default = funcgen }) -- command maps -- A router map entry may either reference a funcgen handler directly, or -- another table which further maps commands to funcgen handlers local m = { -- any \"foo/etc\" key for get/set/touch will route here foo = handler1, bar = { -- only \"get bar/etc\" will use handler2. [mcp.CMD_GET] = handler2, -- if a CMD_ANY_STORAGE entry is also provided, use if no exact match [mcp.CMD_ANY_STORAGE] = handler3, -- if no CMD_ANY_STORAGE is provided, and no exact CMD match, the -- router's default entry is used. } } local r = mcp.router_new({ map = m }) mcp.attach(mcp.CMD_ANY_STORAGE, r) ","status#Status":"At this stage API functions are mostly stable, but are still subject to occasional change. Most changes in functionality will be either additions or with a backwards-compatible deprecation cycle.\nAfter 1.6.23, we do not expect major core changes to the API. We will stick to incremental improvements.","what-happens-to-in-flight-requests-on-config-reload#What happens to in-flight requests on config reload?":"When the configuration is reloaded, mcp_config_routes gets called again. During this process routes are assembled into functions and mcp.attach() is called with these top level hooks. Any time a request comes in these top level hooks are checked for their associated function.\nThis means once a request fires off its hook, it is immune from configuration changes until it completes. Any new request coming in will see what’s presently configured in a hook and get the new code even as older requests are being processed.\nThis does mean you have to be careful with using global variables in Lua: we suggest the use of function closures for routes to avoid configurations clashing.","what-is-it#What is it?":"A proxy speaking the memcached text and meta protocols designed for managing clusters of memcached servers. It is fast, flexible, trivial to build and deploy. Since it is built into memcached and scriptable using Lua (5.4), many topologies, tricks, and deployment options are possible.\nMost existing memcached proxies reflect the architecture of the companies which originally made them. With the internal proxy, the “route handlers” are small Lua functions which pass requests into pools of servers. This allows it to not only emulate most existing proxies, but adapt more closely to your own architecture.","why-lua#Why Lua?":"I thought ya’ll could use a break from YAML :) We use Lua and its extensibility like glue: nearly everyone has different methods of managing their configuration, and in most cases a simple lua script would be able to parse output from such services or talk to them directly. A handful of for loops and object reuses can remove tens of thousands of lines of generated configuration.\nFor route handling our usage of Lua is more bold, but again it’s simply glue. Configurations for routes will tend to be wide but shallow: just a couple small function calls based on the contents of the request, and then the request is handed back off to the C side. Object methods written in C further avoid copying strings/data to/from Lua for common operations.\nSince the proxy integrates with memcached’s existing systems, we can (over time) ensure all large memory allocations are handled outside of Lua. The rest of the tiny allocations, if any, are tied to a coroutine and released immediately after the (typically under a millisecond) request/response.","why-not-luajit#Why not LuaJIT?":"For half the answer to this, please see Why lua? - for loading configuration the performance difference isn’t going to matter much. For route handling very little work is done from Lua, which will be reduced or removed as development continues.\nWhen development started LuaJIT had a much more rocky status. Also Lua 5.4 has a good number of language and performance improvements on its own.","why-not-use-a-mesh-router#Why not use a mesh router?":"Memcached’s proxy is not intended to replace a mesh router; its scope is much smaller and more performance focused. A mesh router may be highly confgurable, with broad support, but will be very slow. Caching services (and in this case a caching proxy) can be used to restore performance to a service migrated to a mesh router; for cost or practicality reasons.\nMany data queries don’t or shouldn’t go through a mesh router anyway. If you want to speed up access to data storage from an application implemented as an endpoint on a mesh router, a caching service is what sits behind that endpoint but before its actual data storage."},"title":"Builtin Proxy"},"/proxy/arch/":{"data":{"":"","backend-and-pool-object-management#Backend and Pool object management":"Backend object lifecycle The below API only creates a description of a backend internally. Actual backend objects are created when mcp.pool() is called. This allows us to track the lifecycle of backends with the lifecycle of pools.\nIE: If pool A is created with backends 1 and 2, those backends are guaranteed to live as long as pool A lives. If pools A and B share the same backends, reference counting is used on the backends. Both pools A and B would need to be de-allocated before backends 1 and 2 are removed.\nThis is partly done for performance reasons: since we don’t have to change the reference count or lock backends 1 and 2 when requests are being executed. Basically:\nA backend can only be queried if a pool object still exists. Pool objects cannot be deallocated anywhere when a request is being handled. Pools use a higher level memory management. Thus we can use everything without reference counting or locking at request time. ","backend-connection-failure-detection#Backend connection failure detection":" ","backend-requests-and-connections#Backend requests and connections":"Backend requests may either come directly from a worker thread (if iothread = false in pool settings). Each worker thread has a dedicated TCP connection to each backend server.\nflowchart TD subgraph worker2 direction LR Worker{Worker thread} \u003c--\u003e Backend1[Backend server] Worker \u003c--\u003e Backend2[Backend server] Worker \u003c--\u003e Backend3[Backend server] end subgraph worker1 direction LR Worker2{Worker thread} \u003c--\u003e Backend11[Backend server] Worker2 \u003c--\u003e Backend12[Backend server] Worker2 \u003c--\u003e Backend13[Backend server] endOr, if iothread = true, workers will submit requests to a dedicated IO thread, which will batch up requests to the same backend if possible. In this mode we will use fewer total TCP sockets.\nThis IO thread does not contain any Lua processing, it is pure C and only handles the networking and protocol parsing on response data.\nflowchart LR Worker1[Worker thread] \u003c--\u003e IO{IO thread} Worker2[Worker thread] \u003c--\u003e IO IO \u003c--\u003e Backend1[Backend server] IO \u003c--\u003e Backend2[Backend server] IO \u003c--\u003e Backend3[Backend server]","client-and-backend-request-batching#Client and backend request batching":"Batching client requests Multiple requests from a single client socket may be batch processed. This improves performance by reducing the number of syscalls and context switches, but has some caveats.\nFor the proxy, client request batching works exactly the same as a normal memcached, as the code is shared. They differ when it comes time to return a response to the client.\nFor example, lets take client A and proxy P:\nClient A makes a TCP write() call with a buffer containing three requests at the same time: get foo\\r\\n get bar\\r\\n get baz\\r\\n A worker thread on proxy P now gets woken up with a notification that data is ready on the socket for client A. The proxy now issues a read() against the socket, for up to READ_BUFFER_SIZE (16kb) bytes. The read buffer is large enough to hold all three requests, and the proxy begins to parse the buffer. The proxy first executes get foo, which resolves to backend b1. The request is now queued to be executed by b1, and get foo is now suspended while waiting for a response. The proxy immediately moves to the next request, starting get bar. Which goes to backend b2 and so on. The process repeats until the proxy runs out of client requests or hits a yield limit (see below) Now that the proxy has nothing to return to Client A, because it is waiting on three parallel requests to different backends. It will suspend the processing of Client A.\nOnce all queued responses are collected Proxy P will resume and send all results back to Client A. This means the Time To First Byte for the response to Client A will be the speed of the slowest backend server.\nIf more requests arrive at Client A’s socket while it is already suspended, those requests cannot start until the original set completes.\nNOTE: This will likely change in future versions; allowing the proxy to return partial responses when safe, and start new requests if they arrive while former ones are waiting.\nIn many cases there is either exactly one request arriving at a time, or all backends are roughly the same speed: memcached does not typically do processing before returning results, so all requests take the same amount of time. In most cases performance is acceptable.\nsequenceDiagram Participant Client Participant Proxy Worker Participant Backend Client-\u003e\u003eProxy Worker: 3x GET key\\r\\n Note right of Proxy Worker: Process incoming requests Note right of Proxy Worker: Queue backend requests Proxy Worker-\u003e\u003eBackend: 3x GET etc\\r\\n Note right of Proxy Worker: Send all GETs to backends Backend-\u003e\u003eProxy Worker: 3x VALUE etc\\r\\n Note right of Proxy Worker: Ready to respond to Client Proxy Worker-\u003e\u003eClient: 3x VALUE etc\\r\\nBatching backend requests In comparison to Client socket handling detailed above, backend sockets use full bidirectional streaming.\nTake a Backend B that has received three requests from different clients at the same time:\nget foo\\r\\n get bar\\r\\n get baz\\r\\n Backends do no processing on requests that are queued for it: all they need to do is write these requests out to the socket connected to the backend server. Here we will:\nQueue up all three requests into a single write syscall Wait for responses Read up to READ_BUFFER_SIZE (16kb) from the socket at once Begin processing each response in a loop: Parse the response, if okay return the response object to its original client. If there is another response ready in the buffer, immediately process it. Once complete, go back to waiting. If more requests arrive while Backend B is waiting for respones, it will immediately write() them to the same socket. If the socket buffer is full, it will wait until it can write more. Thus new requests are not delayed while waiting for a previous batch to complete.\nResponess are immediately sent to their respective Client’s as they’re read off of the socket, so there is no internal delay for waiting on a batch to process.\nIf Backend B breaks for some reason, the queue is immediately drained and error responses are sent to all waiting Client’s.\nTODO: chart.","client-connections-and-workers#Client connections and workers":"Client connections to the proxy are handled exactly the same as a normal memcached. A dedicated thread listens for new sockets, and distributes client connections to each worker thread in a round robin.\nEach worker gets a dedicated Lua VM: Lua data cannot be directly shared between worker threads.\nThere are no dedicated “proxy” worker threads. A worker thread may handle cache responses or proxy requests. Lua for request handling is only executed in a worker thread.\n--- title: Client socket handling --- flowchart LR Client[Client connection] --\u003e Accept{Listen/Accept thread} Accept --\u003e|round robin| Worker1[Worker thread] Accept --\u003e|round robin| Worker2[Worker thread] Accept --\u003e|round robin| Worker3[Worker thread]","configuration-load-and-reload#Configuration load and reload":"A separate Lua configuration thread processes the config file, executes mcp_config_pools and creates all of the backend and pool objects. It then copies the configuration to each worker VM. The worker VM’s each execute mcp_config_routes on load; it is important to keep this function lightweight.\nThe configuration thread has its own dedicated Lua VM. It shares data to the worker VM’s by doing a specialized cross-VM data copy of the results returned from mcp_config_pools()\nThe load process runs against one worker thread at a time. First, because the configuration thread has to copy some data into each worker, and second to minimize the latency impact of reload.\nflowchart LR Config{Configuration thread} --\u003e|first| Worker1[Worker thread] Config --\u003e|second| Worker2[Worker thread] Config --\u003e|third| Worker3[Worker thread] ","configuration-reload#Configuration reload":" ","request-flow#Request flow":"flowchart TD A[\"get foo/username\"] --\u003eB[\"is there a get hook?\"] B --\u003e |yes|C[check map for a 'foo' func] B --\u003e |no|D[respond from local cache] C --\u003e |yes|E[is a req slot free?] E --\u003e |yes|F[\"run func(req)\"] E --\u003e |no|G[\"generate a func slot\"] G --\u003e F F --\u003e H[execute against one or more pools] H --\u003e I[pool: map key against list of backends] I --\u003e J[is backend on worker thread or background thread?] J --\u003e |worker|K[execute from within same thread] J --\u003e |background|L[ship request to shared BG thread] K --\u003e M[remote memcached processes request] L --\u003e N[BG thread batches all pending requests] N --\u003e M M --\u003e O[response received from remote mc] O --\u003e P[\"VALUE etc response sent to client\"]Almost all of the actual processing is done outside of Lua, with Lua used to primarily manage configuration as code."},"title":"Deployment Architectures"},"/proxy/examples/":{"data":{"":"The memcached proxy is a flexible and lightweight system with few dependencies. Any memcached binary can be a proxy, a cache server, or both. This allows us to adjust easily based on application requirements.","application-sidecar#Application Sidecar":"flowchart TD subgraph app [Application Host] App[Application] --\u003e|simplified memcached protocol| Prox{Memcached Proxy} end Prox --\u003e foo subgraph foo [key prefix 'foo/'] FN1[memcached] FN2[memcached] FN3[memcached] end Prox --\u003e bar subgraph bar [key prefix 'bar/'] BN1[memcached] BN2[memcached] BN3[memcached] endSidecar Architecture In a “sidecar” style deployment, each application server runs a proxy co-located on its host. This can be by binary deployment, container, and so on.\nThis provides a compromise between having full border proxies and having fat clients directly inside the application. The sidecar can abstract pool configuration, fan-out, key distribution, upgrading the proxy, etc, away from an application client, simplifying maintenance.\nIt’s also possible to mix these approaches: some applications may work better with a local sidecar (high bandwidth) and some might use a centralized pool (less cache usage, so simplify deployments).\nSidecar Pros Scales similar to memcached without a proxy: no limits on bandwidth or request rate.\nMore work than maintaining a small centralized pool, but still allows proxies to be updated without adjusting an application server.\nAllows applications to use simplified clients still.\nSidecar Cons Must manage deployments on every application server, instead of one pool centrally.\nAdd some CPU overhead to application servers.\nStill requires extra system calls: between client and local proxy, then out to remote servers and back.\nGenerally the overhead of local connections is low, but this must be verified because “container systems” can add significant overhead.","best-effort-data-redundancy#Best effort data redundancy":"","cache-layering-proxy#Cache Layering Proxy":"flowchart TD App[Application] --\u003e foo subgraph foo [cache pool] C1[memcached] C2[memcached] C3[memcached] end foo --\u003e rem subgraph rem [remote pool] R1[memcached] R2[memcached] R3[memcached] endCache Layering Architecture A layered cache is an architecture where a pre-existing pool of memcached servers is replaced by proxy nodes. A standard client is used, which hashes keys and distributes them across proxy nodes. The nodes themselves then may execute extra work.\nThis extra work could be copying set commands to remote pools, fetching from remote pools on a miss, or fetching from remote pools for specific namespaces. This makes sense if you want to store long tail cold data on cheaper servers, or if you have some key namespaces which have a long tail of data, but not a high request rate.\nIt can also be a good gateway into deploying the proxy into an existing memcached pool.\nCache Layering Pros If you already have memcached deployed but want to add redundancy, expansion, or so on.\nKeep your most commonly used cache data in the top layer for good performance.\nCache Layering Cons Needs more complex application clients.\nConfiguration of pools needs to be managed in two places (application clients, memcached proxies)","distributing-data-by-usage#Distributing data by usage":"","protocol-translation#Protocol translation":"","proxy-middleware-machine#Proxy Middleware Machine":"flowchart TD A[Application] --\u003e|memcached protocol|B B{Memcached Proxy} B --\u003eD[Memcached] B --\u003eE[Memcached] B --\u003eF[Memcached]flowchart TD A[Application] --\u003e|memcached protocol|B B{Memcached Proxy} --\u003efoo1 B --\u003ebar1 subgraph foo1 [key prefix 'foo/'] FN1[memcached] FN2[memcached] FN3[memcached] end subgraph bar1 [key prefix 'bar/'] BN1[memcached] BN2[memcached] BN3[memcached] endMiddleware Architecture The “middleware machine” deployment approach is probably a familiar design: a machine or pool of machines sit inbetween the application servers and cache storage nodes. This design allows centralization of pool configurations, simplifying cache clients, and centralizing the maintenance of proxy servers.\nEach cache request must first be processed by the proxy server. The proxy will then fan-out sets of requests as necessary to backend servers and return the results back to the client.\nMiddleware Pros Cache configuration and cache pool maintenance is centralized. This allows a team to maintain a complex cache structure without disturbing or having to modify, restart, or push configuration to application servers.\nCache client complexity is moved to the proxy layer. Most memcached clients are “full featured”: meaning they take a configuration with a list of servers, run hash calculations, and spread requests out to backend servers directly. This is typically the best approach as it has the highest level of performance.\nHowever it can be useful to instead have a very thin memcached client. Especially if you need complex features, having to update all application programs to make changes can be a large burden on teams. This can lead to stagnation and people try to avoid making changes.\n“Hot key caches” are possible within the proxy layer to aid performance. Since every proxy is also a normal memcached, it is possible to create an “L1/L2” layered cache. The details will depend highly on your needs, but doing so can remove the added latency and CPU overhead of having extra network requests added from having to first go through the proxy.\nMiddleware Cons Fetching data requires going through the proxy first, adding roundtrips and latency. Without the proxy, a request/response to memcached requires:\nWrite request from client Read request from memcached Write response from memcached Read response from client With the proxy, extra latency steps are involved:\nWrite request from client .. wait for network..\nRead request from proxy Write request from proxy .. wait for netork..\nRead request from memcached Write response from memcached .. wait for network..\nRead response from proxy Write response from proxy .. wait for network..\nRead response from client Note that this can vary a lot by implementation: Hot caches in the proxy, or fetching from remote pools on miss, can still improve overall performance.\nPerformance is not ideal, especially for large caches with high bandwidth usage. If all involved machines are fast enough, high request rates can be manageable. However if cache data is very large (hundreds of kilobytes to megabytes), and the number of proxies is fewer than the number of cache servers, you can quickly run out of bandwidth.\nA non obvious benefit of memcached is that its distributed direct-to-client nature means the total bandwidth capacity of the pool scales linearly with the number of servers in the pool.\nIf you need 10 servers to hold all of your cache data, but only need 2 proxies to “front” them, your bandwidth is limited by the proxies, not the backend servers.","simplifying-and-unifying-cache-clients#Simplifying and Unifying Cache Clients":"","transparent-pool-resizing#Transparent pool resizing":"","transparent-upgrades#Transparent upgrades":"","use-case-examples#Use Case Examples":""},"title":"Usage Examples"},"/releasenotes/":{"data":{"":"","#":"Releases ReleaseNotes1629 1.6.29 (2024-6-28) ReleaseNotes1628 1.6.28 (2024-5-31) ReleaseNotes1627 1.6.27 (2024-5-5) ReleaseNotes1626 1.6.26 (2024-3-27) ReleaseNotes1625 1.6.25 (2024-3-19) ReleaseNotes1624 1.6.24 (2024-2-27) ReleaseNotes1623 1.6.23 (2024-1-9) ReleaseNotes1622 1.6.22 (2023-10-15) ReleaseNotes1621 1.6.21 (2023-6-15) ReleaseNotes1620 1.6.20 (2023-5-12) ReleaseNotes1619 1.6.19 (2023-3-8) ReleaseNotes1618 1.6.18 (2023-1-10) ReleaseNotes1617 1.6.17 (2022-8-26) ReleaseNotes1616 1.6.16 (2022-8-3) ReleaseNotes1615 1.6.15 (2022-3-29) ReleaseNotes1614 1.6.14 (2022-2-9) ReleaseNotes1613 1.6.13 (2022-1-12) ReleaseNotes1612 1.6.12 (2021-9-28) ReleaseNotes1611 1.6.11 (2021-9-27) ReleaseNotes1610 1.6.10 (2021-7-25) ReleaseNotes169 1.6.9 (2020-11-20) ReleaseNotes168 1.6.8 (2020-10-26) ReleaseNotes167 1.6.7 (2020-9-4) ReleaseNotes166 1.6.6 (2020-5-12) ReleaseNotes165 1.6.5 (2020-4-13) ReleaseNotes164 1.6.4 (2020-4-12) ReleaseNotes163 1.6.3 (2020-3-28) ReleaseNotes162 1.6.2 (2020-3-23) ReleaseNotes161 1.6.1 (2020-3-16) ReleaseNotes160 1.6.0 (2020-3-8) ReleaseNotes1522 1.5.22 (2020-2-1) ReleaseNotes1521 1.5.21 (2020-1-21) ReleaseNotes1520 1.5.20 (2019-11-11) ReleaseNotes1519 1.5.19 (2019-9-30) ReleaseNotes1518 1.5.18 (2019-9-17) ReleaseNotes1517 1.5.17 (2019-8-29) ReleaseNotes1516 1.5.16 (2019-5-24) ReleaseNotes1515 1.5.15 (2019-5-20) ReleaseNotes1514 1.5.14 (2019-4-27) ReleaseNotes1513 1.5.13 (2019-4-15) ReleaseNotes1512 1.5.12 (2018-11-3) ReleaseNotes1511 1.5.11 (2018-10-10) ReleaseNotes1510 1.5.10 (2018-8-10) ReleaseNotes159 1.5.9 (2018-7-7) ReleaseNotes158 1.5.8 (2018-5-25) ReleaseNotes157 1.5.7 (2018-3-28) ReleaseNotes156 1.5.6 (2018-2-27) ReleaseNotes155 1.5.5 (2018-2-12) ReleaseNotes154 1.5.4 (2017-12-20) ReleaseNotes153 1.5.3 (2017-11-4) ReleaseNotes152 1.5.2 (2017-9-30) ReleaseNotes151 1.5.1 (2017-8-24) ReleaseNotes150 1.5.0 (2017-7-21) ReleaseNotes1439 1.4.39 (2017-7-4) ReleaseNotes1438 1.4.38 (2017-6-24) ReleaseNotes1437 1.4.37 (2017-6-4) ReleaseNotes1436 1.4.36 (2017-3-19) ReleaseNotes1435 1.4.35 (2017-2-26) ReleaseNotes1434 1.4.34 (2017-1-7) ReleaseNotes1433 1.4.33 (2016-10-31) ReleaseNotes1432 1.4.32 (2016-10-12) ReleaseNotes1431 1.4.31 (2016-8-19) ReleaseNotes1430 1.4.30 (2016-8-11) ReleaseNotes1429 1.4.29 (2016-7-13) ReleaseNotes1428 1.4.28 (2016-7-1) ReleaseNotes1427 1.4.27 (2016-6-24) ReleaseNotes1426 1.4.26 (2016-6-17) ReleaseNotes1425 1.4.25 (2015-11-19) ReleaseNotes1424 1.4.24 (2015-4-24) ReleaseNotes1423 1.4.23 (2015-4-19) ReleaseNotes1422 1.4.22 (2014-12-31) ReleaseNotes1421 1.4.21 (2014-10-12) ReleaseNotes1420 1.4.20 (2014-5-11) ReleaseNotes1419 1.4.19 (2014-5-1) ReleaseNotes1418 1.4.18 (2014-4-17) ReleaseNotes1417 1.4.17 (2013-12-20) ReleaseNotes1416 1.4.16 (2013-12-9) ReleaseNotes1415 1.4.15 (2012-9-3) ReleaseNotes1414 1.4.14 (2012-7-30) ReleaseNotes1413 1.4.13 (2012-2-2) ReleaseNotes1412 1.4.12 (2012-2-1) ReleaseNotes1411 1.4.11 (2012-1-16) ReleaseNotes1410 1.4.10 (2011-11-9) ReleaseNotes149 1.4.9 (2011-10-18) ReleaseNotes148 1.4.8 (October 4th, 2011) ReleaseNotes147 1.4.7 (August 16th, 2011) ReleaseNotes146 1.4.6 (July 15th, 2011) ReleaseNotes145 1.4.5 (April 3rd, 2010) ReleaseNotes144 1.4.4 (November 26th 2009) ReleaseNotes143 1.4.3 (November 7th, 2009) ReleaseNotes142 1.4.2 (October 11th, 2009) ReleaseNotes141 1.4.1 (August 29th, 2009) ReleaseNotes140 1.4.0 (July 9th, 2009) Notes for Old Releases ReleaseNotes127 1.2.7 (April 3, 2009) ReleaseNotes128 1.2.8 (April 11, 2009) "},"title":"_index"},"/releasenotes/releasenotes127/":{"data":{"":"","#":"Memcached 1.2.7 Release Notes Date: 2009-04-03 Fri\nDownload Download link:\nhttp://memcached.org/files/old/memcached-1.2.7.tar.gz\nNotes With the release of memcached 1.2.7, the 1.2 tree is now officially in maintenance mode. Only bugfixes and very minor improvements will be added to the 1.2 tree. All development is now happening on the 1.3 tree. Efforts are now being made to stabilize the 1.3 tree into a 1.4 series stable release. Please help test :)\n1.2.7 appears to be a good, stable release, and is a decent farewell to the codebase that has helped scale many companies.\n-Dormando\nFeatures UDP/TCP can be disabled by setting their port to 0 Can set the listen backlog on the commandline (-b) Stats Handful of new stats.\n==== evicted_time ====\nUnder ‘stats items’, this lists the time since the last evicted object was last accessed. If an object was evicted a day after it had last been fetched, you would see 86400 as the time.\n==== other stats also noted in 1.3.3 ====\naccepting_conns listen_disabled_num cmd_flush other improvements also noted in 1.3.3 missing key debugging. tail repair. tail repair Tail repair is an important stability fix, and is worth repeating here.\nThere is a rare, unidentified reference leak that causes a slab to be full of invalid objects that cannot be evicted via the LRU nor will they expire on their own.\nTail repair is a strategy by which we forcefully evict objects that are marked as ``in-use’’ (that is, in-flight or otherwise being used), but haven’t been accessed in a long time (currently three hours).\nThere is an additional stat that comes along with this (tailrepairs on a slab) that will allow you to detect that this condition has occurred on one of your slabs.\nBugfixes use a dedicated accept/dispatch thread. prevent starvation by busy threads. startup crash fix under certain distros. better errors/warnings on the listen code. fix listen errors in odd setups (no network, ipv4 only, etc). ensure udp works in non-threaded mode. update CAS on incr/decr properly. incr/decr bugfixes. improved tests make ‘stats slabs’ used_checks report correctly Contributors The following people contributed to this release since 1.2.6. This is not a measure of the amount of effort per commit, just the total.\n18 dormando 11 Dustin Sallings 4 Brian Aker 1 Chris Goffinet 1 Evan Klitzke 1 Jonathan Bastien-Filiatrault 1 Ricky Zhou "},"title":"ReleaseNotes127"},"/releasenotes/releasenotes128/":{"data":{"":"","#":"Release Notes for 1.2.8 There were no release notes for 1.2.8, as it was a quick turnaround fix for an issue that had come up after 1.2.7.\nFrom the email announcement about 1.2.8:\nA few bugs were fixed that warranted an immediate release of memcached 1.2.8. If you are running memcached prior to 1.2.7, please skip 1.2.7 and upgrade straight to 1.2.8. Please note that the critical bug noted below only affects memcached binaries built with –enable-threads. While highly recommended, this is not the default in the 1.2 series. It is the default in 1.3.\n[http://groups.google.com/group/memcached/browse_thread/thread/ff96a9b88fb5d40e email about 1.2.8]"},"title":"ReleaseNotes128"},"/releasenotes/releasenotes132/":{"data":{"":"","#":"Memcached 1.3 Beta 2 Release Notes Date: 2009-03-11 Wed\nNew Features Binary Protocol A new feature that brings new features. We now have goodness like CAS-everywhere (e.g. delete), silent, but verifiable mutation commands, and many other wonders.\nNote that the original protocol is not deprecated. It will be supported indefinitely, although some new features may only be available in the binary protocol.\n==== Client Availability ===\nMany clients for the binary protocol are available.\nC\nlibmemcached supports just about anything you can do with a memcached protocol and is the foundation for many clients in many different languages (which you can find linked from the project page).\nProject page: http://tangent.org/552/libmemcached.html\nJava\nspymemcached has very good text and binary protocol support over IPv4 and IPv6 with a quite comprehensive test suite.\nProject page: http://code.google.com/p/spymemcached/\nProtocol Spec\nNIH problem? Go write your own client. :)\nhttp://cloud.github.com/downloads/dustin/memcached/protocol-binary.txt\nPerformance Lots of effort has gone into increasing performance.\nThere is no longer a build-time distinction between a single-threaded and multi-threaded memcached. If you want a single-threaded memcached, ask for one thread (though there’ll still be utility threads and other such things in the background). This change lets us focus on a future where multiple cores can be saturated for servicing requests.\nFacebook-inspired contention reduction with per-thread stat collection and the Facebook connection dispatch and thread starvation prevention contributions helped our scalability.\nLock analysis also showed us that we had quite a bit of contention on hash table expansion which has been moved into its own thread, greatly improving the scalability on multicore hardware.\nA variety of smaller things also shook out of performance testing and analysis.\nThere’s also a memory optimization for users who don’t actually make use of CAS. Running memcached with -C disables the use of CAS resulting in a savings of about eight bytes per item. If you have big caches, and don’t use CAS, this can lead to a considerable savings.\nStats There are several new stats and some new ways to look at older stats.\nNew Stats Delete\nThe global stats now contain statistics on deletion.\ndelete_hits refers to the number of times a deletion command was issued which resulted in a modification of the cache while delete_misses refers to the number of times a deletion command was issued which had no effect due to a key mismatch.\nIncr/Decr\nIncr and decr each have a pair of stats showing when a successful/unsuccessful incr occurred. incr_hits, incr_misses, decr_hits, and decr_misses show where such mutations worked and where they failed to find an existing object to mutate.\nCAS\nCAS stats are tracked in three different ways:\ncas_hits\nNumber of attempts to CAS in a new value that worked.\ncas_misses\nNumber of attempts to CAS in a value where the key was not found.\ncas_badval\nNumber of attempts to CAS in a value where the CAS failed due to the object changing between the gets and the update.\nslab class evicted time\nPer slab class, you can now see how recently accessed the most recent evicted data was. This is a useful gauge to determine eviction velocity on a slab so you can know whether evictions are healthy or if you’ve got a problem.\nMore Granular Stats Where possible, stats are now tracked individually by slab class. The following stats are available on a per-slab-class basis (via “stats slabs”):\nget_hits cmd_set delete_hits incr_hits decr_hits cas_hits cas_badval (misses are obviously not available as they refer to a non-existent item)\nRemoved stats “stats malloc” and “stats maps” have been removed.\nIf you depended on these commands for anything, please let us know so we can bring them back in a more maintainable way.\nBug Fixes Build fixes on ubuntu (gcc and icc) and FreeBSD bad interaction with cas + incr (bug 15) setuid failures are reported properly at daemonization time decr overflow causing unnecessary truncation to 0 (bug 21) failure to bind on Linux with no network (i.e. laptop dev) some memcached-tool cleanup Development Info We’ve added a bunch of tests and new code coverage reports.\nAll included code in this release has been tested against the following platforms (using the in-tree test suite):\nubuntu 8.10 (64-bit, both gcc and icc) ubuntu 8.04 (32-bit) OS X 10.5 (ppc and intel) OpenSolaris 5.11 x86 (with and without dtrace) FreeBSD 7 x86 Feedback Please try this version. Make it suffer. Report feedback to the list or file bugs as you find them.\nMailing List: [http://groups.google.com/group/memcached] Issue Tracker: [https://github.com/memcached/memcached/issues/list] IRC: #memcached on freenode Contributors The following people contributed to this release since 1.2.6.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.2.6..1.3.2 or use a web view.\nRepo list: [https://github.com/memcached/memcached/wiki/DevelopmentRepos] Web View: [http://github.com/dustin/memcached/commits/1.3.2] 104 Dustin Sallings 49 Trond Norbye 32 Toru Maesaka 31 dormando 8 Steve Yen 7 hachi 6 Aaron Stone 6 Brian Aker 4 Victor Kirkebo 2 Ricky Zhou 1 Jonathan Bastien-Filiatrault 1 Evan Klitzke 1 Eric Lambert "},"title":"ReleaseNotes132"},"/releasenotes/releasenotes133/":{"data":{"":"","#":"Memcached 1.3 Beta 3 Release Notes Date: 2009-04-03 Fri\nDownload Download link:\nhttp://memcached.org/files/old/memcached-1.3.3.tar.gz\nFeatures Can set listen backlog on the commandline. Prevent connection refused during connection storms at the cost of kernel memory.\nstats settings Show all current server settings (useful for troubleshooting as well as internal verification).\nBug fixes Alignment bug in binary stats (bug26) Occasional buffer overflow in stats (bug27) Try to recycle memory more aggressively. (bug14) incr validation (bug31) 64-bit incr/decr delta fixes (bug21) ascii UDP set (bug36) stats slabs’ used chunks (bug29) stats reset should reset item stats, eviction counters, etc… (bug22) Fix all stat buffer management Misc More tests More/better documentation Code cleanup Stable fixes from Dormando New Stats ==== accepting_conns ====\n1 or 0 to indicate whether the server is currently accepting connections or not.\nThe server will stop accepting connections when it has as many as it’s configured to take.\n==== listen_disabled_num ====\nThe number of times socket listeners were disabled due to hitting the connection limit.\n==== cmd_flush ====\nThe number of times the flush command was issued.\nmissing key debugging With verbosity enabled, you can see why objects were not found. In many cases, an item exists under a given key, but is considered invalid due to lazy expiration or flush.\ntail repair There is a rare, unidentified reference leak that causes a slab to be full of invalid objects that cannot be evicted via the LRU nor will they expire on their own.\nTail repair is a strategy by which we forcefully evict objects that are marked as ``in-use’’ (that is, in-flight or otherwise being used), but haven’t been accessed in a long time (currently three hours).\nThere is an additional stat that comes along with this (tailrepairs on a slab) that will allow you to detect that this condition has occurred on one of your slabs.\nsocket listen bugs There were some issues listening to sockets on machines with different network interface configurations (i.e. no network, only ipv4, only ipv6, etc…).\nContributors The following people contributed to this release since 1.3.2. Please refer to the 1.3.2 release notes for more info:\nReleaseNotes133\n28 Dustin Sallings 8 Trond Norbye 6 dormando 5 Brad Fitzpatrick 4 Steve Yen 1 Eric Lambert 1 Clinton Webb 1 Chris Goffinet "},"title":"ReleaseNotes133"},"/releasenotes/releasenotes140/":{"data":{"":"","#":"Memcached 1.4.0 Release Notes Date: Thu July 9, 2009\n1 Download Download Link:\nhttp://memcached.org/files/old/memcached-1.4.0.tar.gz\nNew Features Binary Protocol A new feature that brings new features. We now have goodness like CAS-everywhere (e.g. delete), silent, but verifiable mutation commands, and many other wonders.\nNote that the original protocol is not deprecated. It will be supported indefinitely, although some new features may only be available in the binary protocol.\n==== Client Availability ====\nMany clients for the binary protocol are available.\nC\nlibmemcached supports just about anything you can do with a memcached protocol and is the foundation for many clients in many different languages (which you can find linked from the project page).\nProject page: http://tangent.org/552/libmemcached.html\nJava\nspymemcached has very good text and binary protocol support over IPv4 and IPv6 with a quite comprehensive test suite.\nProject page: http://code.google.com/p/spymemcached/\nProtocol Spec\nNIH problem? Go write your own client. :)\nhttp://cloud.github.com/downloads/memcached/memcached/protocol-binary.txt\nPerformance Lots of effort has gone into increasing performance.\nThere is no longer a build-time distinction between a single-threaded and multi-threaded memcached. If you want a single-threaded memcached, ask for one thread (though there’ll still be utility threads and other such things in the background). This change lets us focus on a future where multiple cores can be saturated for servicing requests.\nFacebook-inspired contention reduction with per-thread stat collection and the Facebook connection dispatch and thread starvation prevention contributions helped our scalability.\nLock analysis also showed us that we had quite a bit of contention on hash table expansion which has been moved into its own thread, greatly improving the scalability on multicore hardware.\nA variety of smaller things also shook out of performance testing and analysis.\nThere’s also a memory optimization for users who don’t actually make use of CAS. Running memcached with -C disables the use of CAS resulting in a savings of about eight bytes per item. If you have big caches, and don’t use CAS, this can lead to a considerable savings.\nStats There are several new stats and some new ways to look at older stats.\n==== New Stats ====\nstats settings\nShow all current server settings (useful for troubleshooting as well as internal verification).\nDelete\nThe global stats now contain statistics on deletion.\ndelete_hits refers to the number of times a deletion command was issued which resulted in a modification of the cache while delete_misses refers to the number of times a deletion command was issued which had no effect due to a key mismatch.\nIncr/Decr\nIncr and decr each have a pair of stats showing when a successful/unsuccessful incr occurred. incr_hits, incr_misses, decr_hits, and decr_misses show where such mutations worked and where they failed to find an existing object to mutate.\nCAS\nCAS stats are tracked in three different ways:\ncas_hits\nNumber of attempts to CAS in a new value that worked.\ncas_misses\nNumber of attempts to CAS in a value where the key was not found.\ncas_badval\nNumber of attempts to CAS in a value where the CAS failed due to the object changing between the gets and the update.\nslab class evicted time\nPer slab class, you can now see how recently accessed the most recent evicted data was. This is a useful gauge to determine eviction velocity on a slab so you can know whether evictions are healthy or if you’ve got a problem.\nConnection yield counts\nThe -R option allows you to limit how many requests are handled in a single trip through the network state machine. The conn_yields stat reports how many times this has occurred.\nThis is most useful when you have very high rates of operations from a single client which seems to be hogging server resources unfairly, such as extremely large multi-get operations. We do not expect this to be a common situation, but this stat can help diagnose such issues if they should occur.\n==== More Granular Stats ====\nWhere possible, stats are now tracked individually by slab class. The following stats are available on a per-slab-class basis (via “stats slabs”):\nget_hits cmd_set delete_hits incr_hits decr_hits cas_hits cas_badval (misses are obviously not available as they refer to a non-existent item)\n==== Removed stats ====\n“stats malloc” and “stats maps” have been removed.\nIf you depended on these commands for anything, please let us know so we may suggest alternatives for you.\nMisc More tests More/better documentation Code cleanup Bug Fixes Build fixes on ubuntu (gcc and icc) and FreeBSD bad interaction with cas + incr (bug 15) setuid failures are reported properly at daemonization time decr overflow causing unnecessary truncation to 0 (bug 21) failure to bind on Linux with no network (i.e. laptop dev) some memcached-tool cleanup Alignment bug in binary stats (bug26) Occasional buffer overflow in stats (bug27) Try to recycle memory more aggressively. (bug14) incr validation (bug31) 64-bit incr/decr delta fixes (bug21) ascii UDP set (bug36) stats slabs’ used chunks (bug29) stats reset should reset item stats, eviction counters, etc… (bug22) Fix all stat buffer management Fixes for -R handling (bug61) GCC 4.4 fixes (bug60) Development Info We’ve added a bunch of tests and new code coverage reports.\nAll included code in this release has been tested against the following platforms (using the in-tree test suite):\nubuntu 8.10 (64-bit, both gcc and icc) ubuntu 8.04 (32-bit) ubuntu 9.10 (64-bit, gcc 4.4) OS X 10.5 (ppc and intel) OpenSolaris 5.11 x86 (with and without dtrace) Solaris 10 sparc (with and without dtrace) FreeBSD 7 x86 Feedback This version is considered a stable release and has been well-tested, but bugs are always possible. Report feedback to the list or file bugs as you find them.\nMailing List: http://groups.google.com/group/memcached Issue Tracker: https://github.com/memcached/memcached/issues/list IRC: #memcached on freenode Contributors The following people contributed to this release since 1.2.8.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.2.8..1.4.0 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.0 149 Dustin Sallings 61 Trond Norbye 33 Toru Maesaka 30 dormando 13 Steve Yen 7 hachi 6 Aaron Stone 5 Brad Fitzpatrick 4 Victor Kirkebo 3 Eric Lambert 2 Brian Aker 1 Chris Goffinet 1 Clinton Webb 1 Matt Ingenthron 1 Ricky Zhou 1 Evan Klitzke "},"title":"ReleaseNotes140"},"/releasenotes/releasenotes141/":{"data":{"":"","#":"Memcached 1.4.1 Release Notes Date: 2009-08-29 Sat\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.1.tar.gz\nOverview This is a maintenance release consisting primarily of bug fixes.\nFixes Criticial Fixes Boundary condition during pipelined decoding caused crash (bug72) Bad initialization during buffer realloc (bug77) Buffer overrun in stats_prefix_find (bug79) Memory corruption from negative and invalid item lengths (bug70) Non-critical Fixes Update flush stats for binary flushes (bug71) Build fixes for OpenBSD Build fixes for Solaris/gcc Cleanup warnings brought to us by OpenBSD (sprintf, etc…) Lots of fixes with the test tools Various documentation cleanups RPM spec autoupdate New Features stats slabs returns the number of requested bytes as mem_requested memcached can bind to ephemeral ports (used for testing) Contributors The following people contributed to this release since 1.4.0.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.0..1.4.1 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.1 18 Dustin Sallings 8 Trond Norbye 2 dormando 1 Mat Hostetter 1 Adam Thomason 1 Monty Taylor 1 Steve Yen 1 Matt Ingenthron 1 Cosimo Streppone 1 James Cohen "},"title":"ReleaseNotes141"},"/releasenotes/releasenotes1410/":{"data":{"":"","#":"Memcached 1.4.10 Release Notes Date: 2011-11-9\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.10.tar.gz\nOverview This release is focused on thread scalability and performance improvements. This release should be able to feed data back faster than any network card can support as of this writing.\nFixes Disable issue 140’s test. Push cache_lock deeper into item_alloc Use item partitioned lock for as much as possible Remove the depth search from item_alloc Move hash calls outside of cache_lock Use spinlocks for main cache lock Remove uncommon branch from asciiprot hot path Allow all tests to run as root New Features Performance For more details, read the commit messages from git. Each change was carefully researched to not increase memory requirements and to be safe from deadlocks. Each change was individually tested via mc-crusher (http://github.com/dormando/mc-crusher) to ensure benefits.\nTested improvements in speed between 3 and 6 worker threads (-t 3 to -t 6). More than -t 6 reduced speed.\nIn my tests, set was raised from 300k/s to around 930k/s. Key fetches/sec (multigets) from 1.6 million/s to around 3.7 million/s for a quadcore box. A machine with more cores was able to pull 6 million keys per second. Incr/Decr performance increased similar to set performance. Non-bulk tests were limited by the packet rate of localhost or the network card.\nMultiple NUMA nodes reduces performance (but not enough to really matter). If you want the absolute highest speed, as of this release you can run one instance per numa node (where n is your core count):\nOlder versions of memcached are plenty fast for just about all users. This changeset is to allow more flexibility in future feature additions, as well as improve memcached's overall latency on busy systems. Keep an eye on your hitrate and performance numbers. Please let us know immediately if you experience any regression from these changes. We have tried to be as thorough as possible in testing, but you never know. ### Contributors The following people contributed to this release since 1.4.9. Note that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it. Note that this is just a summary of how many changes each person made which doesn't necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of `git log 1.4.9..1.4.10` or use a web view. * Repo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos * Web View: http://github.com/memcached/memcached/commits/1.4.10 10\tdormando "},"title":"ReleaseNotes1410"},"/releasenotes/releasenotes1411/":{"data":{"":"","#":"Memcached 1.4.11 Release Notes Date: 2012-1-16\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.11.tar.gz\nOverview Memcached 1.4.11. Fixes race conditions and crashes introduced in 1.4.10. Adds the ability to rebalance and reassign slab memory.\nFixes bug237: Don’t compute incorrect argc for timedrun fix ‘age’ stat for stats items binary deletes were not ticking stats counters Fix a race condition from 1.4.10 on item_remove close some idiotic race conditions initial slab automover slab reassignment clean do_item_get logic a bit. fix race. clean up the do_item_alloc logic shorten lock for item allocation more Fix to build with cyrus sasl 2.1.25 New Features Slab page reassignment and bug fixes over 1.4.10.\nBug Fixes There were some race conditions and logic errors introduced in 1.4.10, they should be rare, but users are strongly encouraged to upgrade.\nSlab Reassign Long running instances of memcached may run into an issue where all available memory has been assigned to a specific slab class (say items of roughly size 100 bytes). Later the application starts storing more of its data into a different slab class (items around 200 bytes). Memcached could not use the 100 byte chunks to satisfy the 200 byte requests, and thus you would be able to store very few 200 byte items.\n1.4.11 introduces the ability to reassign slab pages. This is a beta feature and the commands may change for the next few releases, so please keep this in mind. When the commands are finalized they will be noted in the release notes.\nSlab reassignment can only be enabled at start time:\nOnce all memory has been assigned and used by items, you may use a command to reassign memory. ```$ echo \"slabs reassign 1 4\" | nc localhost 11211}}} That will return an error code indicating success, or a need to retry later. Success does not mean that the slab was moved, but that a background thread will attempt to move the memory as quickly as it can. #### Slab Automove While slab reassign is a manual feature, there is also the start of an automatic memory reassignment algorithm. ```$ memcached -o slab_reassign,slab_automove}}} The above enables it on startup. slab_automove requires slab_reassign first be enabled. automove itself may also be enabled or disabled at runtime: ```$ echo \"slabs automove 0\" | nc localhost 11211}}} The algorithm is slow and conservative. If a slab class is seen as having the highest eviction count 3 times 10 seconds apart, it will take a page from a slab class which has had zero evictions in the last 30 seconds and move the memory. There are lots of cases where this will not be sufficient, and we invite the community to help improve upon the algorithm. Included in the source directory is `scripts/mc_slab_mover`. See perldoc for more information: ```$ perldoc ./scripts/mc_slab_mover}}} It implements the same algorithm as built into memcached, and you may modify it to better suit your needs and improve on the script or port it to other languages. Please provide patches! #### Slab Reassign Implementation Slab page reassignment requires some tradeoffs: * All items larger than 500k (even if they're under 730k) take 1MB of space * When memory is reassigned, all items that were in the 1MB page are evicted * When slab reassign is enabled, an extra background thread is used The first item will be improved in later releases, and is avoided if you start memcached without the -o slab_reassign option. #### New Stats STAT slab_reassign_running 0 STAT slabs_moved 0\nslab_reassign_running indicates if the slab thread is attempting to move a page. It may need to wait for some memory to free up, so it could take several seconds. slabs_moved is simply a count of how many pages have been successfully moved. ### Contributors The following people contributed to this release since 1.4.10. Note that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it. Note that this is just a summary of how many changes each person made which doesn't necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of `git log 1.4.10..1.4.11` or use a web view. * Repo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos * Web View: http://github.com/memcached/memcached/commits/1.4.11 15\tdormando 1\tDustin Sallings 1\tSteve Wills "},"title":"ReleaseNotes1411"},"/releasenotes/releasenotes1412/":{"data":{"":"","#":"Memcached 1.4.12 Release Notes Date: 2012-2-1\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.12.tar.gz\nOverview Fix a small number of bugs, mostly in building on different platforms.\nFor the real meat, see [ReleaseNotes1411 1.4.11 Release Notes]\nFixes fix glitch with flush_all (exptime) Skip SASL tests unless RUN_SASL_TESTS is defined. Look around for saslpasswd2 (typically not in the user’s path). build fix: Define sasl_callback_ft on older versions of sasl. fix segfault when sending a zero byte command fix warning in UDP test properly detect GCC atomics tests: loop on short binary packet reads fix slabs_reassign tests on 32bit hosts New Features Fewer bugs!\nContributors The following people contributed to this release since 1.4.11.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.11..1.4.12 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.12 5\tDustin Sallings 5\tdormando "},"title":"ReleaseNotes1412"},"/releasenotes/releasenotes1413/":{"data":{"":"","#":"Memcached 1.4.13 Release Notes Date: 2012-2-2\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.13.tar.gz\nOverview Really tiny release with some important build fixes which were accidentally omitted from 1.4.12.\nFor the interesting meat see [ReleaseNotes1412] and [ReleaseNotes1411] especially, for slab memory reassignment!\nFixes Fix inline issue with older compilers (gcc 4.2.2) Better detection of sasl_callback_ft New Features Sigh.\nContributors The following people contributed to this release since 1.4.12.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.12..1.4.13 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.13 1\tDustin Sallings 1\tSteve Wills "},"title":"ReleaseNotes1413"},"/releasenotes/releasenotes1414/":{"data":{"":"","#":"Memcached 1.4.14 Release Notes Date: 2012-7-30\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.14.tar.gz\nOverview Fixes fix compile issue with new GCC’s Added support for automake-1.12 in autogen.sh Use Markdown for README. Fixed issue with invalid binary protocol touch command expiration time (https://github.com/memcached/memcached/issues/detail?id=275) Define touch command probe for DTrace support Error and exit if we don’t have hugetlb support (changes -L behavior) update reassign/automove documentation Remove USE_SYSTEM_MALLOC define slab rebalancing from random class split slab rebalance and automove threads pre-split slab pages into slab freelists Avoid race condition in test during pid creation by blind retrying New Features This release mainly features a number of small bugfixes, but also a change to slab rebalance behavior.\nPreviously, if you moved a slab page from one slab to another, you had to wait until that new page was fully used before moving another one. That wait has been removed, and you can move pages as fast as the system can … move them.\nA few new features as well:\nslabs reassign slabs reassign -1 15 will pick a page from any slab class and move it to class 15.\nslabs automove slabs automove 2 now enables an ultra aggressive page reassignment algorithm. On every eviction, it will try to move a slab page into that class. You should never run this in production unless you have a very, very good idea of what’s going to happen. For most people who have spurious evictions everywhere, you’ll end up mass evicting random data and hurting your hit rate. It can be useful to momentarily enable for emergency situations, or if you have a data access pattern where evictions should never happen.\nThis was work we were planning on doing already, but twitter’s rewrite has people presently interested in trying it out. You’ve been warned.\nContributors The following people contributed to this release since 1.4.13.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.13..1.4.14 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.14 18\tdormando 1\tClint Byrum 1\tEric McConville 1\tFordy 1\tMaksim Zhylinski 1\tToru Maesaka 1\tyuryur "},"title":"ReleaseNotes1414"},"/releasenotes/releasenotes1415/":{"data":{"":"","#":"Memcached 1.4.15 Release Notes Date: 2012-9-3\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.15.tar.gz\nOverview This is a somewhat experimental release which pushes thread performance even more than before. Since this is a more experimental release than usual, and contains no other major fixes or features, we urge some caution for important deployments. We feel as though it is high quality software, but please take caution and do slow rollouts or testing. Thanks!\nFixes Add some mild thread documentation README.md was missing from dist tarball Issue 286: –disable-coverage drops “-pthread” option Reduce odds of getting OOM errors in some odd cases New Features Thread scalability is much improved for reads, and somewhat improved for writes. In a pure read-only situation on a dual socket six core NUMA machine I’ve tested key fetch rates around 13.6 million keys per second.\nMore tuning is necessary and you’d get significant lag at that rate, but that shows the theoretical limit of the locks.\nContributors The following people contributed to this release since 1.4.14.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.14..1.4.15 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.15 6\tdormando 1\tTrond Norbye "},"title":"ReleaseNotes1415"},"/releasenotes/releasenotes1416/":{"data":{"":"","#":"Memcached 1.4.16 Release Notes Date: 2013-12-9\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.16.tar.gz\nOverview A quick bugfix release to get the tree moving again after a long absence. I don’t want to make too many changes at once, so here are a number of platform and crash fixes, as well as some introspection.\nIf you run 1.4.16 and experience any sort of memory leak or segfault/crash/hang, please contact us. Please do the following:\nBuild memcached 1.4.16 from the tarball. Run the “memcached-debug” binary that is generated at make time under a gdb instance Don’t forget to ignore SIGPIPE in gdb: “handle SIGPIPE nostop” Grab a backtrace “thread apply all bt” if it crashes and post it to the mailing list or otherwise hunt me down. Grab “stats”, “stats settings”, “stats slabs”, “stats items” from an instance that has been running for a while but hasn’t crashed yet. These crashes have been around too long and I would love to get rid of them soon.\nThanks!\nFixes Builds on OS X Mavericks (with clang) Add statistics for allocation failures Issue 294: Check for allocation failure Make tail leak expiry time configurable (-o tail_repair_time=60) Fix segfault on specially crafted packet. Close connection on update_event error while parsing new commands Don’t truncate maxbytes stat from ‘stats settings’ Add the “shutdown” command to the server. This allows for better automation fix enable-sasl-pwdb New Features Adjusting tail repair time: -o tail_repair_time=60 (in seconds)\n“tail repairs” are a failsafe within memcached where if a cache item is leaked via an unfixed or obscure bug, the item will be recycled anyway if it ends up at the bottom of the LRU and hasn’t been touched in a long period of time. Most releases do not have these bugs, but some have so we’ve left the mechanism in place. The default time before reaping is 3 hours. For a busy site that sucks. we’ve lowered the default to one hour, which is much longer than any object should ever take to download.\nIf you need dead items to be pulled more quickly, use this override. Make sure you don’t set it too low if you have clients which download items very slowly (unlikely, but eh).\nContributors The following people contributed to this release since 1.4.15.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.15..1.4.16 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.16 5\tTrond Norbye 4\tdormando 2\tBrian Aker 2\tEric McConville 1\tGabriel A. Samfira 1\tHuzaifa Sidhpurwala 1\tKenneth Steele 1\tKeyur 1\tWing Lian 1\tliu bo "},"title":"ReleaseNotes1416"},"/releasenotes/releasenotes1417/":{"data":{"":"","#":"Memcached 1.4.17 Release Notes Date: 2013-12-20\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.17.tar.gz\nOverview Another bugfix release along with some minor new features. Most notable is a potential fix for a crash bug that has plagued the last few versions. If you see crashes with memcached, please try this version and let us know if you still see crashes.\nThe other notable bug is a SASL authentication bypass glitch. If a client makes an invalid request with SASL credentials, it will initially fail. However if you issue a second request with bad SASL credentials, it will authenticate. This has now been fixed.\nIf you see crashes please try the following:\nBuild memcached 1.4.17 from the tarball. Run the “memcached-debug” binary that is generated at make time under a gdb instance Don’t forget to ignore SIGPIPE in gdb: “handle SIGPIPE nostop” Grab a backtrace “thread apply all bt” if it crashes and post it to the mailing list or otherwise hunt me down. Grab “stats”, “stats settings”, “stats slabs”, “stats items” from an instance that has been running for a while but hasn’t crashed yet. … and send as much as you can to the mailing list. If the data is sensitive to you, please contact dormando privately.\nFixes Fix potential segfault in incr/decr routine. Fix potential unbounded key prints (leading to crashes in logging code) Fix bug which allowed invalid SASL credentials to authenticate. Fix udp mode when listening on ipv6 addresses. Fix for incorrect length of initial value set via binary increment protocol. New Features Add linux accept4() support. Removes one syscall for each new tcp connection. scripts/memcached-tool gets “settings” and “sizes” commands. Add parameter (-F) to disable flush_all. Useful if you never want to be able to run a full cache flush on production instances. Contributors The following people contributed to this release since 1.4.16.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.16..1.4.17 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.17 6\tdormando 1\tAdam Szkoda 1\tAlex Leone 1\tAndrey Niakhaichyk 1\tDaniel Pañeda 1\tJeremy Sowden 1\tSimon Liu 1\tTomas Kalibera 1\ttheblop 1\t伊藤洋也 "},"title":"ReleaseNotes1417"},"/releasenotes/releasenotes1418/":{"data":{"":"","#":"Memcached 1.4.18 Release Notes Date: 2014-4-17\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.18.tar.gz\nOverview Fixes fix LRU contention for first minute of uptime This made some synthetic benchmarks look awful. Make hash table algorithm selectable Don’t lose item_size_max units in command line Add a “stats conns” command to show the states of open connections. Allow caller-specific error text in binary protocol Stop returning ASCII error messages to binary clients Fix reference leak in binary protocol “get” and “touch” handlers Fix reference leak in process_get_command() New Features Stats conns New “stats conns” command, which will show you what currently open connections are up to, how idle they’ve been, etc.\nStarttime Hash Algorithm Selection The jenkins hash was getting a little long in the tooth, and we might want to add specific hash algorithms for different platforms in the future. This makes it selectable in some sense. We’ve initially added murmur3 hash to the lineup and that seems to run a tiny bit faster in some tests.\n-o hash_algorithm=murmur3\nLRU Crawler A new background thread emerges! Currently experimental, so the syntax might change. If you run into bugs please let us know (though it’s been testing fine in torture tests so far).\nIf you wish to clean your slab classes of items which have been expired, either one-time or periodically, this will do it with low impact as a background operation.\nCurrently it requires kicking off a crawl via manual command:\nFirst, enable the thread: lru_crawler enable or use -o lru_crawler as a starttime option.\nlru_crawler crawl 1,3,5\n… would crawl slab classes 1,3,5 looking for expired items to add to the freelist.\nThis is generally not useful or required, unless you have memory with very mixed TTLs, you do not fetch items frequently enough or otherwise cause them to expire, and you don’t want items with longer TTLs block reclaiming expired items, or to be evicted early.\nFuture uses of the thread should allow examining and purging items via a plugin interface: IE crawl all items matching some string and remove them, or count them. It is simple to modify to experiment with as of now.\nSee doc/protocol.txt for full explanation of related commands and counters.\nContributors The following people contributed to this release since 1.4.17.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.17..1.4.18 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.18 21\tdormando 8\tSteven Grimm 1\tAndrew Glinskiy "},"title":"ReleaseNotes1418"},"/releasenotes/releasenotes1419/":{"data":{"":"","#":"Memcached 1.4.19 Release Notes Date: 2014-5-1\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.19.tar.gz\nOverview Fixes Fix endianness detection during configure. Fixes a performance regression with binary protocol (up to 20%) Fix rare segfault in incr/decr. disable tail_repair_time by default. Likely not needed anymore, and can rarely cause bugs. use the right hashpower for the item_locks table. Small perf improvement. Fix crash for LRU crawler while using lock elision (haswell+ processors) New Features See the release notes for 1.4.18 for recent interesting features.\nContributors The following people contributed to this release since 1.4.18.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.18..1.4.19 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.19 9\tdormando 1\tDagobert Michelsen 1\tEric McConville "},"title":"ReleaseNotes1419"},"/releasenotes/releasenotes142/":{"data":{"":"","#":"Memcached 1.4.2 Release Notes Date: 2009-10-11 Sun\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.2.tar.gz\nOverview This is a maintenance release consisting primarily of bug fixes.\nFixes Critical Fixes Reject keys larger than 250 bytes in the binary protocol (bug94) Bounds checking on stats cachedump (bug92) Binary protocol set+cas wasn’t returning a new cas ID (bug87) Non-critical Fixes Binary quitq didn’t actually close the connection (bug84) Build fix on CentOS 5 (bug88) Slab boundary checking cleanup (bad logic in unreachable code) Removed some internal redundancies. Use the OS’s provided htonll/ntohll if present (bug83) Test fixes/cleanup/additions. Get hit memory optimizations (bug89) Disallow -t options that cause the server to not work (bug91) memcached -vv now shows the final slab Killed off incomplete slab rebalance feature. Better warnings. More consistent verbosity in binary and ascii (bug93) New Features Support for libhugetlbfs (in Linux) From http://libhugetlbfs.ozlabs.org/ -\nlibhugetlbfs is a library which provides easy access to huge pages of memory. It is a wrapper for the hugetlbfs file system. If you are running memcached with a very large heap in Linux, this change will make it available to you. The hugetlbfs HOWTO provides detailed information on how to configure your Linux system and provide advice to applications (such as memcached) to make use of it.\nSupport for evictions, evict_time and OOM counts in memcached-tool memcached-tool is a commandline tool to display information about your server. It displays more now.\nConfigurable maximum item size Many people have asked for memcached to be able to store items larger than 1MB, while it’s generally recommended that one not do this, it is now supported on the commandline.\nA few enlightened folk have also asked for memcached to reduce the maximum item size. That is also an option.\nThe new -I parameter allows you to specify the maximum item size at runtime. It supports a unit postfix to allow for natural expression of item size.\nExamples:\nmemcached -I 128k # Refuse items larger than 128k. memcached -I 10m # Allow objects up to 10MB New stat: ’evicted_nonzero' The evicted_nonzero stat is a counter of all of the evictions for items that had an expiration time greater than zero.\nThis can be used to help distinguish “healthy” evictions from “unhealthy” ones. If all of your evictions are for objects with no expiration, then they’re naturally falling off the LRU as opposed to being evicted before their maximum expiry that was set at item store time.\nProtocol definitions for range protocol memcached ships with a binary protocol header that can be used when implementing your own protocol parsers and generators. The structure definitions and opcodes for the range specification are included in this header.\nNote that the server does not support these operations.\nContributors The following people contributed to this release since 1.4.1.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.1..1.4.2 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.2 12 Dustin Sallings 10 Trond Norbye 9 dormando 1 Vladimir 1 Ryan Tomayko 1 Mat Hostetter 1 Jonathan Steinert 1 Dmitry Isaykin "},"title":"ReleaseNotes142"},"/releasenotes/releasenotes1420/":{"data":{"":"","#":"Memcached 1.4.20 Release Notes Date: 2014-5-11\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.20.tar.gz\nOverview Just one tiny change to fix a regression causing threads to lock up and spin max CPU.\n1.4.18 and 1.4.19 were affected. 1.4.17 and earlier were not affected. If you are on .18 or .19 an upgrade to 1.4.20 is strongly advised.\nThanks to commando.io for reporting the bug initially and putting up with me being blind for a few weeks.\nFixes Fix a race condition causing new connections to appear closed, causing an inifinte loop. New Features None, see 1.4.18 for new interesting features, or 1.4.19 for other useful bugfixes.\nContributors The following people contributed to this release since 1.4.19.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.19..1.4.20 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.20 1\tdormando "},"title":"ReleaseNotes1420"},"/releasenotes/releasenotes1421/":{"data":{"":"","#":"Memcached 1.4.21 Release Notes Date: 2014-10-12\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.21.tar.gz\nOverview Fixes makefile cleanups Avoid OOM errors when locked items stuck in tail If clients occasionally fetch many items, more than can fit the TCP buffers, then hang for a very long period of time, that slab class could OOM. In older versions this could cause a crash. Since 1.4.20 this will cause OOM errors.\nNow, if a locked item lands in the LRU tail, it will be bumped back to the head and an lrutail_reflocked counter incremented. If you’re concerned about having stuck clients, watch that counter.\nBig thanks to Jay Grizzard et all at Box for helping track this down!\nNew Features None.\nContributors The following people contributed to this release since 1.4.20.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.20..1.4.21 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.21 4\tSteve Wills 3\tdormando 1\tJay Grizzard "},"title":"ReleaseNotes1421"},"/releasenotes/releasenotes1422/":{"data":{"":"","#":"Memcached 1.4.22 Release Notes Date: 2014-12-31\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.22.tar.gz\nOverview Bugfix maintenance release. Fixes to hash table expansion now completely hang all threads very briefly while the hash table pointers are swapped. Once swapped, it unlocks and uses locks as normal.\nIn previous versions, the hash table was switched to a global lock instead of a map of bucket-locks during expansion. This should be faster overall with a small latency penalty. It’s possible to presize the hash table with -o hashpower\nFixes gatkq: return key in response Handle SIGTERM the same as SIGINT Fix off-by-one causing segfault in lru_crawler Fix potential corruption for incr/decr of 0b items Fix issue #369 - uninitialized stats_lock issue#370: slab re-balance is not thread-safe in function do_item_get Fix potential corruption in hash table expansion use item lock instead of global lock when hash expanding fix hang when lru crawler started from commandline rename thread_init to avoid runtime failure on AIX Support -V (version option) New Features Contributors The following people contributed to this release since 1.4.21.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.21..1.4.22 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.22 6\tdormando 2\tJason CHAN 1\tDan McGee 1\tMenghan 1\tMike Dillon 1\tOskari Saarenmaa 1\tclark.kang 1\tmckelvin "},"title":"ReleaseNotes1422"},"/releasenotes/releasenotes1423/":{"data":{"":"","#":"Memcached 1.4.23 Release Notes Date: 2015-4-19\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.23.tar.gz\nOverview Major new release with a complete overhaul of the LRU system. Potentially huge benefits in memory efficiency are possible if the new features are enabled. By default the code should behave similar to how it did in all previous versions, though locking is improved and the new code is still used in some ways.\nPlease read the feature notes carefully and try it out!\nReal world examples have shown huge memory efficiency increases when using items of mixed TTL’s (some short, some long). When all items have unlimited TTLs, hit ratios have still improved by several percent.\nFixes spinlocks removed since they never seem to improve performance. flush_all was not thread safe. better handle items refcounted in tail by unlinking them from the LRU’s New Features This release is a reworking of memcached’s core LRU algorithm.\nglobal cache_lock is gone, LRU’s are now independently locked. LRU’s are now split between HOT, WARM, and COLD LRU’s. New items enter the HOT LRU. LRU updates only happen as items reach the bottom of an LRU. If active in HOT, stay in HOT, if active in WARM, stay in WARM. If active in COLD, move to WARM. HOT/WARM each capped at 32% of memory available for that slab class. COLD is uncapped. Items flow from HOT/WARM into COLD. A background thread exists which shuffles items between/within the LRU’s as capacities are reached. The primary goal is to better protect active items from “scanning”. items which are never hit again will flow from HOT, through COLD, and out the bottom. Items occasionally active (reaching COLD, but being hit before eviction), move to WARM. There they can stay relatively protected.\nA secondary goal is to improve latency. The LRU locks are no longer used on item reads, only during sets and from the background thread. Also the background thread is likely to find expired items and release them back to the slab class asynchronously, which speeds up new allocations. Further work on the thread should improve this.\nThere are a number of new statistics to monitor this. Mainly you’ll just want to judge your hit ratio before/after, as well as any potential latency issues.\nTo enable: start with -o lru_maintainer,lru_crawler\nTo adjust percentage of memory reserved for HOT or WARM LRU’s (default to 32% each): -o lru_maintainer,lru_crawler,hot_lru_pct=32,warm_lru_pct=32\nA recommended start line: -o lru_maintainer,lru_crawler,hash_algorithm=murmur3\nAn extra option: -o expirezero_does_not_evict (when used with lru_maintainer) will make items with an expiration time of 0 unevictable. Take caution as this will crowd out memory available for other evictable items.\nSome caveats exist:\nSome possible tunables are currently hardcoded. Max number of slab classes is now 62, instead of 200. The default slab factor gives 42 classes. This is loosely inspired by the 2Q algorithm. More specifically the OpenBSD variant of it: http://www.tedunangst.com/flak/post/2Q-buffer-cache-algorithm\nIt’s then extended to cope with the fact that memcached items do not behave the same way as a buffer pool. TTL’s mean extra scanning/shuffling is done to improve memory efficiency for valid items.\nContributors The following people contributed to this release since 1.4.22.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.22..1.4.23 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.23 31\tdormando "},"title":"ReleaseNotes1423"},"/releasenotes/releasenotes1424/":{"data":{"":"","#":"Memcached 1.4.24 Release Notes Date: 2015-4-25\nDownload Download Link:\nhttp://www.memcached.org/files/memcached-1.4.24.tar.gz\nOverview Bugfix release to replace 1.4.23. If you tried 1.4.23, please try this version instead. I apologize for any frustrations from the .23 release. If you see further issues, please report them quickly and we will look into them.\nFixes relax timing glitch in the lru maintainer test fix major off by one issue New Features Please see: https://code.google.com/p/memcached/wiki/ReleaseNotes1423 for the changes new to 1.4.23, as they were significant.\nContributors The following people contributed to this release since 1.4.23.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.23..1.4.24 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.24 3\tdormando "},"title":"ReleaseNotes1424"},"/releasenotes/releasenotes1425/":{"data":{"":"","#":"Memcached 1.4.25 Release Notes Date: 2015-11-19\nDownload http://www.memcached.org/files/memcached-1.4.25.tar.gz\nOverview Many small fixes from internal and public pull requests/bug reports have gone into this release. Thanks to all of those who contribute.\nA large change to slab class rebalancing has gone into this release. Please read carefully below and try the new options, as they may improve your memory efficiency and hit ratio. Especially for long running instances.\nFixes Automake improvements Misc documentation fixes Misc updates to startup scripts lru_crawler enable blocks until ready (test failure) Record and report on time spent in listen_disabled (time_in_listen_disabled_us) Update manpage for -I command. Make it more clear Fix display of settings.hot_lru_pct in stats settings No longer edits the output of ps while processing arguments No longer crashes when failing to give arguments to some start args Fix memcached unable to bind to an ipv6 address No longer attempts bind to same interface more than once fixed libevent version check: add the missing 1.0.x version check fix off-by-one in LRU crawler, causing rare segfault remove another invalid assert(), fixes clang and pedantic compilation New Features Slab automover has gotten a very large update. The wider discussion can be found in the pull request.\nAs data is stored into memcached, it pre-allocates pages of memory into slab classes of a particular size (ie: 90 bytes, 120 bytes). If you fill your cache with 90 byte objects, and then start writing 120 byte objects, there will be much less space available for 120 byte objects.\nWith the slab automover improvements, freed memory can be reclaimed back into a global pool and reassigned to new slab classes. You can also still manually move slab pages between classes with your own external process if the automover does not fit your needs (see doc/protocol.txt for full details).\nThe automover now attempts to rescue items which are still valid when moving a page from one class to another, or from one class into the global page pool. This makes it much less destructive.\nTo get all of the benefits of the last few releases, we recommend adding the following startup options:\n-o slab_reassign,slab_automove,lru_crawler,lru_maintainer\nA modern start line includes a few other items:\n-o slab_reassign,slab_automove,lru_crawler,lru_maintainer,maxconns_fast,hash_algorithm=murmur3\nMany of these options are likely to become defaults in the future.\nContributors The following people contributed to this release since 1.4.24.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.24..1.4.25 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.25 20\tdormando 3\tCameron Norman 3\tMiroslav Lichvar 2\tAntony Dovgal 1\tAlwayswithme 1\tIan Miell 1\tJohan Bergström 1\tMattias Geniar 1\tRoman Mueller 1\tSaman Barghi 1\tSharif Nassar 1\tYongyue Sun 1\tgithublvv 1\tkenvifire 1\tmdl 1\twangkang-xy 1\tzhoutai "},"title":"ReleaseNotes1425"},"/releasenotes/releasenotes1426/":{"data":{"":"","#":"Memcached 1.4.26 Release Notes Date: 2016-6-17\nDownload https://www.memcached.org/files/memcached-1.4.26.tar.gz\nOverview The usual routine of small fixes comes with the first pass of a big new feature: on-demand live logging! If you’ve ever reached for stats cachedump, you’ll be much better served by this feature. See below for details.\nFixes bump some global stats to 64bit uints (total_connections) sanity check for maximum connections setting get_expired stats make cachedump print 0exp for noexpire items compilation fixes for GNU/Hurd fix building of binary documentation files. document negative expiration values fix build with musl libc New Features There is now a -o modern option which combines all of the new recommended features. In the previous release, it was recommended that memcached be started with:\n-o slab_reassign,slab_automove,lru_crawler,lru_maintainer,maxconns_fast,hash_algorithm=murmur3\n… to get the benefit of new features. These will become the default soon. In the meantime a shorthand of -o modern can be used which will act like the above line, and include new recommended defaults ahead of them becoming actual defaults. Memcached has always been treated extremely conservatively so this tries to be as safe as possible.\nLogging! $ telnet localhost 11211 Trying 127.0.0.1... Connected to localhost. Escape character is '^]'. watch fetchers OK Connect again:\n$ telnet localhost 11211 Trying 127.0.0.1... Connected to localhost. Escape character is '^]'. get foo END First connection will output:\nts=1466120156.99667 gid=1 type=item_get key=foo status=not_found watch evictions can show details about evicted items:\nts=1466120156.304163 gid=57180 type=eviction key=n%2Cfoo1539 fetch=no ttl=-1 la=0 (ttl: time remaining before expiration. la: last access time. fetch: whether or not it was ever read)\nIn this release fetchers mutations and evictions are supported. You can mix and match on a connection:\nwatch fetchers mutations evictions\nLogs will continue to emit until the watcher disconnects. If the watcher gets behind on reading data, log lines will be dropped (and a notice appended when it resumes).\nLogs are collected asynchronously. A background thread renders and writes to clients. This should reduce the latency and max CPU overhead of using the logs. If no watchers are active, logs aren’t generated at all.\nLogs are potentially received out of order. Re-order by the gid= option if this is important.\nKeys are represented by “URI Encoding”. Most ASCII keys are unaffected, but some characters will be replaced by %NN equivalents.\nThe initial fetchers/mutations code are monitoring internal key fetches and stores. This means a “set” command runs first a get and then a store, showing two log lines. A multiget will emit one log line per key.\nFurther code cleanups and more logging endpoints are scheduled for future releases. There’s also a potential for modular log formats. Let us know what’s important for you!\nSee the pull request for full detail.\nContributors The following people contributed to this release since 1.4.25.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.25..1.4.26 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.26 23\tdormando 4\tGuillaume Delacour 3\tsergiocarlos 2\t祁冰 1\tCaleb Shay 1\tMatt Fowles Kulukundis 1\tNatanael Copa 1\thiracy 1\tmeteorgan "},"title":"ReleaseNotes1426"},"/releasenotes/releasenotes1427/":{"data":{"":"","#":"Memcached 1.4.27 Release Notes Date: 2016-6-24\nDownload http://www.memcached.org/files/memcached-1.4.27.tar.gz\nOverview Fix some compile and flaky test issues with 1.4.26. Adds several new features and fixes.\nFixes treat and print item flags as unsigned int\nmake watcher test less flaky.\nindent fixes in thread_libevent_process to make future changes easier\nfix solaris compiler warning in bipbuffer.c\nadd #include \u003cstdio.h\u003e to fix error: implicit declaration of function ‘snprintf’ on centos\nchange LRU crawler fprintf to use %u format instead of %d\nadd -o watcher_logbuf_size=N worker_logbuf_size=N\nYou don’t need this last one unless you’re writing tests or need to carefully tune the logger to avoid skipped or dropped lines.\nNew Features memcached idle connection killer (https://github.com/memcached/memcached/pull/80) If specifying -o idle_timeout=s where s is seconds, connected clients idle for at least that long will be asked to close. Defaulted to off, but could be useful if you tend to have clients that go out to lunch and never come back.\nThanks to Jay Grizzard for this feature!\ncache_memlimit command for tuning runtime maxbytes (https://github.com/memcached/memcached/pull/170) Finally! You can now dynamically increase the amount of memory available to memcached without having to restart it. If -o modern is in use (slab rebalancer enabled), it can be told to free memory back to the system by lowering the memory limit.\nA big caveat is that it’s up to the OS as to if the memory can be returned to the OS, or if it stays in the application heap. Do careful testing before relying on being able to free memory.\nonline hang-free “stats sizes” command. allow manually specifying slab class sizes (https://github.com/memcached/memcached/pull/169) These two features are part of the one pull request. The stats sizes command would hang one of the worker threads while iterating all of your items.\nNow, the process is dynamic, tallying sizes as items are added to or removed from the cache. It must be enabled at starttime via -o track_sizes, or dynamically via stats sizes_enable and stats sizes_disable ascii commands.\nIf you have item sizes that are very static, or align very poorly by using the -f feature, you can now specify the exact sizes of the slab classes via commands like -o slab_sizes=100-200-300-400-500.\nContributors The following people contributed to this release since 1.4.26.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.26..1.4.27 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.27 9\tdormando 2\tJay Grizzard 1\tMathieu CARBONNEAUX 1\tRyan McCullagh "},"title":"ReleaseNotes1427"},"/releasenotes/releasenotes1428/":{"data":{"":"","#":"Memcached 1.4.28 Release Notes Date: 2016-7-1\nDownload http://www.memcached.org/files/memcached-1.4.28.tar.gz\nOverview Bugfix release. Thanks to everyone who tested!\nWhile good progress has been made on a new feature, it’s getting some more burn-in time and this fix/cleanup release is happening in the meantime.\nFixes systemd init script hardening hardening make watcher.t be even less flaky. don’t fail on systems without 64bit atomics small code refactor of logger clean up global stats code a little. add get_flushed counter, fix expired_unfetched Fix undefined behavior in vlen check New Features None. Several new features have been added in 1.4.26 and 1.4.27, please refer to those release notes.\nContributors The following people contributed to this release since 1.4.27.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.27..1.4.28 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.28 7\tdormando 2\tCraig Andrews 1\tJ. Grizzard 1\tPaul Lindner "},"title":"ReleaseNotes1428"},"/releasenotes/releasenotes1429/":{"data":{"":"","#":"Memcached 1.4.29 Release Notes Date: 2016-7-13\nDownload http://www.memcached.org/files/memcached-1.4.29.tar.gz\nOverview Improved support for large items over the 1 megabyte default. Also includes a handful of features.\nLarge items now have much better memory efficiency, and can get very large (potentially hundreds of megabytes) safely.\nTo make use of the new feature, simply use the -I option as before, IE:\n-I 2m\nMany thanks to https://www.packet.net/ for providing high speed baremetal hardware which was used for performance and burn-in testing of this new feature.\nFixes fix items with a “0” hash result from failing to evict sometimes. allow cachedump’ing of slab 63. fix flakiness of slabs-reassign2.t test. Fix ancient binprot bug with sets resulting in OOM errors desycning the protocol. New Features After over a decade of having an item size target of a single megabyte, items can now safely raise above that. Up to hundreds of megabytes, potentially.\nThis feature automatically enables if you raise the item size limit above 1mb. IE: -I 2m.\nYou can also enable it manually with a limit of 1mb (the default of -I 1m) or less (like -I 512k) by setting -o slab_chunk_max=16384 (16384 is the recommended default).\nFull details in the pull request: https://github.com/memcached/memcached/pull/181\nIn summary:\nMemcached uses a slab allocator, which splits up memory into chunks of specific sizes. The “item size limit” has always been the largest possible slab chunk. Increasing the size limit thus spreads out available slab classes, reducing memory efficiency. Now:\nThe maximum slab chunk size is no longer tied to the maximum item size. Items larger than the slab chunk size now comprise of multiple chunks of the largest size. Benefits:\nWith a smaller maximum chunk size, the slab classes for small items are now more fine grained raising memory efficiency. Items that approach 1mb can waste more memory as the classes are far apart. Chaining items together can help a lot here. Performance should be good, as small items are still 1:1 and large items soak more bandwidth, allowing extra room for a very small amount of CPU overhead. Current caveats:\nThe system has always been able to store an item after evicting exactly one item. This is no longer the case for large items. If you mix very large items (say 5 megabyte), with many small-ish items (say 100k), with a slab chunk max of 16k, memcached may return more OOM errors than normal while attempting to free enough space to store a new 5 megabyte item. With a slab chunk max of 16k, an item that requires 16k + 1 byte of memory will use 32k of memory. The larger the item the less effective overhead this has, but at the smaller levels it can lead to problems. Simply leave settings at their defaults or raise the slab_chunk_max if you run into this. There be dragons if you attempt to store multiple gigabyte items. The item size attributes are 32bit. These issues should improve in future releases after some refactoring. IE: It should be possible to comprise a chunked item of more than one chunk size, alleviating the last-chunk inefficiency.\nTo get the most out of this feature, we again recommend you start memcached with -o modern, or many of its new defaults. This allows it to reassign memory as necessary and improves the LRU algorithm significantly.\nContributors The following people contributed to this release since 1.4.28.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.28..1.4.29 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.29 17\tdormando 1\tDavid Oliveira 1\tEiichi Tsukata "},"title":"ReleaseNotes1429"},"/releasenotes/releasenotes143/":{"data":{"":"","#":"Memcached 1.4.3 Release Notes Date: 2009-11-07 Sat\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.3.tar.gz\nOverview This is a maintenance release of memcached featuring mostly bug fixes and one new feature.\nRC history rc2 fixes a multiget bug that showed up in rc1. A bug was not filed, but it was found and patched at roughly the same time.\nFixes Critical Fixes Malicious input can crash server. bug102 Non-critical Fixes Removed special case in slab sizing for factor 2. bug56 Provide better errors for deletion scenarios. bug3 Fix get stats accounting. bug104 Ignore stats prefix for keys without a delimiter. bug96 Work around rpm’s broken concept of versions more. bug98 Use slab class growth factor limit. bug57 Added LSB section to init script. bug54 Documentation fixes Various build fixes Itemized List of Bugs Closed If a bug shows up in this list that wasn’t specifically mentioned above, it’s either too minor to mention specifically or the bug was closed by introducing a test that proves that the bug, as described, does not exist.\nbug3 bug54 bug56 bug57 bug62 bug67 bug68 bug69 bug96 bug97 bug98 bug101 bug102 bug104 New Features Support for SASL Authentication Some installations of memcached are not in controlled environments where simple network filtering keeps bad guys out of your stuff. To help with those other environments, we’ve introduced SASL support. You can read more about it here:\nhttps://github.com/memcached/memcached/wiki/SASLHowto\nNew perl tool damemtop in scripts/ dormando’s awesome memcached top - a new commandline perl tool for monitoring small to large memcached clusters. Supports monitoring arbitrary statistics. See scripts/README.damemtop for more information.\nThis tool is intended to replace memcached-tool, but not yet.\nAlso Noteworthy, Slab Optimizations Objects on the larger end of the limit should be generally more memory efficient now as more slabs are created (thus are more granular).\nContributors The following people contributed to this release since 1.4.2.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.2..1.4.3 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.3 15 Dustin Sallings 10 Trond Norbye 5 dormando 2 Colin Pitrat 1 Monty Taylor 1 Chang Song 1 CaptTofu 1 Tomash Brechko "},"title":"ReleaseNotes143"},"/releasenotes/releasenotes1430/":{"data":{"":"","#":"Memcached 1.4.30 Release Notes Date: 2016-8-11\nDownload http://www.memcached.org/files/memcached-1.4.30.tar.gz\nOverview Bugfix release, with a critical fix to large item support.\nFixes Add MemoryDenyWriteExecute to the systemd service Handle end of line comment on memcached.conf Add missing parameters and escape hypens as minus to manpage Modernize unit file in systemd crawler now uses rate limiter sleeps properly (CPU overusage) add slab_chunk_max to stats settings Importantly:\nfix over-allocating with large item support. If you set -I 2m, memcached was allocating 2 megabytes of memory per page, then only using 1mb. This would lead to it hitting the malloc limit with only 50% of the memory available before. This gets worse the more distant -I is from 1MB.\nIf you are still seeing issues with memory efficiency with large item support (-I set higher than 1m default), try the startup setting: -o slab_chunk_max=524288 Most workloads will function fine, and it should nearly always be better than how memory efficiency worked prior to the new feature (when using large items).\nNew Features Contributors The following people contributed to this release since 1.4.29.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.29..1.4.30 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.30 6\tdormando 2\tGuillaume Delacour 1\tCraig Andrews 1\tRemi Collet "},"title":"ReleaseNotes1430"},"/releasenotes/releasenotes1431/":{"data":{"":"","#":"Memcached 1.4.31 Release Notes Date: 2016-8-19\nDownload http://www.memcached.org/files/memcached-1.4.31.tar.gz\nOverview Big new feature: lru_crawler metadump all, will now dump (most of) the metadata for (all of) the items in the cache. As opposed to cachedump, it does not cause severe performance problems and has no limits on the amount of keys that can be dumped.\nFixes More fixes for defaults related to large item support. Several improvements to how the LRU crawler’s default background job is launched. Should be less aggressive. Fix LRU crawler rate limiting sleep never actually being used. New Features If -o modern is in use (or at least -o lru_crawler), a new command is usable: lru_crawler metadump [all|1|2|3]. You may dump all of the metadata for a particular slab class, a list of slab classes, or all slab classes.\nThis is useful for inspection, pulling cache data from one server to another, etc.\nThis is not a way to replicate a cache: it is an inconsistent non-multiversioned grab of the key storage. It makes a best effort to not include duplicates but a small number can happen on busy servers.\nMany thanks for Netflix, for sponsoring and patiently testing the work done in this release!\nMore details and code can be seen in the PR: https://github.com/memcached/memcached/pull/193\nContributors The following people contributed to this release since 1.4.30.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.30..1.4.31 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.31 14\tdormando "},"title":"ReleaseNotes1431"},"/releasenotes/releasenotes1432/":{"data":{"":"","#":"Memcached 1.4.32 Release Notes Date: 2016-10-12\nDownload http://www.memcached.org/files/memcached-1.4.32.tar.gz\nOverview Bugfix release. One important bug introduced in 1.4.29 could cause OOM errors if you have many items with keys longer than the data.\nFixes fix missing evicted_time display in stats output Update old ChangeLog note to visit Github wiki fix OOM errors with newer LRU Misc typo fixes New Features None this time!\nContributors The following people contributed to this release since 1.4.31.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.31..1.4.32 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.32 4\tdormando 1\tAdam Chainz 1\tGiovanni Bechis 1\takisssa "},"title":"ReleaseNotes1432"},"/releasenotes/releasenotes1433/":{"data":{"":"","#":"Memcached 1.4.33 Release Notes Date: 2016-10-31\nDownload http://www.memcached.org/files/memcached-1.4.33.tar.gz\nOverview Serious remote code execution bugs are fixed in this release.\nThe bugs are related to the binary protocol as well as SASL authentication of the binary protocol.\nIf you do not use the binary protocol at all, a workaround is to start memcached with -B ascii - otherwise you will need the patch in this release.\nThe diff may apply cleanly to older versions as the affected code has not changed in a long time.\nFull details of the issue may be found here: http://blog.talosintel.com/2016/10/memcached-vulnerabilities.html\nFixes CVE reported by cisco talos New Features None. Contributors The following people contributed to this release since 1.4.32.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.32..1.4.33 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.33 1\tdormando "},"title":"ReleaseNotes1433"},"/releasenotes/releasenotes1434/":{"data":{"":"","#":"Memcached 1.4.34 Release Notes Date: 2017-1-7\nDownload http://www.memcached.org/files/memcached-1.4.34.tar.gz\nOverview Larger than average bugfix release. :) Important fix for users of SASL authentication.\nFixes Add -o modern switches to -h metadump: Fix preventing dumping of class 63 Fix cache_memlimit bug for \u003e 4G values metadump: ensure buffer is flushed to client before finishing Number of small fixes/additions to new logging add logging endpoint for LRU crawler evicted_active counter for LRU maintainer stop pushing NULL byte into watcher stream Scale item hash locks more with more worker threads (minor performance) Further increase systemd service hardening Missing necessary header for atomic_inc_64_nv() used in logger.c (solaris) Fix print format for idle timeout thread Improve binary sasl security fixes Fix clang compile error Widen systemd caps to allow maxconns to increase Add -X option to disable cachedump/metadump Don’t double free in lru_crawler on closed clients Fix segfault if metadump client goes away New Features None\nContributors The following people contributed to this release since 1.4.33.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.33..1.4.34 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.34 21\tdormando 1\tAlexander Pyhalov 1\tCraig Andrews 1\tNick "},"title":"ReleaseNotes1434"},"/releasenotes/releasenotes1435/":{"data":{"":"","#":"Memcached 1.4.35 Release Notes Date: 2017-2-26\nDownload http://www.memcached.org/files/memcached-1.4.35.tar.gz\nOverview Significant fixes to new LRU algorithm. Also performance and memory overhead improvements. You are even more likely to see improved hit ratios when using -o modern. Please try it out!\nLooking for contributors! The relevant wiki has been updated: https://github.com/memcached/memcached/wiki/DevelopmentRepos\nIf you use memcached, please consider helping out! Much appreciation to those who already do.\nThis version is getting close to what I envision 1.5.0 will be. The plan for 1.5.0 (as of this writing) is to simply switch the defaults to what is reflected in -o modern, no or minimal other changes will be included in that release.\nTo prepare yourself for the 1.5.0 release, again please try one instance with -o modern options.\nFixes init.d script status check routine Print with more-restricted format string to fix compiler warning with gcc 7’s -Wformat-truncation. Display HOT/WARM tail age in stats items Active items in HOT` flow to WARM (algorithm fix) Moves to WARM requires two hits overall (algorithm fix) LRU maintainer performance: per-class sleep scheduling Allow limiting the internal LRU crawler run length Stop using atomics for item refcount management (performance) Make the conn suffix list the same as item list (performance) Do LRU-bumps while already holding item lock (performance) Reduce add_iov() work for TCP connections (performance) New Features “lru” command for setting LRU parameters at runtime Allow switching LRU algo’s at runtime The full documentation is in doc/protocol.txt under “LRU Tuning”. Since a few years ago, memcached supports the original “flat” LRU algorithm alongside a segmented LRU. With the “lru” ASCII command you can tune settings live, or even switch between algorithms entirely!\nSo long as memcached is started with -o modern or similar, you can experiment with the hit ratio of differnt algorithms or options without restarting with a cold cache each time.\nIE: lru mode flat to switch back from segmented. Or lru mode segmented to flip back again.\nlru tune [etc] is for adjusting the segmented LRU options. I strive for sensible defaults, but that may not apply to everyone.\nNew TEMP_LRU feature The “expirezero does not evict” feature is gone, and in its place is a “temporary LRU”. Items set with TTL’s under a specific value are put into a special “temporary” LRU. These items are not evictable, and the LRU maintainer background thread reaps from the tail as they expire.\nThis can help a lot if you have mixed workloads with short and long TTL’s, as items with short TTL’s could be freed automatically sooner than any other background process. Do not set this too high!\nThis can be enabled with -o temporary_ttl=60 for a “60 seconds or lower”, or live via lru temp_ttl 60. lru temp_ttl -1 disables the feature live.\nautotuning for HOT/WARM LRU’s By default the HOT and WARM LRU’s can take up to 32% of memory each. I’ve found people with mixed TTL workloads will end up with close to 1/3rd of memory utilized. With this change a couple more tunables (adjustable live via lru tune) are added, with hopefully sensible defaults.\nItems are now moved out of HOT if they are idle more than 3600 seconds or memory usage is above 32%.\nItems are now moved out of WARM if they are idle more than twice the idle time of COLD, or memory usage is above 32%. This is to encourage fairness between items that were active briefly but never again and newer items flowing through COLD. Sometimes WARM idle time could reach weeks!\nConditionally don’t inline the ASCII VALUE line (memory efficiency/performance) Since the first releases, memcached has written an inlined buffer of the ASCII protocol response into items. This uses some small amount of memory in exchange for avoiding a sprintf on every read. In this release, a very fast itoa library is used and the header is written into a temporary buffer.\nThis means ASCII reads are very slightly slower, however it also means SETs are faster. Also the binary protocol never used this header, so binprot SETs are improved and memory efficiency is improved for small objects.\nA SET would usually sprintf twice. Other performance tweaks were included, this release should be faster overall than any previous one. Currently this is enabled within -o modern or -o no_inline_ascii_resp.\nContributors The following people contributed to this release since 1.4.34.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.34..1.4.35 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.35 34\tdormando 1\tJoe Orton 1\tJuliy V. Chirkov "},"title":"ReleaseNotes1435"},"/releasenotes/releasenotes1436/":{"data":{"":"","#":"Memcached 1.4.36 Release Notes Date: 2017-3-19\nDownload http://www.memcached.org/files/memcached-1.4.36.tar.gz\nOverview Important bug fix that could lead to a hung slab mover. Also improves memory efficiency of chunked items.\nFixes fix refcount leak in LRU bump buf New Features Chained items were introduced in 1.4.29. With -o modern items sized 512k or higher are created by chaining 512k chunks together. This made increasing the max item size (-I) more efficient in many scenarios as the slab classes no longer have to be stretched to cover the full space.\nThere was still an efficiency hole for items 512k-\u003e5mb or so where the overhead is too big for the size of the items. This change fixes it by using chunks from other slab classes in order to “cap” off chained items. With this change larger items should be more efficient than the original slab allocator in all cases.\nChunked items are only used with -o modern or explicitly changing -o slab_chunk_max It is not recommended to set slab_chunk_max to be smaller than 256k at this time.\nContributors The following people contributed to this release since 1.4.35.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.35..1.4.36 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.36 2\tdormando "},"title":"ReleaseNotes1436"},"/releasenotes/releasenotes1437/":{"data":{"":"","#":"Memcached 1.4.37 Release Notes Date: 2017-6-4\nDownload http://www.memcached.org/files/memcached-1.4.37.tar.gz\nOverview A good number of small community fixes (see below). Number of crash fixes and a 10 year old memory leak as well!\nA new script (scripts/memcached-automove) is now included. This is a beta test of the slab page automove algorithm we will be moving to, and will be enabled by default when 1.5.0 lands soon. If you have time, please give it a test and send us feedback!\nFixes LRU crawler: avoid running infinitely. fix very old memory leak in ASCII multigets. (when using multiget gets and keys after the first one are \u003e255 characters) remove old slab mover example script. fix crash in page mover while using large items automover algo python script avoid segfault if idle_timeout value is missing. fix rare crash in LRU crawler sleep more aggressively in some threads don’t overflow item refcount on get fix solaris compilation error usability fix for cache_memlimit command fix verbose print for idle-kicker disable refhang.t test due to flakiness fix ordering issue in conn dispatch (prevents potential hangups) New Features LRU crawler scheduling improvements The LRU crawler’s internal run scheduler still predated the segmented LRU. It would run across each sub-LRU (HOT|WARM|etc), but schedule runs by slab class.\nNow it schedules each sub-class independently. Now it will make more frequent targeted runs. IE: If you make use of TEMP and store many items that expire within a few minutes, it will wake up and re-run scans of each active TEMP LRU instead of timing based on the total size of the slab class.\nIt can also re-schedule runs while a previous run is still running. In the same example, it could continue to wake and scan TEMP LRU’s, even if there’s a COLD LRU with 300 million items in it which could take minutes to scan by itself.\nper-LRU hits breakdown under stats items (hits_to_(hot|warm|cold|temp)) Contributors The following people contributed to this release since 1.4.36.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.36..1.4.37 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.37 17\tdormando 1\tFumihiro Ito 1\tGrant Mathews 1\tJosh Soref 1\tPeter (Stig) Edwards "},"title":"ReleaseNotes1437"},"/releasenotes/releasenotes1438/":{"data":{"":"","#":"Memcached 1.4.38 Release Notes Date: 2017-6-24\nDownload http://www.memcached.org/files/memcached-1.4.38.tar.gz\nOverview NOTE: This is probably the last release before -o modern becomes the default and 1.5.0 is released.\nThe slab page automover algorithm should be much more fair. It now attempts to keep the tail ages of slab classes similar. Please let us know how well this works out!\nThe slab page mover can also delete items in order to make progress if it detects a jam. Previously hot items could indefinitely hold the page mover.\nThe rest are minor fixes.\nFixes hot_max_age is now hot_max_factor - HOT is now limited to 20% of COLD’s age or 20% of total space, whichever comes first. sleep longer between slab move runs (1ms instead of 50us) automove script: improve algo, add basic test slab_rebal: delete busy items if stuck fix LRU maintainer thread slowdown in edge case fix rare long background thread pause in hash expansion New Features The slab automover algorithm recently would only kick in if there was too many free chunks in a slab class. If your items simply changed size over time this was fine, but there were too many edge cases. If slab class 3 periodically empties a lot of its memory, but slab class 5 will use as much as you have and still evict, over time 3 will still become starved.\nThis new algorithm attempts to keep the youngest evicting slab class to within 80% of the age of the oldest slab class (by default). Ages are averaged over a window to avoid ping-ponging memory between slab classe.\nIt also still aggressively frees memory if too much is free.\nContributors The following people contributed to this release since 1.4.37.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.37..1.4.38 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.38 8\tdormando "},"title":"ReleaseNotes1438"},"/releasenotes/releasenotes1439/":{"data":{"":"","#":"Memcached 1.4.39 Release Notes Date: 2017-7-4\nDownload http://www.memcached.org/files/memcached-1.4.39.tar.gz\nOverview Fixes a reported CVE in binary protocol code. Also adds a trivial 4 byte reduction in memory usage under -o modern if client flags aren’t used.\nThis CVE seems relatively minor; may be able to crash worker threads. I wasn’t able to quickly reproduce a crash but folks should still upgrade when convenient.\nFixes fix for CVE-2017-9951 save four bytes per item if client flags are 0 New Features If client flags are “0”, no extra storage is used.\nContributors The following people contributed to this release since 1.4.38.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.38..1.4.39 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.39 2\tdormando "},"title":"ReleaseNotes1439"},"/releasenotes/releasenotes144/":{"data":{"":"","#":"Memcached 1.4.4 Release Notes Date: 2009-11-26 Sat\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.4.tar.gz\nOverview This is a maintenance release of memcached with a workaround for common client issue as well as a few new stats.\nFixes Add partial backwards compatibility for delete with timeout 0 Before version 1.4.0, there was an optional argument to delete that would allow a client to specify that a deleted object should exist in the cache after the deletion occurred such that add operations would fail even though objects did not appear in the cache.\nThis feature was removed completely in 1.4.0, but a parser bug caused it to slip through. The bug was fixed in 1.4.3. If anyone was attempting to use it legitimately in the 1.4 series, it would simply not work as expected.\nThe 1.4.4 backwards compatibility change allows specifically the value of 0 (i.e. non-lingering delete), while continuing to reject others. This will satisfy clients that always wish to send a value even when they do not wish the item to linger.\nNew Features New Stats ==== auth_enabled_sasl ====\nThis is a general stat that indicates whether SASL authentication is enabled or not.\n==== auth_cmds ====\nIndicates the total number of authentication attempts.\n==== auth_errors ====\nIndicates the number of failed authentication attempts.\nContributors The following people contributed to this release since 1.4.3.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.3..1.4.4 or use a web view.\nRepo list: [https://github.com/memcached/memcached/wiki/DevelopmentRepos] Web View: [http://github.com/memcached/memcached/commits/1.4.4] 2 Dustin Sallings 2 Matt Ingenthron 1 dormando "},"title":"ReleaseNotes144"},"/releasenotes/releasenotes145/":{"data":{"":"","#":"Memcached 1.4.5 Release Notes Date: 2010-04-03\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.5.tar.gz\nOverview This is a maintenance release with some build fixes, doc fixes, and one new stat.\nFixes Properly detect CPU alignment on ARM. bug100 Remove 1MB assertion. bug 119 More automake versions supported. Compiler warning fixes for OpenBSD. potential buffer overflow in vperror Report errors opening pidfiles using vperror New Features New stat: reclaimed This stat reports the number of times an entry was stored using memory from an expired entry.\nsasl_pwdb for more simple auth deployments –enable-sasl-pwdb allows memcached to use it’s own password file and verify a plaintext password.\nThe file is specified with the environment variable MEMCACHED_SASL_PWDB, and is a plain text file with the following syntax:\nusername:password Please note that you have to specify “mech_list: plain” in your sasl config file for this to work.\nEx:\necho \"mech_list: plain\" \u003e memcached.conf echo \"myname:mypass\" \u003e /tmp/memcached-sasl-db export MEMCACHED_SASL_PWDB=/tmp/memcached-sasl-db export SASL_CONF_PATH=`pwd`/memcached.conf ./memcached -S -v and you should be able to use your favorite memcached client with sasl support to connect to the server.\n(Please note that not all SASL implementations support SASL_CB_GETCONF, so you may have to install the sasl config (memcached.conf) to the systemwide location)\nContributors The following people contributed to this release since 1.4.4.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.4..1.4.5 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.5 6 Trond Norbye 3 Paul Lindner 2 Dustin Sallings 1 Brad Fitzpatrick 1 Jørgen Austvik "},"title":"ReleaseNotes145"},"/releasenotes/releasenotes146/":{"data":{"":"","#":"Memcached 1.4.6 Release Notes Date: 2011-07-15\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.6.tar.gz\nOverview This is a maintenance release with some build fixes, many small bug fixes, and a few major bug fixes. incr/decr are now actually atomic, and a crash with hitting the max connection limit while using multiple interfaces has been fixed.\nFixes Gcc on Solaris sparc wants -R and not -rpath Issue 121: Set the runtime path when –with-libevent is used Fix autogen failure when unable to find supported command. fix race crash for accepting new connections fix incr/decr race conditions for binary prot fix incr/decr race conditions for ASCII prot Compile fix (-Werror=unused-but-set-variable warnings) Bind each UDP socket to an a single worker thread in multiport env Add support for using multiple ports Issue 154: pid file out of sync (created before socket binding) Issue 163: Buggy mem_requested values Fix cross compilation issues in configure Issue 140 - Fix age for items stats Issue 131 - ChangeLog is outdated Issue 155: bind to multiple interface Issue 161 incorrect allocation in cache_create Fix type-punning issues exposed with GCC 4.5.1 Simplify stats aggregation code Reverse backward expected/actual params in test Issue 152: Fix error message from mget Refuse to start if we detect libevent 1.[12] Fix compilation issue on Solaris 9 wrt isspace() macro - Resolves issue 111 New Features Multiple port binding You may now specify multiple addresses by listing -l multiple times.\nContributors The following people contributed to this release since 1.4.5.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.5..1.4.6 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.6 13 Trond Norbye 6 dormando 5 Dan McGee 2 Paul Lindner 1 Jon Jensen 1 nirvanazc "},"title":"ReleaseNotes146"},"/releasenotes/releasenotes147/":{"data":{"":"","#":"Memcached 1.4.7 Release Notes Date: 2011-08-16\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.7.tar.gz\nOverview This is a maintenance release with many small bugfixes. Now (mostly) immune from time travelers.\nFixes Use a monotonically increasing timer Immediately expire items when given a negative expiration time fix memcached-tool to print about all slabs Properly daemonize memcached for debian Don’t permanently close UDP listeners on error Allow memcached-init to start multiple instances (not recommended) Issue 214: Search for network libraries before searching for libevent Issue 213: Search for clock_gettime in librt Issue 115: accont for CAS in item_size_ok Fix incredibly slim race for maxconns handler. Should no longer hang ever Issue 183 - Reclaim items dead by flush_all Issue 200: Don’t fire dtrace probe as the last thing in a function New Features Montonic Clock This isn’t really a feature, but is the main change. If your system has clock_gettime with CLOCK_MONOTONIC support, memcached will attempt to use it. If your clock does wild adjustments, memcached will do its best to continue to count forward and not backward.\nHowever, if you use the “expiration is an absolute time” feature, where specifying an value expiration time as a specific date, it can still break. You must ensure that memcached is started after your clocks have been synchronized. This has always been the case, though.\nContributors The following people contributed to this release since 1.4.6.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.6..1.4.7 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.7 9 dormando 6 Trond Norbye 1 Clint Byrum 1 Gordon Franke "},"title":"ReleaseNotes147"},"/releasenotes/releasenotes148/":{"data":{"":"","#":"Memcached 1.4.8 Release Notes Date: 2011-10-04\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.8.tar.gz\nOverview Feature and bugfix release. New Touch commands, counters, and a change to connection limit functionality.\nIncluded is an important bugfix for binary protocol users. The binary get command was not activating the LRU algorithm. Fetching an item would not prevent it from getting expired early.\nFixes Fix to write correct pid from start-memcached Fix to enable LRU when using binary protocol Upgrade stats items counters to 64bit Add new stats expired_unfetched, evicted_unfetched Allow setting initial size of the hash table Expose stats for the internal hash table bug220: incr would sometimes return the previous item’s CAS Fixed bug on multi get processing Experimental maxconns_fast option Add an ASCII touch command Add binary GATK/GATKQ Backport binary TOUCH/GAT/GATQ commands Issue 221: Increment treats leading spaces as 0 Fix compile error on OS X New Features Touch Commands Binary Touch/GAT commands were backported from 1.6. New GATK/GATKQ commands were added for completeness. Finally, an Ascii protocol touch command was also added.\nTouch commands are used to update the expiration time of an existing item without fetching it. Say you have a counter set to expire in five minutes, but you may want to push back the expiration time by five more minutes, or change it to 15 minutes. With touch, you can do that.\nThe binary protocol also adds GAT commands (Get And Touch), which allow you to fetch an item and simultaneously update its expiration time.\nFast Connection Limit Handling A new option, -o, has appeared! With -o new, experimental, or highly specific options are given full names. The first of which is maxconns_fast\nThis option changes the way the maximum connection limit is handled. By default, when memcached runs out of file descriptors, it stops listening for new connections. When this happens, connections will sit in the listen backlog (defaulting to 1024, and adjustable with the -b option). Once some connections close off, memcached will starts accepting new connections again and they will be served. This is undesireable as it can cause clients to delay or timeout for a long period of time. Long enough that it may be quicker to treat the items as a cache miss. When a client connects and memcached is configured with maxconns_fast, it writes an error to the client and immediately closes the connection. This is similar to how MySQL operates, whereas the default is similar to Apache. It is experimental as it is unknown how clients will handle this change. Please help test and report any issues to upstream client maintainers! #### Internal Hash Table STAT hash_power_level 16 STAT hash_bytes 524288 STAT hash_is_expanding 0\nNow it's possible to see how much memory the hash table itself uses. This can be useful for deciding on RAM limits for very large instances. There is also a new option for setting the size of the hash table on startup: ```$ memcached -o hashpower=20}}} If you run instances with many millions of items, and items are added very rapidly on a restart, it may be desireable to _presize_ the hash table. Normally memcached will dynamically grow the hash table as needed, and this operation is generally very low overhead. If you put decals on your '96 Mazda grapefruit shootermobile, you may like this option. Just examine the hash_power_level before restarting your instances, and adjust the startup command. #### expired_unfetched, evicted_unfetched The two stats represent items which expired and memory was reused, and valid items which were evicted, but never touched by get/incr/append/etc operations in the meantime. Useful for seeing how many wasted items are being set and then rolling out through the bottom of the LRU's. If these counters are high, you may consider auditing what is being put into the cache. ### Contributors The following people contributed to this release since 1.4.7. Note that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it. Note that this is just a summary of how many changes each person made which doesn't necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of `git log 1.4.7..1.4.8` or use a web view. * Repo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos * Web View: http://github.com/memcached/memcached/commits/1.4.8 12 dormando 2 Daniel Pañeda 2 Trond Norbye 1 Dustin Sallings 1 Nate "},"title":"ReleaseNotes148"},"/releasenotes/releasenotes149/":{"data":{"":"","#":"Memcached 1.4.9 Release Notes Date: 2011-10-18\nDownload Download Link:\nhttp://memcached.org/files/old/memcached-1.4.9.tar.gz\nOverview Small bugfix release. Mainly fixing a critical issue where using -c to increase the connection limit was broken in 1.4.8. If you are on 1.4.8, an upgrade is highly recommended.\nFixes Add a systemd service file Fix some minor typos in the protocol doc Issue 224 - check retval of main event loop Fix -c so maxconns can be raised above default. New Features No new features in this version.\nContributors The following people contributed to this release since 1.4.8.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.8..1.4.9 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.4.9 3\tdormando 1\tMatt Ingenthron 1\tMiklos Vajna "},"title":"ReleaseNotes149"},"/releasenotes/releasenotes150/":{"data":{"":"","#":"Memcached 1.5.0 Release Notes Date: 2017-7-21\nDownload http://www.memcached.org/files/memcached-1.5.0.tar.gz\nOverview This release makes the options -o modern enabled in 1.4.39 the default options. It also adds –long-options (see –help|-h) if the platform supports it and fixes a small bug.\nPeople who were not running -o modern before should see wins in hit rate or reductions in memory requirements. Please report any regressions.\nFixes fix for musl libc: avoid huge stack allocation New Features This release is the culmination of many years of part-time work.\nMemcached was introduced in 2003, two years before the first dual-core opteron x86 processor. Since then computers have added huge numbers of cores and vastly expanded memory.\nRecently the cost ratio of memory to CPU has started to shift a bit. For a few years memory prices will likely be inflated (though this always comes in cycles). I’ve managed to keep memcached’s performance and thread scalability very high. Now it makes use of some extra CPU in background threads in order to reduce memory usage. You may find you need half as much RAM to get the same hit ratio, or it could be the same as what you have now.\nThe new features:\nLRU crawler to background-reclaim memory. Mixed-TTL’s and LRU reordering leaves many holes, making it difficult to properly size an instance. Segmented LRU. HOT/WARM/COLD and background processing should try harder to keep semi-active items in memory for longer. Automated slab rebalancing. Avoiding slab stagnation as objects change size over time. Faster hash table lookups with murmur3 algorithm (though it’s been so long this is now outdated again;) Reduce memory requirements per-item by a few bytes here and there Immediately close connections when hitting the connection limit, instead of hanging until a spot opens up. Items larger than 512k (by default) are assembled by stacking multiple chunks together. Now raising the item size above 1m doesn’t drop memory efficiency by spreading out slab classes. These features have been slowly assembled, tuned, and tested behind feature flags for far too long. Recently after finishing reworking the automated page mover, I felt confident enough to flip the defaults around and call this thing 1.5.x.\n-o modern will live on as new feature flags appear. Though they may not take as long to migrate to the actual defaults.\nIf you want the old defaults, -o no_modern will work for a while.\nSome old flags will be deprecated (old maxconns handling, and the inverse of the byte-savings, for two) and eventually removed.\nA great thanks goes out to Andrew Rodland (hobbs) for running production tests of the adjusted slab page algorithm. Help from the community greatly reduces the time it takes for me to find bugs and gain confidence in features.\nAnother great thanks to https://www.packet.net/ - Their donation of test hardware has been invaluable while I run endless burn-in tests on various features. It’s crazy the weird bugs you find while shoveling tens of millions of qps at a single instance while moving memory around randomly!\nIt’d be great to hear from users as well. It’s been a long time and there are a lot of key/value stores now. If this work is truly useful we’ll keep it up.\nContributors The following people contributed to this release since 1.4.39.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.4.39..1.5.0 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.0 2\tdormando "},"title":"ReleaseNotes150"},"/releasenotes/releasenotes151/":{"data":{"":"","#":"Memcached 1.5.1 Release Notes Date: 2017-8-24\nDownload http://www.memcached.org/files/memcached-1.5.1.tar.gz\nOverview Bugfix release for the 1.5.0 series. Includes --enable-seccomp configure option for enabling linux seccomp privilege dropping.\nFixes add max_connections stat to ‘stats’ output Drop sockets from obviously malicious command strings (HTTP/) stats cachedump: now more likely to show data memcached-tool: fix slab Full? column fix null pointer ref in logger for bin update cmd default to unix sockets for tests, make them much less flaky PARALLEL=9 make test -\u003e runs prove in parallel fix flaky stats.t test New Features –enable-seccomp compiles in options for strict privilege reduction in linux. see output of -h for more information.\nContributors The following people contributed to this release since 1.5.0.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.0..1.5.1 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.1 10\tdormando 4\tStanisław Pitucha 1\tBen Evans 1\tDavid Schoen "},"title":"ReleaseNotes151"},"/releasenotes/releasenotes1510/":{"data":{"":"","#":"Memcached 1.5.10 Release Notes Date: 2018-8-10\nDownload http://www.memcached.org/files/memcached-1.5.10.tar.gz\nOverview Build, Bugfixes, and … Blocks?\nNOTE: For extstore users, -o ext_page_count= is deprecated and no longer works.\nTo specify device size: -o ext_path=/d/m/e:500G - extstore figures out the page count based on your desired page size. M|G|T|P supported.\nThis change is disruptive, but likely the last time I’ll do this. There is higher confidence in extstore every month and people should be ready to rely on it. If the arguments change in the future, they will follow a strict deprecation cycle.\nAlso, basic JBOD support for extstore is here! If you have multiple similar devices, simply specify ext_path multiple times and it will stripe data across them, example: -o ext_path=/d1/e:1T,ext_path=/d2/e:1T\nMake sure you experiment and specify enough ext_threads to fully utilize the drives. There’s no hard rule on how many IO threads are necessary, but you need fewer threads for devices with lower latency.\nFuture releases will allow mixing different types of devices, ie:\ndrive A is a small persistent memory (Optane or similar) device drive B is a large inexpensive flash SSD You will be able to direct “compacted”, longer lived items, onto the SSD. Or drive low TTL items onto the persistent memory, etc. This has been tested, but requires adjustments to the compaction algorithm before going into mainline.\nFixes fix alignment issues on some ARM platforms for chunked items add missing va_end() call to logger_log() New Features basic extstore JBOD support (noted in Overview)\nsplit storage writer into its own thread\nThe extstore storage writer was co-located with the LRU maintenance thread. This change separates it into its own thread, which brings up the performance consistency and throughput. This is especially true during benchmarks, which could easily starve the extstore flush routine of resources. Most users are unlikely to notice a difference.\nContributors The following people contributed to this release since 1.5.9.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.9..1.5.10 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.10 4\tdormando 1\tGleicon Moraes 1\tMiroslav Lichvar 1\tphantom9999 "},"title":"ReleaseNotes1510"},"/releasenotes/releasenotes1511/":{"data":{"":"","#":"Memcached 1.5.11 Release Notes Date: 2018-10-10\nDownload http://www.memcached.org/files/memcached-1.5.11.tar.gz\nOverview Fixes broken test and small extstore optimization.\nFixes extstore: balance IO thread queues t/lru-maintainer.t: check for WARM item earlier, fixing race condition on some platforms. New Features None.\nContributors The following people contributed to this release since 1.5.10.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.10..1.5.11 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.11 2\tdormando 1\tNick Frost "},"title":"ReleaseNotes1511"},"/releasenotes/releasenotes1512/":{"data":{"":"","#":"Memcached 1.5.12 Release Notes Date: 2018-11-3\nDownload http://www.memcached.org/files/memcached-1.5.12.tar.gz\nOverview Single bugfix release. Fixes a refcount leak that could happen when attempting to run incr/decr against a:\n0 byte value CHUNKED (\u003e 512k) item extstore item that has been flushed to disk Fixes fix INCR/DECR refcount leak for invalid items New Features None\nContributors The following people contributed to this release since 1.5.11.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.11..1.5.12 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.12 1\tdormando "},"title":"ReleaseNotes1512"},"/releasenotes/releasenotes1513/":{"data":{"":"","#":"Memcached 1.5.13 Release Notes Date: 2019-4-15\nDownload https://www.memcached.org/files/memcached-1.5.13.tar.gz\nOverview Experimental TLS support. Brought to you by Netflix, thanks! :)\nSee memcached --help for usage. Allows mixing TLS and non-TLS listeners (for local monitoring, tests, etc). Has been reviewed and tested but please treat it as experimental. Let us know if you run into any issues!\nRequires a minimum OpenSSL version of 1.1.0. OpenSSL’s API changed the API, deprecating some old functions. They also redid the locking code entirely, which scales much better. Old versions should be avoided for security reasons, as well as for not giving good performance in multithreaded servers such as memcached.\nSee doc/tls.txt for more information.\nAs of this writing no known memcached clients support TLS; please contact the maintainers/authors of your client software to enquire about adding TLS support. You can also use proxies, routers, and so on.\nIf you have extremely sensitive performance requirements, take care in deploying this feature.\nFixes Basic implementation of TLS for memcached. Improve Get And Touch documentation New Features TLS support!\nContributors The following people contributed to this release since 1.5.12.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.12..1.5.13 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.13 1\tAndre Azevedo Pinto 1\tTharanga Gamaethige "},"title":"ReleaseNotes1513"},"/releasenotes/releasenotes1514/":{"data":{"":"","#":"Memcached 1.5.14 Release Notes Date: 2019-4-27\nDownload https://www.memcached.org/files/memcached-1.5.14.tar.gz\nOverview Bugfix release. No new features. Fix an extstore test failure introduced in 1.5.13. All other bugs are trivial or older.\nFixes update -h output for -I (max item size) fix segfault in “lru” command fix compile error on centos7 extstore: error adjusting page_size after ext_path extstore: fix segfault if page_count is too high. close delete + incr item survival race bug FreeBSD superpages checking. FreeBSD capabilities support. memcached-tool dump fix loss of exp value Add optional feature support to RPM package building Fix “qw” in “MemcachedTest.pm” so wait_ext_flush is exported properly New Features None.\nContributors The following people contributed to this release since 1.5.13.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.13..1.5.14 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.14 8\tdormando 2\tDavid Carlier 1\tJohn Leslie 1\tTianon Gravi 1\thayashier 1\tmiwasson "},"title":"ReleaseNotes1514"},"/releasenotes/releasenotes1515/":{"data":{"":"","#":"Memcached 1.5.15 Release Notes Date: 2019-5-20\nDownload http://www.memcached.org/files/memcached-1.5.15.tar.gz\nOverview A couple small bugfixes, and two notable changes. An authentication mode for ASCII protocol, and removal of a minor feature flag.\n-o inline_ascii_response was a compatability mode which was disabled since 1.5.0; it uses 10-20 more bytes of memory to speed up ASCII responses. Since we switched from snprintf to a fast itoa implementation years ago it was disabled by default. Now the option is gone.\nBinary protocol was also not honoring the idle-timeout feature. This should now be fixed.\nFixes Speed up incr/decr by replacing snprintf. Use correct buffer size for internal URI encoding. change some links from http to https Fix small memory leak in testapp.c. free window_global in slab_automove_extstore.c remove inline_ascii_response option -Y [filename] for ascii authentication mode fix: idle-timeout wasn’t compatible with binprot New Features -Y [authfile] enables an authentication mode for ASCII protocol. See doc/protocol.txt for the most up to date information. This feature is experimental; there’s a small chance it could change based on community feedback. Unlike the SASL authentication for binary protocol, this is built in by default and has no external dependencies. It is also far simpler to use; we get a constant slow trickle of support requests around SASL authentication.\nWhen enabled, UDP and binary protocols are also disabled.\nThe files take up to 8 user:pass tokens:\nfoo:bar baz:quux The feature isn’t meant to give a fine grained set of access to a large number of users: there’s currently no further restriction once authenticated. Multiple tokens are useful for token rotation or similar, where old tokens should work alongside newer ones for a while.\nIt’s used via the set command:\nset key 0 0 N\\r\\n auth pass\\r\\n where N is the length of the “auth pass\\r\\n” payload.\nThe “key” value is ignored. When used in a cluster, it may not be easy to ensure an authentication request hits a specific server. For those cases, a failed command may retry using the same key, but using a SET command with a supplied “auth pass” token. An AUTH specific command may be added in the future, as well.\nReloading the auth file is done by sending a HUP signal to the memcached process. We may also add a management command to reload the file.\nIf you are a client author and have feedback about this feature, please hit up the mailing list and let us know. Thanks!\nNote: worth mentioning this doesn’t protect against timing attacks. We’re not against extra security features, but need to understand the use case better and add just what’s needed. If you need better security, the TLS feature is better.\nContributors The following people contributed to this release since 1.5.14.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.14..1.5.15 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.15 4\tdormando 2\tTharanga Gamaethige 1\tDavid Carlier 1\tkun 1\tliwenlong05 "},"title":"ReleaseNotes1515"},"/releasenotes/releasenotes1516/":{"data":{"":"","#":"Memcached 1.5.16 Release Notes Date: 2019-5-24\nDownload http://www.memcached.org/files/memcached-1.5.16.tar.gz\nOverview Fixes critical potential segfault/memory corruption bug in 1.5.15 when storing items with client flags of “0”. Bug only exists in 1.5.15, and the fix is the only change in this release.\nFixes When nsuffix is 0 space for flags hasn’t been allocated so don’t memcpy them. New Features None.\nContributors The following people contributed to this release since 1.5.15.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.15..1.5.16 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.16 1\tMatthew Shafer "},"title":"ReleaseNotes1516"},"/releasenotes/releasenotes1517/":{"data":{"":"","#":"Memcached 1.5.17 Release Notes Date: 2019-8-29\nDownload http://www.memcached.org/files/memcached-1.5.17.tar.gz\nOverview Bugfixes and small changes. Thanks to the many external contributors in this release!\nThe strncpy bug was found by a security group:\nJonas Jensen Geoffrey White Antonio Morales … though given the nature of the bug, while it will trip ASAN, there’s no way to exploit it and it only occurs over unix domain sockets. No data is copied past the end of any buffers. Still, we take this seriously and have repaired the offending code, just in case.\nFixes fix strncpy call in stats conns to avoid ASAN violation extstore: fix indentation add error handling when calling dup function add unlock when item_cachedump malloc failed extstore: emulate pread(v) for macOS fix off-by-one in logger to allow CAS commands to be logged. use strdup for explicitly configured slab sizes move mem_requested from slabs.c to items.c (internal cleanup) New Features add server address to the “stats conns” output log client connection id with fetchers and mutations Add a handler for seccomp crashes Contributors The following people contributed to this release since 1.5.16.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.16..1.5.17 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.17 5\tdormando 4\tStanisław Pitucha 2\tTharanga Gamaethige 2\tminkikim89 1\tAndrew Drake 1\tDavid Carlier 1\tGregor Jasny 1\tShiv Nagarajan "},"title":"ReleaseNotes1517"},"/releasenotes/releasenotes1518/":{"data":{"":"","#":"Memcached 1.5.18 Release Notes Date: 2019-9-17\nDownload http://www.memcached.org/files/memcached-1.5.18.tar.gz\nOverview Big new feature: warm cache restart!\nFixes None.\nNew Features Memcached 1.5.18 and newer can recover its cache between restarts. It can restart after upgrades of the binary, most changes in settings, and so on. It now also supports using persistent memory via DAX filesystem mounts. See below for more details.\nUse it by adding: -e /tmpfs_mount/memory_file to your startup options.\n/tmpfs_mount/ must be a ram disk of some sort, big enough to satisfy the memory limit specified on startup with -m. To gracefully restart; send a SIGUSR1 signal to the daemon, and wait for it to shut down and exit.\nIt will create a /tmpfs_mount/memory_file.meta file on shutdown. On restart it will read this file and ensure the restart is compatible. If it is not compatible or the file is corrupt, it will start with a clean cache.\nIf you change some parameters the cache will come up clean:\nThe memory limit (-m) The max item size. Slab chunk sizes. Whether CAS is enabled or not. Whether slab reassignment is allowed or not. … you are able to change all other options inbetween restarts!\nImportant Caveats (see below for more detail):\nSystem clock must be set correctly and must not jump while memcached is down. Deletes, sets, adds, incr/decr/etc commands will be missed while instance restarts! The earliest version you can restart from is 1.5.18. Older versions cannot upgrade to 1.5.18 without losing the cache. Consider this feature experimental for the next few releases, but please give it a try and let us know what you think.\nDETAILS This works by putting memory related to item data into an external mmap file (specified via -e). All other memory: the hash table, connection memory, etc, stay in main RAM. When the daemon is restarted, it runs a pass over the item data and fixes up the internal pointers and regenerates the hash table. This typically takes a few seconds, but if you have close to a billion items in memory it can take two or three minutes.\nOnce restarted, there is no performance difference between restartable and non-restartable modes.\nDAX mounts and persistent memory If you have a persistent memory device, you can utilize this feature to extend memcached’s memory into persistent memory. This does not make memcached crash safe! It will put item memory into your persistent memory mount, while the rest of memory (hash table/buffers/etc) use system DRAM. This is a very high performance mode as the majority of memory accesses stay in DRAM. Also, with a graceful shutdown memcached can be restarted after reboots so long as the DAX mount persists.\nSee your persistent memory vendor’s documentation for how to configure a DAX mount.\nYou can see extensive testing we did in this and other modes on our blog: https://memcached.org/blog/persistent-memory/\nCAVEATS Your system clock must be set correctly, or at least it must not move before memcached has restarted. The only way to tell how much time has passed while the binary was dead, is to check the system clock. If the clock jumps forward or backwards it could impact items with a specific TTL.\nUsers must keep in mind that while an instance is stopped, it may be missing updates from the network; deletes, sets, and so on. It is only safe to restart memcached if your architecture can handle this by either pausing/buffering updates, or restarting at a time when no changes are happening to the cache.\nFUTURE WORK This feature is presently incompatible with extstore. This should be resolved in the next version or two. Further additions to usability, safety, etc, will be added based on feedback we receive.\nContributors The following people contributed to this release since 1.5.17.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.17..1.5.18 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.18 2\tdormando "},"title":"ReleaseNotes1518"},"/releasenotes/releasenotes1519/":{"data":{"":"","#":"Memcached 1.5.19 Release Notes Date: 2019-9-30\nDownload http://www.memcached.org/files/memcached-1.5.19.tar.gz\nOverview This release contains an experimental new protocol extension for the default Text Protocol. This extension includes a flexible set of new commands encompassing features previously unique to the binary protocol, as well as many new updates allowing a reduction of network roundtrips for advanced features.\nFor details, please see the “Meta Commands” section in doc/protocol.txt https://github.com/memcached/memcached/blob/master/doc/protocol.txt\nFor use case examples, see the wiki: https://github.com/memcached/memcached/wiki/MetaCommands\nThese commands are experimental until stated otherwise in a future release. This means the syntax may change based on community feedback. We feel this is unlikely, but early adopters should keep track of the release notes. We don’t expect this process to take more than a few releases. After a short period we will no longer consider incompatible changes.\nThis release also contains a fix for the restart code and a memory leak in the TLS code when connections fail to properly establish. Also some other minor updates and fixes.\nFixes Keep “last access” time up to date in default segmented LRU mode slow down t/watcher.t test more Add include stdio.h to restart.c Reload CA cert in refresh routine TLS: fix leak of SSL context on accept failure drop privileges for FreeBSD. Make memcached setgroups failure non-fatal restart: use /tmp for restart tests. restart: add missing msync at close time New Features The meta commands feature, as noted above.\nContributors The following people contributed to this release since 1.5.18.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.18..1.5.19 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.19 10\tdormando 1\tDavid Carlier 1\tKevin Lin 1\tPiotr Balcer 1\tjwbee 1\tminkikim89 "},"title":"ReleaseNotes1519"},"/releasenotes/releasenotes152/":{"data":{"":"","#":"Memcached 1.5.2 Release Notes Date: 2017-9-30\nDownload http://www.memcached.org/files/memcached-1.5.2.tar.gz\nOverview Fixes a crash when storing more than 3.2 billion items in a single instance.\nBug is from 2006 :)\nFixes fix more binary protocol documentation errors. fix segfault during 31b -\u003e 32b hash table expand don’t create hashtables larger than 32bit some non-user-facing code changes for supporting future features. New Features None\nContributors The following people contributed to this release since 1.5.1.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.1..1.5.2 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.2 7\tdormando "},"title":"ReleaseNotes152"},"/releasenotes/releasenotes1520/":{"data":{"":"","#":"Memcached 1.5.20 Release Notes Date: 2019-11-11\nDownload http://www.memcached.org/files/memcached-1.5.20.tar.gz\nOverview Bugfix release.\nSecurity issue: When enabling SASL authentication for binary protocol, enabling UDP mode would allow bypassing SASL. Now refuses to start with both UDP and SASL enabled. Text mode authentication was not vulnerable.\nIncludes a performance improvement for page rebalancing. Full discussion here: https://github.com/memcached/memcached/pull/524 - in some circumstances, page will be moved between slab classes much faster than before.\nFixes Security fix: Don’t allow UDP with binprot SASL Remove multiple double-initializations of condition variables and mutexes Fix data race in assoc_start_expand Use a proper data type for settings.sig_hup restart: add error handling when a tag is not found in a metadata file. doc: Update rfc2629.dtd, use local copy, fix error, and fix warning doc: Fix out-of-tree build slab rebalance performance improvements fix potential deadlock bug in log watcher Support running tests in out-of-tree build configure: Fix cross-compilation errors DTrace build fix New Features None.\nContributors The following people contributed to this release since 1.5.19.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.19..1.5.20 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.20 6\tOla Jeppsson 3\tDaniel Schemmel 2\tminkikim89 1\tDaniel Byrne 1\tDavid Carlier 1\tdormando 1\tneal-zhu "},"title":"ReleaseNotes1520"},"/releasenotes/releasenotes1521/":{"data":{"":"","#":"Memcached 1.5.21 Release Notes Date: 2020-1-21\nDownload https://www.memcached.org/files/memcached-1.5.21.tar.gz\nOverview Bugfixes and smaller changes. Thanks to all the external contributors!\nFixes Adding missing defaults to the –help output stats: Fix stats delimiter unit tests Allow compilation with ASAN restart: add error handling if mmap fails For text auth token mode, use alternative bcmp implementation memcached-tool: Fix up tabular output for the ‘stats’ command. linux_priv.c: add termios.h include to fix powerpc(64) builds Update the build documentation in BUILD file Update documentation for –max-item-size Fix build issue due to improper pthread_t comparison Ensure t/whitespace.t test is skipped when outside a memcached git checkout Allocating large chunk of slabs for FreeBSD. New Features configuration option to disable watch commands (-W) Contributors The following people contributed to this release since 1.5.20.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.20..1.5.21 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.21 4\tDavid Carlier 4\tKanak Kshetri 3\tdormando 2\tCarl Myers 2\tDaniel Schemmel 2\tIqram Mahmud 1\tDavid J. M. Karlsen 1\tJosh Kupershmidt 1\tMartin Tzvetanov Grigorov 1\tSailesh Mukil 1\tTharanga Gamaethige 1\tiqr4m 1\tq66 "},"title":"ReleaseNotes1521"},"/releasenotes/releasenotes1522/":{"data":{"":"","#":"Memcached 1.5.22 Release Notes Date: 2020-2-1\nDownload http://www.memcached.org/files/memcached-1.5.22.tar.gz\nOverview Bugfix release for a crash regression introduced in 1.5.20. An optimization made to the slab page mover in 1.5.20 could cause segfaults in a specific situation.\nWhen moving page memory containing a chunked (\u003e 512K) item header, and the item is expired, but not yet reaped by LRU crawler or other mechanisms, the attached chunks would leak. If later the page mover tries to move the memory for these page chunks, it will no longer be able to find the proper header item, eventually causing a crash.\nThanks to the folks on github who reported this bug!\nFixes slabs: fix crash in page mover slabs: fix for skipping completed items New Features None.\nContributors The following people contributed to this release since 1.5.21.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.21..1.5.22 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.22 3\tdormando "},"title":"ReleaseNotes1522"},"/releasenotes/releasenotes153/":{"data":{"":"","#":"Memcached 1.5.3 Release Notes Date: 2017-11-4\nDownload http://www.memcached.org/files/memcached-1.5.3.tar.gz\nOverview Bugfix release. Adds “GAT” command from binprot to asciiprot.\nFixes Add warning about time on very low TTL’s in doc/protocol.txt pledge privdropping support for OpenBSD make for loop more clear in logger watcher fix theoretical leak in process_bin_stat fix use of unitialized array in lru_maintainer -o no_hashexpand to disable hash table expansion fix chunked items set in binprot, read from ascii New Features adds get and touch command for ascii protocol “gat [exptime] key [key…]\\r\\n” will fetch the item and refresh its expiration time. This is great for keys you’d normally either manually delete, or set to 0 TTL. Items rarely hit will expire, leaving more room for others.\nThis command has existed in the binary protocol for a long time, but now there’s party for ascii users.\nContributors The following people contributed to this release since 1.5.2.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.2..1.5.3 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.3 6\tdormando 1\tGiovanni Bechis 1\tTheo Najim "},"title":"ReleaseNotes153"},"/releasenotes/releasenotes154/":{"data":{"":"","#":"Memcached 1.5.4 Release Notes Date: 2017-12-20\nDownload http://www.memcached.org/files/memcached-1.5.4.tar.gz\nOverview New external storage (flash) shim. Still experimental and a little hard to tune, but generally stable and well tested.\nThis new feature requires ./configure --enable-extstore to be compiled in. building it in might have a very minor performance impact even without using the new shim. Netflix has been running production tests using this new system.\nWithout compiling in extstore, almost no new changes since 1.5.3.\nFixes make -I argument less position dependent external storage base commit lru_crawler metadump output ends with “END\\r\\n” fix: -o no_lru_crawler didn’t work New Features extstore, a cleverly named external storage shim, is an addon for using flash drives to expand cache storage.\nFor more detail, see the Extstore page. If this page is low on details, check back as it will be periodically updated.\nA short summary:\n-o ext_path=/mnt/somefile,ext_page_count=100 Will start memcached with external storage in /mnt/somefile, with a page size of 64 megabytes by default, and up to 100 pages of storage, which is 6.4 gigabytes. See ./memcached --help for some other options, and the page above for tuning detail.\nThis is a very flat, cache-oriented data shim. It is fast to forget but may not be as space efficient or write-amp efficient as a complex storage engine. Data is not persistent. If restarted, all is lost (same as normal RAM cache). The shim only helps with larger items; a data structure and the full key are always stored in RAM, and that object points to a position on disk for the value. The larger your items, the more you can benefit from this system. Values are “aged” out of RAM; recent and popular items stay in RAM cache. Pages are occasionally “compacted” when deletes or expired items leave too many holes in them. Configurable via ext_max_frag. Does not presently work on ARM! It can, or should, work in many scenarios. Since only older, colder items end up on flash, you can use SSD-backed VM’s and reduce the money you spend on RAM caches. This will vary by use case.\nSee Extstore for full discussion on the tradeoffs. Please find us on the mailing list if you have any questions.\nContributors The following people contributed to this release since 1.5.3.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.3..1.5.4 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.4 55\tdormando "},"title":"ReleaseNotes154"},"/releasenotes/releasenotes155/":{"data":{"":"","#":"Memcached 1.5.5 Release Notes Date: 2018-2-12\nDownload http://www.memcached.org/files/memcached-1.5.5.tar.gz\nOverview General bugfix release. Potential rare deadlock fixed (introduced in 1.5.x series). Improvements to memory balancing when extstore is in use.\nFixes remove redundant counter/lock from hash table (2% boost for sets) limit crawls for metadumper. avoids dumping too much data. extstore: revise automove algorithm quick fix for slab mover deadlock extstore: fix segfault in ’extstore’ admin command New Features None.\nContributors The following people contributed to this release since 1.5.4.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.4..1.5.5 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.5 6\tdormando "},"title":"ReleaseNotes155"},"/releasenotes/releasenotes156/":{"data":{"":"","#":"Memcached 1.5.6 Release Notes Date: 2018-2-27\nDownload http://www.memcached.org/files/memcached-1.5.6.tar.gz\nOverview This is a bugfix release, but it primarily disables the UDP protocol by default.\nIn the last few days reports of UDP amplification attacks utilizing inesure memcached instances have surfaced. Attackers are able to set large values into memcached, then send requests via spoofed UDP packets. Memcached will then send a very large number of very large UDP packets back in response.\n12 years ago, the UDP version of the protocol had more widespread use: TCP overhead could be very high. In the last few years, I’ve not heard of anyone using UDP anymore. Proxies and special clients allow connection reuse, which lowers the overhead. Also, RAM values are so large that TCP buffers just don’t add up as much as they used to.\nThat said, I don’t have any way of knowing how many UDP installations there are. Everyone who uses UDP and upgrades past this version, will find the UDP protocol disabled unless they explicitly enable it via -U 11211. Hopefully this one-time pain is acceptable.\nThanks for everyone who reached out in the last couple days to help understand the problem and coordinate patches sent to linux and BSD distro’s.\nFixes disable UDP port by default systemd instancing support \u0026 rpm build improvements fix gcc warnings in beta GCC fix build with clang fix for dtrace compilation on freebsd New Features The RPM specfiles have been greatly improved for systemd installations, see: https://github.com/memcached/memcached/commit/7141922a6188b00bc542b29c578506e0db52c9c7 for full detail.\nContributors The following people contributed to this release since 1.5.5.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.5..1.5.6 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.6 4\tdormando 1\tDavid Carlier 1\tJ. Grizzard 1\tManish Katiyar 1\tMiroslav Lichvar 1\tQian Li "},"title":"ReleaseNotes156"},"/releasenotes/releasenotes157/":{"data":{"":"","#":"Memcached 1.5.7 Release Notes Date: 2018-3-28\nDownload http://www.memcached.org/files/memcached-1.5.7.tar.gz\nOverview Bugfix release. Many thanks to the mostly outside contributors for this one!\nFixes alignment issues for 64bit ARM processors, seccomp portability, and a refcount leak with extstore while using binary touch commands. Full detail below.\nFixes extstore: fix ref leak when using binary protocol with TOUCH,GAT,GATK Drop supplementary groups in addition to setgid Use HAVE_SASL_CB_GETCONFPATH Fix SASL_CB_GETCONF(PATH) detection Rewrite memchached-tool ‘dump’ method to use new lru_crawler interface. Fixes decrement-before-check problem (issue #362). document in manpage that port 0 is off. Fix SIGBUS from alignment issues on 64bit ARM Update seccomp with syscalls found on Arch Enforce seccomp policy (kill process) Support seccomp on musl update –help for UDP default Fix sed options order in rpm specfile New Features None.\nContributors The following people contributed to this release since 1.5.6.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.6..1.5.7 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.7 4\tStanisław Pitucha 4\tdormando 3\tCalin Iorgulescu 2\tPeter (Stig) Edwards 1\tAnthony Ryan 1\tFangrui Song 1\tJosh Soref 1\tOri Shalev 1\tRemi Collet "},"title":"ReleaseNotes157"},"/releasenotes/releasenotes158/":{"data":{"":"","#":"Memcached 1.5.8 Release Notes Date: 2018-5-25\nDownload http://www.memcached.org/files/memcached-1.5.8.tar.gz\nOverview Number of important bugfixes for seccomp and extstore. Extstore platform portability has been greatly improved for ARM and 32bit systems.\nFixes fix sasl tests fix flaky extstore tests alignment and 32bit fixes for extstore crc32c for aarch64 support fix rare partial deadlock during hash table expansion Add Dockerfile definitions Fix lru-crawler behaviour for seccomp Fail loudly if seccomp setup fails New Features Thanks to @aparida1 from Qualcomm, extstore now has hardware CRC32 support for ARMv8 when available.\nEnabling it requires a few extra steps: ./configure CFLAGS=\"-march=armv8-a+crc\" --enable-extstore --enable-arm-crc\nthis should autodetect better in future releases.\nThanks to the help of @tianon and a few bug reports, extstore now works on 32bit systems and a number of ARM platforms.\nMore information on extstore can be found here: https://github.com/memcached/memcached/wiki/Extstore\nContributors The following people contributed to this release since 1.5.7.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.7..1.5.8 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.8 8\tdormando 3\tStanisław Pitucha "},"title":"ReleaseNotes158"},"/releasenotes/releasenotes159/":{"data":{"":"","#":"Memcached 1.5.9 Release Notes Date: 2018-7-7\nDownload https://www.memcached.org/files/memcached-1.5.9.tar.gz\nOverview Bugfix release.\nImportant note: if using --enable-seccomp, privilege dropping is no longer on by default. The feature is experimental and many users are reporting hard to diagnose problems on varied platforms.\nSeccomp is now marked EXPERIMENTAL, and must be explicitly enabled by adding -o drop_privileges. Once we’re more confident with the usability of the feature, it will be enabled in -o modern, like any other new change. You should only use it if you are willing to carefully test it, especially if you’re a vendor or distribution.\nAlso important is a crash fix in extstore when using the ASCII protocol, large items, and running low on memory.\nThanks to the many people who’ve participated in this release :) Lots of commits from the community this time around!\nFixes fix ASCII get error handling (+ extstore leak) drop_privileges is no longer default if available. remove bad assert from crawler Mark seccomp experimental Include keys with non-[\\w.~-] bytes in memcached-tool dump whitelist clock_gettime in seccomp rules Fix segfault: Prevent calling sasl_server_step before sasl_server_start fix flaky lru-maintainer test (OS X) New Features support transparent hugepages on Linux (-L option) Contributors The following people contributed to this release since 1.5.8.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.8..1.5.9 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.5.9 5\tdormando 3\tPaul Furtado 2\tLinkerist 2\tPeter (Stig) Edwards 2\tVadim Pushtaev 1\tCharmander 1\tChen-Yu Tsai 1\tSjon Hortensius 1\tStanisław Pitucha "},"title":"ReleaseNotes159"},"/releasenotes/releasenotes160/":{"data":{"":"","#":"Memcached 1.6.0 Release Notes Date: 2020-3-8\nDownload https://www.memcached.org/files/memcached-1.6.0.tar.gz\nOverview 1.6.0 brings significant new features and fixes to memcached.\nThe external flash storage (https://memcached.org/extstore) system is now compiled by default. The system still requires some careful attention to run in a large production, but it is generally considered stable. We’ll continue to improve the defaults incrementally. While it is compiled by default, it has to be explicitly enabled at start time, so it does not affect installs unless you intend to use it. It can be disabled at compile time via --disable-extstore\nThe new meta protocol (https://github.com/memcached/memcached/wiki/MetaCommands and doc/protocol.txt in your tarball) now has more features than the binary protocol. Anything you can do with the text/binary protocol can be done with the new meta commands. These commands can bring huge benefits to performance and correctness of cache systems.\nAt the same time, the binary protocol is now officially deprecated. We will support it and provide fixes for years to come, but it will not receive new commands or updates. All users should use meta or text protocols.\nFinally, the network code has been refactored to allow automatic batching of response syscalls. IE: If you submit multiple get commands in the same TCP packet, memcached will tend to send the responses with a single syscall. Previously, especially for the binary protocol, all keys fetched would use separate syscalls for each response. The only time this wasn’t true was for a text “multiget”. See details in the MetaCommands wiki page for how to efficiently use pipelining.\nYou don’t need to do much pipelining to see significant benefit: averaging 1.5 keys per syscall could reduce server CPU by up to 25% and latency by at least a few percent.\nWith this change, many buffers that were statically assigned to connected clients are now only used on-demand. This reduces the amount of memory usaged by an idle client connection from a minimum of 4.5 kilobytes to 400-500 bytes or so. It also removes many inline mallocs, reallocs, frees, and so on that could cause memory fragmentation for systems with a huge number of connections.\nEvery worker thread manages its own pool of read and write buffers for active client connections. This can be limited by two new tunables, though most users should never change these values.\n-o resp_obj_mem_limit=N and -o read_buf_mem_limt=N - N is a decimal amount of megabytes.\nThis can be useful if you have, say, 500,000 connected clients but don’t want to instantly OOM your system if a network hiccup causes many of them to be unable to completely read a new request or completely flush responses. When the memory limit is reached connections will be closed.\nMany thanks to Netflix and all the other contributors in this release. A lot of these features have been baking for a long time.\nWe believe this software to be of high quality. However this release is a bit larger than usual. If you have critical infrastructure on memcached, please roll this out slowly if possible.\nFixes meta: indicate refcount overflow meta: fix refleak in mget fix: all new connections were counted as rejected timedrun: proper signal handler initialization. restart: fix potential double free stats_prefix: fix test failure due to non-determinism fix bug where sasl will load config the wrong path meta: make return codes more generic config.h for util.c, fix htonll comp. failure hash: fix build failure against gcc-10 fix memory leaks in unit tests fix make order in BUILD instructions New Features extstore: enable by default. meta: arithmetic command (ma) for incr/decr network: transient static read buffer for conns network: response stacking for all commands Contributors The following people contributed to this release since 1.5.22.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.5.22..1.6.0 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.0 20\tdormando 3\tDavid Carlier 1\tKanak Kshetri 1\tSergei Trofimovich 1\tZheng Gu "},"title":"ReleaseNotes160"},"/releasenotes/releasenotes161/":{"data":{"":"","#":"Memcached 1.6.1 Release Notes Date: 2020-3-16\nDownload http://www.memcached.org/files/memcached-1.6.1.tar.gz\nOverview Bugfix release. Catches a number of build errors that crept in during 1.6.0. Also fixes most of the flaky tests in the test suite, making memcached more usable with slower CI builders.\nThanks to the many contributors to this release!\nFixes tls: handle accept errors properly ssl_errors stat Add touch,gat expiration test Add negative expiration time case to expiration test Fix to handle negative exptime as common function Fix a bunch of flaky tests Fix compile error with DTrace probes Allow missing syscall on ARM for seccomp fix multiple definition of ‘crc32c’ (GCC 10) Add stdio.h,stddef.h to storage.c (OS X compile error) A few text commands did not handle negative expiration times properly. This has been fixed to ensure they immediately expire, instead of just usually immediately expiring.\nNew Features None.\nContributors The following people contributed to this release since 1.6.0.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.0..1.6.1 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.1 11\tdormando 4\tminkikim89 1\tDavid Carlier 1\tKevin Lin 1\tRemi Collet 1\tShiv Nagarajan "},"title":"ReleaseNotes161"},"/releasenotes/releasenotes1610/":{"data":{"":"","#":"Memcached 1.6.10 Release Notes Date: 2021-7-25\nDownload http://www.memcached.org/files/memcached-1.6.10.tar.gz\nOverview Meta protocol is no longer marked as EXPERIMENTAL. A breaking protocol change should only happen in very extreme situations (security, major usage fault), which we do not expect to happen. Any further changes to the meta protocol will be the addition of new commands or flags to existing commands.\nSee doc/protocol.txt for a description of the meta protocol. https://github.com/memcached/memcached/wiki/MetaCommands wiki page for examples.\nThe XXH3 hash has been added to the list of hash table algorithms, but not enabled by default. There is a measurable performance improvement for long keys (\u003e 20 characters), but overall the difference is small.\nRelease otherwise contains bugfixes.\nFixes Fix minor severity heap buffer overflow reading --auth-file stats_prefix.c: Check for NDEBUG before using total_written variable Add settings stat for shutdown_command enabled [docker] Add user and expose the memcached port meta: remove EXPERIMENTAL mark + doc fixes meta: response code OK -\u003e HD meta: fix metaset syntax meta: repairs to mset command hash: add XXH3 to list of hash algorithms. fix arm64 crc32 on old glibc/gcc. extstore: fix crash on ‘stats extstore’ seccomp: extend allowed rules for extended usage The total number of UDP datagrams required for the message is calculated incorrectly. meta: allow base64’ed binary keys with ‘b’ flag small improvements to readme Added debugtime command for test suite New Features The meta protocol can now transmit binary encoded keys by encoding the key in base64 and sending a ‘b’ flag with the command. If for example your key composes of several large numerics (userids and so on), these can be encoded directly as binary. This shortens the key which can save some memory on the server. See doc/protocol.txt for more details.\nContributors The following people contributed to this release since 1.6.9.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.9..1.6.10 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.10 13\tdormando 2\tminkikim89 1\tBrian Aker 1\tHervé Beraud 1\tKevin Lin 1\tKhem Raj 1\tLSmithx2 1\tLevente Polyak 1\tTomas Korbar 1\tTyson Andre 1\ttom "},"title":"ReleaseNotes1610"},"/releasenotes/releasenotes1611/":{"data":{"":"","#":"Memcached 1.6.11 Release Notes Date: 2021-9-27\nDownload https://www.memcached.org/files/memcached-1.6.11.tar.gz\nOverview Bugfixes, potential performance improvements, improvements to logging. Includes some upstreamed changes for an upcoming feature.\nFixes Expose number of currently active watchers in stats Configurable minimum supported TLS protocol version core: fix hang bug in extstore thread: use eventfd for worker notify if available thread: per-worker-thread connection event queues core: cache.c cleanups, use queue.h freelist core: add queue.h to replace handrolled queues. logger: simplify logging code logger: avoid polling without watchers Implement LOG_CONNEVENTS watcher flag for connection state transitions Report item sizes for fetch, mutation, and eviction watchers Fix typos in doc/code comments (tem-\u003eitem, etc) New Features watch connevents will show realtime log entries about client connect/disconnect events.\nContributors The following people contributed to this release since 1.6.10.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.10..1.6.11 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.11 11\tdormando 5\tKevin Lin 1\tTyson Andre "},"title":"ReleaseNotes1611"},"/releasenotes/releasenotes1612/":{"data":{"":"","#":"Memcached 1.6.12 Release Notes Date: 2021-9-28\nDownload http://www.memcached.org/files/memcached-1.6.12.tar.gz\nOverview Fixes a missing file from the 1.6.11 release.\nFixes add queue.h in archive New Features Contributors The following people contributed to this release since 1.6.11.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.11..1.6.12 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.12 1\tRemi Collet "},"title":"ReleaseNotes1612"},"/releasenotes/releasenotes1613/":{"data":{"":"","#":"Memcached 1.6.13 Release Notes Date: 2022-1-12\nDownload http://www.memcached.org/files/memcached-1.6.13.tar.gz\nOverview Many important bugfixes in this release. Includes fixes to the meta protocol, fix for large text multigets in certain conditions, and a rare slowdown in extstore.\nAlso included in the codebase is a non production ready test version of an integrated proxy. For adventerous developers see t/proxy.t test code and the lua libraries at https://github.com/memcached/memcached-proxylibs - for everyone else, hold on for future versions.\nFixes core: make object cache LIFO meta: protocol.txt updates for CAS return meta: fix meta delete meta: fix CAS (‘c’) return values core: fix use-after-free for text multigets Replace OPENSSL_VERSION_NUMBER check with defined(TLS1_3_VERSION) check for TLS v1.3 compatibility Fix full unit test suite under test_tls Track store errors in thread stats Fix for failing tests on OS X extstore: avoid looping IO queues on submission tests: maxconns test when extstore enabled core: remove cdefs include from queue.h New Features The primary feature in development at this time is the proxy. Work can be tracked here: https://github.com/memcached/memcached/issues/827 - As this stabilizes formal documents will be written. If you’re curious about the feature please speak up as we are looking for testers and contributors!\nContributors The following people contributed to this release since 1.6.12.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.12..1.6.13 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.13 16\tdormando 3\tKevin Lin 1\tkokke "},"title":"ReleaseNotes1613"},"/releasenotes/releasenotes1614/":{"data":{"":"","#":"Memcached 1.6.14 Release Notes Date: 2022-2-9\nDownload http://www.memcached.org/files/memcached-1.6.14.tar.gz\nOverview Montly bugfix release. Important fix if you happen to have a couple billion items in a single instance. A handful of useful fixes and a bunch of updates to the upcoming proxy feature.\nFixes tests: workaround for t/watcher.t race restart: fix typo in error message Extend extbuf in try_read_command_binary function tests: repair race in maxconns.t test Fix integer overflow in hashsize calculation causing hang on huge hash tables meta: add “proxy tokens” P, L which are ignored core: fix large pages detection on redhat distros Fix error message on conflicting ports while using ‘-l’ New Features None.\nContributors The following people contributed to this release since 1.6.13.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.13..1.6.14 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.14 24\tdormando 1\tBaptiste Mille-Mathias 1\tDavid Carlier 1\tGabe Van Engel 1\tSailesh Mukil 1\tTomas Korbar 1\tpkarumanchi9 "},"title":"ReleaseNotes1614"},"/releasenotes/releasenotes1615/":{"data":{"":"","#":"Memcached 1.6.15 Release Notes Date: 2022-3-29\nDownload http://www.memcached.org/files/memcached-1.6.15.tar.gz\nOverview No mainline changes vs 1.6.14. This release is a roll-up of fixes to the experimental proxy mode.\nFixes proxy: Fix buffer overflow and prevent recv() of 0 byte proxy: allow await() to be called recursively proxy: mcp.request(cmd, [val | resp]) proxy: hacky method of supporting noreply/quiet proxy: add ring_hash builtin proxy: fix logger entry memory corruption storage: parameterize the compaction thread sleep proxy: pull chunks into individual c files proxy: documentation updates proxy: “stats settings” for proxy proxy: await improvements proxy: trivial support for SO_KEEPALIVE on backend mcmc: upstream update for SO_KEEPALIVE proxy: fix crash on stats proxy sans user stats proxy: enable backend_total stat proxy: track in-flight requests proxy: add some basic logging for backend errors proxy: logging improvements + lua mcp.log() proxy: add stats for commands seen New Features None.\nContributors The following people contributed to this release since 1.6.14.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.14..1.6.15 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.15 18\tdormando 1\tFei Hu "},"title":"ReleaseNotes1615"},"/releasenotes/releasenotes1616/":{"data":{"":"","#":"Memcached 1.6.16 Release Notes Date: 2022-8-3\nDownload http://www.memcached.org/files/memcached-1.6.16.tar.gz\nOverview Minor bugfixes for memcached daemon. Critical bugfixes and API additions for the experimental proxy code (if using, please upgrade)\nFixes proxy: add req:flag_token(\"F\") proxy: mcp.response code and rline API proxy: add r:has_flag(), fix r:token() length proxy: mcp.request() improvements proxy: mcplib_request_token() doesn’t delimit the final token in a request tls: Disable TLS re-negotiation from SSL context Fix undefined behavior and warning with clang proxy: fix the hashstring size for evcache ketama core: Fix FTBFS with GCC 12 on ppc64el proxy: fix race crash from io obj use-after-free proxy: fix mcp.await() when using extended args proxy: add missing errno.h include to proxy.h proxy: fix potential corruption on partial write proxy: rework backend buffer handling to fix protocol desync bug tests: skip whitespace on vendor/* tls: Add switch to opt-in to kernel TLS on OpenSSL 3.0.0+ core: checks port number at start time Add a command to dump keys for memcached-tool proxy: ‘proxyreqs’ does not work unless ‘proxyuser’ also provided proxy: replace proxycmds stream with proxyreqs proxy: mcp.log_req* API interface New Features None, outside of API additions to the proxy code.\nContributors The following people contributed to this release since 1.6.15.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.15..1.6.16 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.16 15\tdormando 2\tSailesh Mukil 1\tDavid Carlier 1\tJunji Hashimoto 1\tKevin Lin 1\tPrudhviraj K 1\tQu Chen 1\tRaphael Isemann 1\tSergio Durigan Junior 1\tTom Stellard "},"title":"ReleaseNotes1616"},"/releasenotes/releasenotes1617/":{"data":{"":"","#":"Memcached 1.6.17 Release Notes Date: 2022-8-26\nDownload http://www.memcached.org/files/memcached-1.6.17.tar.gz\nOverview Lots of fixes and a few new features in this release. Lots of proxy updates as usual for the last few. Core fixes include better defaults and higher reliability for the memory mover, extstore, and large item support.\nFixes Release TLS read and write buffers when idle Find perl via /usr/bin/env instead of directly Mac M1 build update. detects arm64 crc32 h/w support. DTrace build fix on Mac core: fix strncat warning configure.ac: use pkg-config to retrieve openssl proxy: fix missing md5.h from tarball dist docs: don’t rebuild binprot XML anymore Do memory bound check for some C string operations proxy: allow mcp.pool to ignore a nil second arg Improve Slab Automove behavior proxy: allow booleans in pool structure proxy: backend object cache was broken log: fix obscure crashes due to size_t promotion Fix race leads to deadlock during shutdown (sigterm/sigusr1) proxy: req:flag_token(\"F\", \"Freplacement\") New Features sock ip filtering tagging support for FBSD/OBSD MacOS drop privileges support core: make large item storage more reliable extstore: make defaults more aggressive Previously when using external (SSD/disk) storage, a number of items could be evicted when RAM first fills and the background flush threads have not kicked in yet. This should be largely mitigated.\nFor large items, if used exclusively, there were edge cases where SETs would fail because of memory exhaustion in smaller slab classes. This should be largely fixed.\nProxy features are documented at: https://github.com/memcached/memcached/wiki/Proxy\nContributors The following people contributed to this release since 1.6.16.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.16..1.6.17 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.17 16\tdormando 4\tDavid CARLIER 1\tDavid Carlier 1\tFabrice Fontaine 1\tIliya 1\tQu Chen 1\tSailesh Mukil 1\tTharanga Gamaethige "},"title":"ReleaseNotes1617"},"/releasenotes/releasenotes1618/":{"data":{"":"","#":"Memcached 1.6.18 Release Notes Date: 2023-1-10\nDownload http://www.memcached.org/files/memcached-1.6.18.tar.gz\nOverview Mostly fixes and improvements to proxy mode.\nMeta protocol has some adjusments: extra spaces were being returns in a few instances. If your client is looking for an exact number of spaces in meta responses please take note. We regret the error.\nFixes core: do not stop threads on SIGINT/SIGTERM core: remove printf from signal handlers proxy: iterate modified request handling proxy: expose resp:elapsed() proxy: log time now relative to resp lifetime proxy: fix crash in await during SIGHUP reloads proxy: fix lifecycle of backend connections proxy: IO thread performance improvements proxy: add mcp.AWAIT_BACKGROUND proxy: fix lua registry corruption on data chunk error proxy: add proxy_await_active stat proxy: fix partial response read handling proxy: fix flushing partial writes proxy: add more backend failure messages proxy: fix mcp.log_req crash on nil res core: fix tagged listeners for len \u003c 8 proxy: add debug symbols to lua build core: give threads unique names proxy: fix crash when backends are gc’d remove libevent license from usage Fixes to build with clang-15: meta: remove meta_response_old start option meta: allow mg without flags + reflect O/k on EN meta: meta arithmetic command had excess spaces meta: remove excess spaces from meta responses proxy: fix bugs with backend connection initialization Fix log timestamps after 2038 Fix function protypes for clang errors proxy: add mcp.await FASTGOOD flag New Features See the Proxy wiki page page for updates to the proxy API.\nContributors The following people contributed to this release since 1.6.17.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.17..1.6.18 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.18 33\tdormando 1\tBernhard M. Wiedemann 1\tDavid Bohman 1\tDavid Carlier 1\tKhem Raj "},"title":"ReleaseNotes1618"},"/releasenotes/releasenotes1619/":{"data":{"":"","#":"Memcached 1.6.19 Release Notes Date: 2023-3-8\nDownload http://www.memcached.org/files/memcached-1.6.19.tar.gz\nOverview Many fixes and new features for the Proxy feature. Rest are small fixes or code cleanups to the cache daemon. If you’re trying out the Proxy code, please upgrade or continue to track the next branch.\nIf you use the lru_crawler metadump hash command, specifically the hash mode, there is a fix for potential slowdowns.\n-Werror is no longer the default when compiling. Add --enable-werror to restore the feature.\nFixes replace 2\u0026\u003e1 by 2\u003e\u00261 in rpm spec file log: fix race condition while incrementing log entries dropped Add new pkg-config dependencies to dockerfiles Document missing flags of Meta Arithmetic configure.ac: add –enable-werror proxy: reduce noise for dead backends proxy: more await unit tests proxy: fix trailingdata error with ascii multiget misses crawler: don’t hold lock while writing to network proxy: redo libevent handling code (speedup/fixes) proxy: fix “missingend” error on reading responses proxy: add read buffer data to backend error messages proxy: fix partial responses on backend timeouts proxy: disallow overriding mn command tests: timedrun SIGHUP pass-thru proxy: new integration tests. proxy: fix mismatched responses after bad write proxy: fix stats deadlock caused by await code proxy: clean logic around lua yielding core: remove *c from some response code core: simplify background IO API core: remove *conn object from cache commands New Features crawler: add lru_crawler mgdump command For more efficiently getting the keylist back out of the server. A utility demonstrating its usage can be found here: https://github.com/memcached/mcdumpload\nproxy: allow workers to run IO optionally If iothread = false is added as an option to mcp.pool(), each worker thread will handle its own backend IO for this pool. Instead of one tcp connection there will be one per worker thread. This allows mixing and matching (ie; use worker threads for high data rate backends, use IO thread for background IO’s)\nproxy: add mcp.backend(t) for more overrides See tests, examples, documentation. Allows overriding timeouts, number of retries, and so on, on a per-backend basis.\nproxy: add mcp.await_logerrors() New form of mcp.await() which emits a log line for every response that ends in an error, after the main request has returned\nproxy: add mcp.internal(r) API An experimental API for accessing the cache server embedded in every proxy. Executes the command and retrieves a response object as though the command were executed against a remote backend. This allows creating pools of proxies which can answer responses directly, while doing replication to remote zones and other tasks.\nContributors The following people contributed to this release since 1.6.18.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.18..1.6.19 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.19 28\tdormando 5\txuesenliang 1\tDavid Carlier 1\tFabrice Fontaine 1\tMate Borcsok 1\tOlof Nord 1\tPatrice Duroux 1\tRamasai "},"title":"ReleaseNotes1619"},"/releasenotes/releasenotes162/":{"data":{"":"","#":"Memcached 1.6.2 Release Notes Date: 2020-3-23\nDownload http://www.memcached.org/files/memcached-1.6.2.tar.gz\nOverview Fixes a remote DoS (segfault) in parsing of the binary protocol header that was introduced in 1.6.0. Update immediately or disable the binary protocol if you are not using it (-B ascii).\nFixes No other fixes. New Features None. Contributors The following people contributed to this release since 1.6.1.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.1..1.6.2 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.2 1\tdormando "},"title":"ReleaseNotes162"},"/releasenotes/releasenotes1620/":{"data":{"":"","#":"Memcached 1.6.20 Release Notes Date: 2023-5-12\nDownload http://www.memcached.org/files/memcached-1.6.20.tar.gz\nOverview Lots of fixes and updates for Proxy mode. Optimization for extstore disk flushing to alleviate excess evictions. Changes to meta protocol and smaller fixes.\nFixes extstore: increase aggressiveness of flush thread proxy: improve unit test coverage proxy: random small fixes proxy: return ‘readvalidate’ on be read timeout proxy: don’t print null ustats from “stats proxy” proxy: use connect timeout during retries proxy: fix flaky test in proxyconfig.t Add a debian dockerfile, as well as upgrade the autoconf dependency check for sys/auxv.h proxy: send CLIENT_ERROR when proper proxy: print lua error message on reload failure proxy: rip out io_uring code (to be re-added later) proxy: overhaul backend error handling: surface error messages to clients proxy: fix reversal of pipelined backend queries proxy: add request and buffer memory limits proxy: restrict functions for lua config vs route proxy: fix bug ignoring -R setting for proxy reqs proxy: add conntimeout error New Features proxy: add memory accounting tracking Total in-flight item buffer memory can be tracked via stats proxy counters. New options added for limiting the number of in-flight requests and amount of buffer memory: mcp.active_req_limit(count) mcp.buffer_memory_limit(kilobytes)\nThese settings can be adjusted by reloading the configuration.\nlog: Add a new watcher to watch for deletions. watch deletions stream for logs when items get deleted\nmeta: N flag changes append/prepend. meta: Add ms s flag. Adds support for the N flag when running metasets in append mode. Normally append/prepend mode does not work if the item doesn’t already exist. Now it will autovivify the item with the TTL supplied with the N flag.\nAdds support for the s flag in metaset, which will return the size of the new item stored. Useful with append/prepend.\nContributors The following people contributed to this release since 1.6.19.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.19..1.6.20 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.20 28\tdormando 5\tFei Hu 1\tFabrice Fontaine 1\tHemal Shah 1\tOlof Nord "},"title":"ReleaseNotes1620"},"/releasenotes/releasenotes1621/":{"data":{"":"","#":"Memcached 1.6.21 Release Notes Date: 2023-6-15\nDownload http://www.memcached.org/files/memcached-1.6.21.tar.gz\nOverview Bugfix and community contribution release. As usual most fixes are for the new proxy code, along with a lot of community contributed tests for proxy.\nA data corruption issue for extstore was fixed. Requires overriding item_age to a low number of seconds and re-writing the same keys frequently.\nFixes a meta protocol ms bug introduced in 1.6.20 with the s flag being returned when only asking for the c (cas) flag.\nFixes a compilation issue for proxy due to build artifacts being accidentally included into the release tarball.\nFixes build: avoid disting build artifacts from vendor/* extstore: fix data bugs on high overwrite key proxy: fixes for memory tracking meta: fix ms c flag reflecting s flag extstore: fail to start if given no disk space extstore: Handle incorrect units gracefully proxy: mcp.internal() support ascii multiget proxy: fix segfault for reqs with too few tokens proxy: fix per-worker-thread backend mode batching proxy: fix meta set M flag for mcp.internal() proxy: add await tests in proxyunits.t proxy: add response API tests in proxyunits.t New Features None\nContributors The following people contributed to this release since 1.6.20.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.20..1.6.21 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.21 9\tdormando 2\tFei Hu 1\tDanny Kopping 1\tDavid Carlier 1\tKissPeter 1\tajccosta "},"title":"ReleaseNotes1621"},"/releasenotes/releasenotes1622/":{"data":{"":"","#":"Memcached 1.6.22 Release Notes Date: 2023-10-15\nDownload http://www.memcached.org/files/memcached-1.6.22.tar.gz\nOverview Contains important security fixes for users of the proxy, please upgrade at your earliest convenience. This does not affect you unless you build with --enable-proxy and enable the proxy at start time.\nContains many fixes and optimizations foe the proxy subsystem, along with a few small fixes to various things.\nFixes core: fix incr/decr/ma failing in some conditions extstore: fix item loss during page defrag Note that counts for track_sizes are best effort core: fix build on BSD core: speedup for async IO handling core: don’t ignore sighup in daemonize mode proxy: add label to proxy backend error logs proxy: if a ustat label is “”, skip printing proxy: fix ms ignoring T flag for mcp.internal proxy: fix ms parsing error proxy: fix backend cleanup when using worker IO proxy: fix response code in the event of dead backend proxy: fix race condition in first load proxy: fix off-by-one if \\r is missing proxy: update backends if conncount changes proxy: io submission queue opt proxy: io return optimization proxy: fix for dropping -O2 from lua compile proxy: fix buffer overflow with multiget syntax proxy: fix flaky test in t/proxylimits.t New Features proxy: backend antiflap detection. proxy: mcp.backend({ down = true }) option proxy: add mcp.ratelim_tbf({}) proxy: easier usage of N sockets per backend See commit history for full notes. Also see the proxy documentation at: https://github.com/memcached/memcached/wiki/Proxy\nContributors The following people contributed to this release since 1.6.21.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.21..1.6.22 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.22 30\tdormando 3\tFinn Frankis 1\tFei Hu 1\tNick Pillitteri "},"title":"ReleaseNotes1622"},"/releasenotes/releasenotes1623/":{"data":{"":"","#":"Memcached 1.6.23 Release Notes Date: 2024-1-9\nDownload http://www.memcached.org/files/memcached-1.6.23.tar.gz\nOverview This release only affects the proxy code. The request dispatch API has been redone. See https://github.com/memcached/memcached/wiki/Proxy for full documentation of the API.\nIn this release please consider the new API SLIGHTLY EXPERIMENTAL. While a large effort has been made to validate the code, it is a big change. Please carefully test before deploying.\nIf you are new to the proxy, a new user friendly route library is being developed: https://github.com/memcached/memcached-proxylibs/tree/main/lib/routelib\nPLEASE NOTE: The previous mcp.await and pool(request) call forms are being aggressively deprecated. The code will be removed in the next release of memcached. You will need to move your configuration scripts to the new API before upgrading again. We do not expect to have to do this again in the future.\nThis is being done to allow simplifying the internal code and unblock performance and stabilization features that the old API was preventing.\nDEFAULT CHANGE: The proxy has, by default, used a single background thread for issuing IO to backend servers. This generally prevents scaling past 4 CPU cores, but reduces the number of TCP sockets in use and increases pipelining to backends.\nAs of this release the default is to issue backend IO directly from worker threads. This behavior can be tweaked both on a global or per-pool basis.\nIt is our goal to stabilize the proxy going forward, focusing on code cleanups and smaller changes from now on. We also aim to include the new routelib directly inside memcached in the next release to improve ease of use.\nFixes proxy: add mcp.backend_use_iothread(bool) + bugfix proxy: lua API version 2 proxy: add mcp.time_[real|mono]_millis() New Features Proxy API version 2:\nImproved performance by allowing pre-calculations reused on each request Improved performance by avoiding allocations at request time, preventing GC usage Allow recursive function calls Allow much easier future API expansion Custom callbacks for every backend request issued Contributors The following people contributed to this release since 1.6.22.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.22..1.6.23 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.23 5\tdormando "},"title":"ReleaseNotes1623"},"/releasenotes/releasenotes1624/":{"data":{"":"","#":"Memcached 1.6.24 Release Notes Date: 2024-2-27\nDownload http://www.memcached.org/files/memcached-1.6.24.tar.gz\nOverview Mostly fixes from the fix backlog and proxy updates.\nNote: if you use the experimental -o slab_chunk_max feature, the argument has changed from bytes to kilobytes (as was documented in the help output).\nIf you use the debug me command, the expiration time was always negative. That is now fixed.\nFixes core: fix issues with -o slab_chunk_max=kb proto: fix exptime in debug command fix: prevent giving negative number with -R, -m options logger.c: initialize rport crawler: include client flags in metadump output extstore: fix CAS changing during recache slabs: fix CAS changing during page move rescues proxy: add global rate limiter proxy: fix memory leaks when freeing funcgens proxy: fix leak of nils during reload proxy: fix leak of unassigned fgens proxy: fix router accounting in stats proxyfuncs proxy: fix crash in stats proxyfuncs proxy: fix bug in config reload cleanup phase proxy: fix unlocked usage of config VM New Features Nothing of note.\nContributors The following people contributed to this release since 1.6.23.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.23..1.6.24 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.24 15\tdormando 1\tFabrice Fontaine 1\tFinn Frankis 1\tIng-eoking "},"title":"ReleaseNotes1624"},"/releasenotes/releasenotes1625/":{"data":{"":"","#":"Memcached 1.6.25 Release Notes Date: 2024-3-19\nDownload http://www.memcached.org/files/memcached-1.6.25.tar.gz\nOverview Main focus of this release is an overhaul of extstore’s space compaction system, and addition of disk specialization and basic tiering support. This optimization can greatly reduce write amplification and improve general performance. See below for details.\nThe stats sizes_enable and stats sizes_disable commands have been removed as they could cause the daemon to crash. The feature can be enabled at start time via -o track_sizes. You can also generate a histogram of data sizes via the lru_clawler metadump command and a script, which does not block the server.\nThe flush_all command was adjusted to be more accurate with CAS disabled.\nThis also addresses performance issues related to proxy lua scripting.\nFixes core: remove stats sizes_enable|disable core: stop using cas for flush_all proxy: run lua GC outside of request path proxy: fix leak in config reload proxy: allow early freeing rcontexts proxy: add new request meta flag APIs fix build on uclibc-ng New Features This release adds the concept of assigning data storage to specialized “buckets” in extstore. This can be used to create tiered storage between new and old/cold data. You can also tier between normal, compacted, “low ttl” and so on.\nrun with: ext_path=/path/f1:64m,ext_path=/path2/f2:128m:compact creates a 64m file for “Default” pages and a 128m file for compacted pages. Also works with ‘chunked’ and ’lowttl’.\ntiered storage:\nIf the above bucket is ‘old’ (ie; ext_path=/etc:1G:old) then when the “main” disk is full, valid items are moved to the “old” bucket to free up space in the main disk. This allows using cheaper storage for old data. Especially useful if cache is an A/B data load.\nIf the bucket is ‘coldcompact’ then the behavior is similar to ‘old’, except that it will only move items that are in the COLD LRU.\nIf old or coldcompact are full, the oldest page is evicted.\nBoth of these features can be combined at once. Old active data could go to more expensive drives and cold data could go to cheaper networked drives.\nImprovements:\nfixes off-by-one preventing first page in each file from being used. makes page eviction inline with allocation, making it more responsive when necessary. removes the “fragmentation slew” calculation from when compaction should kick in. Instead of writing early, should wait until we’ve hit the compact_under page limit then start compacting the emptiest pages. begins compaction when free pages are nearly all gone, instead of when fewer than 25% of pages are free. defragments the most fragmented page first instead of the oldest uses a dedicated IO thread for data writes and compaction IO, improving tail latency. Runs the compaction checker algorithm less often, saving CPU. Contributors The following people contributed to this release since 1.6.24.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.24..1.6.25 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.25 11\tdormando 1\tFabrice Fontaine 1\tQu Chen "},"title":"ReleaseNotes1625"},"/releasenotes/releasenotes1626/":{"data":{"":"","#":"Memcached 1.6.26 Release Notes Date: 2024-3-27\nDownload http://www.memcached.org/files/memcached-1.6.26.tar.gz\nOverview Fixes a crash when lru_crawler metadump is used and the client connection is closed early. Requires closing the client excactly before the last few kilobytes of a dump are about to be flushed.\nAlso improves the ergonomics of proxy configurations via start arguments.\nPlease see the 1.6.25 Release Notes for a recent significant improvement to Extstore.\nSee Proxy for details and quick start guides on the internal Proxy.\nFixes proxy: -o proxy_arg to pass cmdline to lua proxy: -o proxy_config takes multiple files crawler: fix potential memory corruption New Features Contributors The following people contributed to this release since 1.6.25.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.25..1.6.26 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.26 3\tdormando "},"title":"ReleaseNotes1626"},"/releasenotes/releasenotes1627/":{"data":{"":"","#":"Memcached 1.6.27 Release Notes Date: 2024-5-5\nDownload http://www.memcached.org/files/memcached-1.6.27.tar.gz\nOverview Many proxy updates, including a critical stability fix for users of the newer style request API.\nAdds new meta protocol extensions:\nEcas: If specified and request succeeds, uses supplied number for the CAS value of the item. This allows using external versioning for cache data (ie; row versions, crc’s, etc).\nx flag for md: This flag causes md to atomically replace the value with the same meta data, but 0 byte value. Can be combined with I to make an empty item that is marked stale.\nFixes proxy: fix backend depth counter going negative proxy: fix short writes caused by mcp.internal proxy: fix IO backlog softlock proxy: even more lua GC tuning proxy: fix race condition leading to hang proxy: fix possible corruption with global objects extstore: start arg tokenizer fix proxy: fix proxy_config with \u003e 2 lua files New Features core: add queue info to stats conns proxy: mcp.server_stats(subcmd) meta: md with x removes value proxy: wait timeout API proxy: config thread cron functions meta: E flag for overriding CAS value proxy: stats proxybe to show bad backends proxy: rctx:cfd() and log_req cfd Contributors The following people contributed to this release since 1.6.26.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.26..1.6.27 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.27 19\tdormando "},"title":"ReleaseNotes1627"},"/releasenotes/releasenotes1628/":{"data":{"":"","#":"Memcached 1.6.28 Release Notes Date: 2024-5-31\nDownload https://www.memcached.org/files/memcached-1.6.28.tar.gz\nOverview Fixes unfortunate potentially critical use-after-free bug in the proxy mode that was introduced in 1.6.27. The bug is difficult to trigger but if you are on 1.6.27 upgrading is strongly recommended.\nAlso adds experimental support for TLS to proxy backends. Please let us know if you intend to use this feature as it has only received limited testing; we will prioritize further work if folks are interested in using it.\nFixes core: Reorder r/w for itemstats aggregation proxy: make iov limit bugs easier to see proxy: fix stupid write flush bug crawler: don’t block during hash expansion proxy: fix refcount leak in mcp.internal() New Features memcached-tool: add -u flag to unescape special chars in keys names proxy: add counters for VM memory and GC runs Under stats proxy: vm_gc_runs: increased each time a lua VM GC runs in any worker thread vm_memory_kb: mostly current total memory usage of worker lua VM’s in kilobytes.\nproxy: backend TLS support [EXPERIMENTAL] proxy: support to-be-closed for result objects proxy: res:close() If issuing get requests from mcp.internal, and you are not returning the result object to the client, users should mark the result object as \u003cclose\u003e or manually call res:close() to release the reference on the item data.\nproxy: add mcp.backend_depth_limit(int) If a backend has a request queue depth higher than this limit, further requests will fast fail.\nContributors The following people contributed to this release since 1.6.27.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.27..1.6.28 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.28 9\tdormando 1\tDaniel Vasquez-Lopez 1\tPierre-Yves Rofes "},"title":"ReleaseNotes1628"},"/releasenotes/releasenotes1629/":{"data":{"":"","#":"Memcached 1.6.29 Release Notes Date: 2024-6-28\nDownload https://www.memcached.org/files/memcached-1.6.29.tar.gz\nOverview Only proxy related updates.\nFixes proxy: ustats internal refactor proxy: router refactor and cmap fallback proxy: ensure resp.elapsed gets set on backend errors proxy: let proxy build without openssl installed New Features All proxy updates:\nSpeeds up displaying stats proxy when many user defined counters are used. If a user counter changes name, it will be reset to zero. Allows overriding commands either by key prefix or specific command. These are supported by routelib: https://github.com/memcached/memcached-proxylibs/tree/main/lib/routelib\nContributors The following people contributed to this release since 1.6.28.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.28..1.6.29 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.29 5\tdormando "},"title":"ReleaseNotes1629"},"/releasenotes/releasenotes163/":{"data":{"":"","#":"Memcached 1.6.3 Release Notes Date: 2020-3-28\nDownload http://www.memcached.org/files/memcached-1.6.3.tar.gz\nOverview Bugfix release plus some code cleanup. Includes a fix for another remote crash, this time in the new metaget code.\nFixes crash fix: errstr wasn’t initialized in metaget fix startup segfault for low conns + idle thread restart: fix corrupted restart in some scenarios restart: always wipe memory from global pool restart: fix rare segfault on shutdown tls: fix crash with refresh_certs command when TLS is disabled New Features -o ssl_session_cache can be used (when TLS is compiled in) to enable server side session reuse.\n./configure --enable-static for static builds\nContributors The following people contributed to this release since 1.6.2.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.2..1.6.3 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.3 10\tdormando 2\tKevin Lin "},"title":"ReleaseNotes163"},"/releasenotes/releasenotes164/":{"data":{"":"","#":"Memcached 1.6.4 Release Notes Date: 2020-4-12\nDownload http://www.memcached.org/files/memcached-1.6.4.tar.gz\nOverview Bugfix release. Notably compile/build/compat fixes. Also fixes a few failures in the restartable mode when using chunked items.\nFixes restart: fix failure on deleted chunked items ascii auth: fix CPU spike when waiting for data extstore: fix some valgrind errors. Fix undefined behavior with -D_FORTIFY_SOURCE=2 Fix build warnings in Windows. Add build option to disable unix socket functionality. fix extstore reads for OSX/cygwin Fix misprint in protocol.txt Fix t/64bit.t test failure in Windows. build: sasl build fix on FreeBSD testapp: Fix failure with -flto=auto New Features None.\nContributors The following people contributed to this release since 1.6.3.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.3..1.6.4 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.4 8\tdormando 3\tJefty Negapatan 1\tDavid Carlier 1\tDmitry Volodin 1\tKanak Kshetri "},"title":"ReleaseNotes164"},"/releasenotes/releasenotes165/":{"data":{"":"","#":"Memcached 1.6.5 Release Notes Date: 2020-4-13\nDownload http://www.memcached.org/files/memcached-1.6.5.tar.gz\nOverview Fix for SASL build issue introduced in 1.6.4\nFixes Revert “build: sasl build fix on FreeBSD” New Features None.\nContributors The following people contributed to this release since 1.6.4.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.4..1.6.5 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.5 1\tdormando "},"title":"ReleaseNotes165"},"/releasenotes/releasenotes166/":{"data":{"":"","#":"Memcached 1.6.6 Release Notes Date: 2020-5-12\nDownload http://www.memcached.org/files/memcached-1.6.6.tar.gz\nOverview Bugfixes mostly relating to portability and packaging. Many thanks to the various package maintainers who wrote in and sent patches.\nFixes Update testing certificates to be compatible with latest security levels Fix crash on shutdown when handling signals with TLS enabled start of valgrind test mode more flaky test fixes; crawler/restart Disable aarch64 hw crc32 function for now Pull in BigEndian-compatible crc32c minimum libevent version is 2.x Add Meta no-op command request to protocol.txt New Features None.\nContributors The following people contributed to this release since 1.6.5.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.5..1.6.6 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.6 12\tdormando 2\tTomas Korbar 1\tDmitry Volodin 1\tJefty Negapatan "},"title":"ReleaseNotes166"},"/releasenotes/releasenotes167/":{"data":{"":"","#":"Memcached 1.6.7 Release Notes Date: 2020-9-4\nDownload http://www.memcached.org/files/memcached-1.6.7.tar.gz\nOverview Mainly a bugfix release. -o resp_obj_mem_limit is deprecated, as the memory is all pooled from read_buf_mem_limit now. Almost all connection memory is now managed by this one tunable.\nFixes a bug preventing 1.6 series to work properly on OS X. Improves automated slab rebalancing for bursty writes.\nContains code refactors and fixes related to future work. Should not have any functional changes.\nFixes Dockerfile - allow override of config opts Improve page balancing when writes are bursty main: split binary protocol into proto_bin.c main: split text protocol into proto_text.c add openssl errors to SSL certificate loading error messages skip setting the resource limits in debug builds Use signal function instead of sigignore fixing the basic tls test so it exits correctly when fails net: remove most response obj cache related code net: carve response buffers from read buffers Do not join lru and slab maintainer threads if they do not exist Restore SAN entries in testing TLS certificates Changed code using strtol to use safe_strtol wrapper Fix TCP failure under OS X. New Features None.\nContributors The following people contributed to this release since 1.6.6.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.6..1.6.7 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.7 8\tdormando 2\tTharanga Gamaethige 2\tTomas Korbar 1\tGuido Iaquinti 1\tKevin Lin 1\tMark Hagger 1\tminkikim89 1\tprudhvi "},"title":"ReleaseNotes167"},"/releasenotes/releasenotes168/":{"data":{"":"","#":"Memcached 1.6.8 Release Notes Date: 2020-10-26\nDownload http://www.memcached.org/files/memcached-1.6.8.tar.gz\nOverview Small security related release. A remote crash is possible if UDP is enabled. The remediation is to upgrade or disable UDP. The crash was introduced in the 1.6 series.\nThanks to @Zaffy and @m6w6 for their reports.\nUDP has not been enabled by default for years and it has no authentication or security, so it most users should not have a high exposure to this bug.\nThis also includes two minor fixes.\nFixes Improve opening of authentication file Fix over-freeing in internal object cache udp: crash fix when receiving multi-packet uploads New Features None.\nContributors The following people contributed to this release since 1.6.7.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.7..1.6.8 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.8 1\tTomas Korbar 1\tbitground 1\tdormando "},"title":"ReleaseNotes168"},"/releasenotes/releasenotes169/":{"data":{"":"","#":"Memcached 1.6.9 Release Notes Date: 2020-11-20\nDownload http://www.memcached.org/files/memcached-1.6.9.tar.gz\nOverview This change has a few useful new features, along with a lot of bugfixes and some internal code reorganization for future projects. We have been questing to improve test quality and stamp down bugs that came in over the 1.6 series.\nAs usual many thanks to the numerous contributors who sent in patches or helped test this release!\nFixes crawler: remove bad mutex unlock during error idle_timeout: avoid long hangs during shutdown extstore: use fcntl locking on disk file portability fix for getsubopt illumos build fixes + require libevent2 core: generalize extstore’s defered IO queue fix connection limit tests logger: fix spurious watcher hangups watcher.t: reduce flakiness Extend test CA validity to 500 years adjust “t/idle-timeout.t” be more forgiving New Features arm64: Re-add arm crc32c hw acceleration for extstore\nrestart mode: expose memory_file path in stats settings\n‘shutdown graceful’ command for raising SIGUSR1\nIntroduce NAPI ID based worker thread selection (see doc/napi_ids.txt)\nitem crawler hash table walk mode\nThe background item crawler thread is used by default to walk LRU’s and actively reclaim expired items. It can also be used by end users to examine the cache via the lru_crawler metadump command.\nThe metadump command can be told to walk specific LRU’s, in case you are curious what is taking up memory in lower or higher slab classes. On the downside LRU’s will naturally reorder as things happen. There is also an issue where items that are very frequently accessed are invisible to the LRU crawler.\nNew with this release, if you invoke the crawler via: lru_crawler metadump hash, the crawler will instead visit each bucket in the hash table. This will ensure each item is visited once, but the search cannot be limited in the same way.\nNote this does not in any way snapshot memory. If items are deleted or added to the hash table after the walk starts, they may or may not be seen.\nContributors The following people contributed to this release since 1.6.8.\nNote that this is based on who contributed changes, not how they were done. In many cases, a code snippet on the mailing list or a bug report ended up as a commit with your name on it.\nNote that this is just a summary of how many changes each person made which doesn’t necessarily reflect how significant each change was. For details on what led up into a branch, either grab the git repo and look at the output of git log 1.6.8..1.6.9 or use a web view.\nRepo list: https://github.com/memcached/memcached/wiki/DevelopmentRepos Web View: http://github.com/memcached/memcached/commits/1.6.9 15\tdormando 2\tKevin Lin 1\tAli Saidi 1\tBernhard M. Wiedemann 1\tDavid Carlier 1\tKleber 1\tSridhar Samudrala 1\tTianon Gravi 1\tpkarumanchi9 "},"title":"ReleaseNotes169"}}